{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:29:58.186502Z",
     "start_time": "2021-04-22T10:29:54.091845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "console.log('Starting front end url_querystring_target comm target');\n",
       "const comm = Jupyter.notebook.kernel.comm_manager.new_comm('url_querystring_target', {'init': 1});\n",
       "comm.send({'ipyparams_browser_url': window.location.href});\n",
       "console.log('Sent window.location.href on url_querystring_target comm target');\n",
       "\n",
       "comm.on_msg(function(msg) {\n",
       "    console.log(msg.content.data);\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-22 18:29:58,183: INFO: deployment = dev\n",
      "2021-04-22 18:29:58,183: INFO: dataset_name = snps_18510_c8\n",
      "2021-04-22 18:29:58,184: INFO: working_path = /tf/eipi10/jian-xu3/snps-classification\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ipyparams\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import string  \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from collections import Counter\n",
    "from google_trans_new import google_translator\n",
    "from joblib import Parallel, delayed\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, models, layers, regularizers, preprocessing, datasets, metrics, losses, optimizers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorboard.plugins.hparams import api as hp \n",
    "\n",
    "base_path = os.path.abspath('/tf/eipi10/jian-xu3/snps-classification')\n",
    "sys.path.append(base_path)\n",
    "\n",
    "import snps \n",
    "\n",
    "from snps.core import text_predictor \n",
    "from snps.core import util \n",
    "from snps.utils import data\n",
    "from snps.core.text_classification import lr_schedule\n",
    "from snps.core.text_classification import plot_distribution, plot_length_distribution, plot_frequency_distribution\n",
    "from snps.core.text_classification import Params, TextClassificationHelper\n",
    "from snps.core.text_classification import SimpleTextDatasets, SequenceTextDatasets, RawTextDatasets,TransferTextDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:29:58.205871Z",
     "start_time": "2021-04-22T10:29:58.195803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deployment': 'dev',\n",
       " 'dataset_name': 'snps_18510_c8',\n",
       " 'document_client_id': 'c9a0e93c-8592-4bfd-b9c3-08cc93480ab2',\n",
       " 'document_client_secret': 'coL0KKIJUZBCQP9gDrThcr7V3xVl3kA4CZj2Be/cj7g=',\n",
       " 'list_client_id': 'c03d016f-f430-402a-ad06-c1a021ba79db',\n",
       " 'list_client_secret': 'ipHd2JgOi0w5W1uckFvGNpIVR86k7kOV4oCEzTOcLaA='}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps.env.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T06:11:59.539358Z",
     "start_time": "2021-04-02T06:11:59.530078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]]\n",
      "------------------------------------------------------------\n",
      "[[0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "\n",
    "row_count=5\n",
    "label_count=2\n",
    "np.random.seed(2021)\n",
    "\n",
    "y_true = np.random.randint(0, 2, (row_count, label_count))\n",
    "y_score = np.random.rand(row_count, label_count)*7/10 + y_true*3/10\n",
    "y_pred = np.random.randint(0, 2, (row_count, label_count))\n",
    "\n",
    "print('-'*60)\n",
    "print(y_true)\n",
    "# print('-'*60)\n",
    "# print(y_score.shape, y_score)\n",
    "print('-'*60)\n",
    "print( y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T06:10:48.744798Z",
     "start_time": "2021-04-02T06:10:48.733690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "[0.6, 0.4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "scores = []\n",
    "for j in range(label_count):\n",
    "    scores.append(accuracy_score(y_true[:,j], y_pred[:,j]))\n",
    "print(scores)\n",
    "np.mean(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:56:38.051775Z",
     "start_time": "2021-04-02T02:56:37.970625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ macro ------------------------------\n",
      "0.8343839848445157\n",
      "0.8343839848445158\n",
      "------------------------------ micro ------------------------------\n",
      "0.8343941642840822\n",
      "0.8343941642840822\n",
      "------------------------------ weighted ------------------------------\n",
      "0.8343397110348449\n",
      "0.8343397110348447\n"
     ]
    }
   ],
   "source": [
    "for average in ['macro', 'micro', 'weighted']:\n",
    "    print('-'*30, average, '-'*30)    \n",
    "    print(roc_auc_score(y_true, y_score, average=average))\n",
    "\n",
    "    scores = []\n",
    "    weights = []\n",
    "    \n",
    "    if average=='macro':\n",
    "        for j in range(label_count):\n",
    "            scores.append(roc_auc_score(y_true[:,j], y_score[:,j]))\n",
    "            weights.append(1)\n",
    "    elif average=='weighted':\n",
    "        for j in range(label_count):\n",
    "            scores.append(roc_auc_score(y_true[:,j], y_score[:,j]))\n",
    "            weights.append(np.sum(y_true[:,j]))            \n",
    "    elif average=='micro':        \n",
    "        scores.append(roc_auc_score(y_true.ravel(), y_score.ravel()))\n",
    "        weights.append(1)\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    weights = np.array(weights)/np.sum(weights)   \n",
    "    if average=='weighted':\n",
    "        weighted = weights\n",
    "    print(np.sum(scores*weights))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:56:09.371406Z",
     "start_time": "2021-04-01T08:56:09.331589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83571875\n",
      "0.83560884\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "num_thresholds = 200 \n",
    "m = tf.keras.metrics.AUC(num_thresholds=num_thresholds, multi_label=True, label_weights=weighted)\n",
    "m.update_state(y_true, y_score)\n",
    "print(m.result().numpy())\n",
    "\n",
    "m = tf.keras.metrics.AUC(num_thresholds=num_thresholds, multi_label=False)\n",
    "m.update_state(y_true, y_score)\n",
    "print(m.result().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:56:09.773887Z",
     "start_time": "2021-04-01T08:56:09.373638Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e561a70b169d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fpr' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.figure(figsize=(6, 6))    \n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlim((-0.01, 1.01))\n",
    "    plt.ylim((-0.01, 1.01)) \n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.xticks(np.linspace(0, 1, 11))\n",
    "    plt.yticks(np.linspace(0, 1, 11))\n",
    "    plt.plot(fpr, tpr)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:56:09.776120Z",
     "start_time": "2021-04-01T08:56:09.247Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.trapz(tpr, fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:56:09.777494Z",
     "start_time": "2021-04-01T08:56:09.248Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true[:,0], y_score[:,0], pos_label=1) \n",
    "print('-'*30, 'fpr', '-'*30)\n",
    "print(fpr, len(fpr))\n",
    "print('-'*30, 'tpr', '-'*30)\n",
    "print(tpr, len(tpr))\n",
    "print('-'*30, 'thresholds', '-'*30)\n",
    "print(thresholds, len(thresholds))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:06:34.217796Z",
     "start_time": "2021-04-02T03:06:34.207328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([0, 1, 3 ,2 ])\n",
    "new_labels = np.zeros((labels.size, labels.max() + 1))\n",
    "new_labels[np.arange(labels.size), labels] = 1\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T06:05:04.972357Z",
     "start_time": "2021-04-02T06:05:04.958282Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T06:04:52.685321Z",
     "start_time": "2021-04-02T06:04:52.680430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:35:17.153347Z",
     "start_time": "2021-04-02T08:35:16.067629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 7) (22, 4)\n",
      "Epoch 1/2\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.0000e+00 - binary_accuracy: 0.5227 - val_loss: 0.6858 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.6250\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6842 - accuracy: 0.0000e+00 - binary_accuracy: 0.6705 - val_loss: 0.6805 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.7159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fad607128d0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X = [[1,0,0,0,0,0,0],\n",
    "      [1,2,0,0,0,0,0],\n",
    "      [3,0,0,0,0,0,0],\n",
    "      [3,4,0,0,0,0,0],\n",
    "      [2,0,0,0,0,0,0],\n",
    "      [3,0,0,0,0,0,0],\n",
    "      [4,0,0,0,0,0,0],\n",
    "      [2,3,0,0,0,0,0],\n",
    "      [1,2,3,0,0,0,0],\n",
    "      [1,2,3,4,0,0,0],\n",
    "      [0,0,0,0,0,0,0],\n",
    "      [1,1,2,3,0,0,0],\n",
    "      [2,3,3,4,0,0,0],\n",
    "      [4,4,1,1,2,0,0],\n",
    "      [1,2,3,3,3,3,3],\n",
    "      [2,4,2,4,2,0,0],\n",
    "      [1,3,3,3,0,0,0],\n",
    "      [4,4,0,0,0,0,0],\n",
    "      [3,3,0,0,0,0,0],\n",
    "      [1,1,4,0,0,0,0],\n",
    "      [3,3,0,1,0,0,0],\n",
    "      [1,1,4,0,2,0,0]\n",
    "    ]\n",
    "\n",
    "Y = [[1,0,0,0],\n",
    "    [1,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [0,0,1,1],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [0,0,0,1],\n",
    "    [0,1,1,0],\n",
    "    [1,1,1,0],\n",
    "    [1,1,1,1],\n",
    "    [0,0,0,0],\n",
    "    [1,1,1,0],\n",
    "    [0,1,1,1],\n",
    "    [1,1,0,1],\n",
    "    [1,1,1,0],\n",
    "    [0,1,0,0],\n",
    "    [1,0,1,0],\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0],\n",
    "    [1,0,0,1],\n",
    "    [0,0,1,0],\n",
    "    [1,0,0,1]\n",
    "    ]\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "MAXLEN = 7\n",
    "MAXFEATURES = 4\n",
    "NUM_CLASSES = 4\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAXFEATURES+1,\n",
    "                    50,\n",
    "                    input_length=MAXLEN))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[metrics.Accuracy(), 'binary_accuracy'])\n",
    "model.fit(X, Y,\n",
    "          batch_size=1,\n",
    "          epochs=2,\n",
    "          validation_data=(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:51:48.757651Z",
     "start_time": "2021-04-02T07:51:48.656520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad604777b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6704545454545454"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X) \n",
    "y_true = Y\n",
    "\n",
    "accuracy_score(y_true.ravel(), y_pred.ravel()>=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:27:30.397999Z",
     "start_time": "2021-04-02T08:27:30.306881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67045456\n",
      "0.67045456\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X) \n",
    "y_true = Y\n",
    "\n",
    "accuracy_score(y_true.ravel(), y_pred.ravel()>=0.5) \n",
    "\n",
    "\n",
    "m = tf.keras.metrics.BinaryAccuracy()\n",
    "m.update_state(y_true, y_pred>0.5)\n",
    "print(m.result().numpy())\n",
    "\n",
    "m = tf.keras.metrics.Accuracy()\n",
    "m.update_state(y_true, y_pred>0.5)\n",
    "print(m.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:34:17.184113Z",
     "start_time": "2021-04-02T07:34:17.176721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590909090909091"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:29:28.171661Z",
     "start_time": "2021-04-02T08:29:28.166162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "y_true1 = y_true.argmax(axis=-1) \n",
    "y_pred1 = y_pred.argmax(axis=-1)\n",
    "print(accuracy_score(y_true1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:18:32.209310Z",
     "start_time": "2021-04-02T07:18:32.183274Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ipytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-8c1f6f44297a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mipytest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-qq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ipytest' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T01:21:21.175500Z",
     "start_time": "2021-04-07T01:21:21.171166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'cd', 'efg']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a b cd efg '.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T07:32:23.928844Z",
     "start_time": "2021-04-07T07:32:23.922547Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T07:55:28.130690Z",
     "start_time": "2021-04-07T07:55:28.126800Z"
    }
   },
   "outputs": [],
   "source": [
    "letters = 'c b a 9 8 7 6 5 4 3 2 1 0'.split()\n",
    "X_train = [ letters[i:]  for i in range(len(letters))]\n",
    "X_test = ['a 9 8 1 0 x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T07:56:25.873883Z",
     "start_time": "2021-04-07T07:56:25.868024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, 'a': 11, 'b': 12, 'c': 13}\n",
      "[[9, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer(num_words=10)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(tokenizer.word_index)\n",
    "\n",
    "X_train_transform = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_transform = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# 可以看到编号为字符9被忽略了，因为它的index>=num_words\n",
    "print(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T07:41:29.850417Z",
     "start_time": "2021-04-07T07:41:29.844837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10,\n",
       " 'j': 11,\n",
       " 'i': 12,\n",
       " 'h': 13,\n",
       " 'g': 14,\n",
       " 'f': 15,\n",
       " 'e': 16,\n",
       " 'd': 17,\n",
       " 'c': 18,\n",
       " 'b': 19,\n",
       " 'a': 20}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:25:59.456201Z",
     "start_time": "2021-04-08T07:25:50.308499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 309 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (4.56.0)\n",
      "Installing collected packages: joblib, textblob\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.0\n",
      "    Uninstalling joblib-1.0.0:\n",
      "      Successfully uninstalled joblib-1.0.0\n",
      "Successfully installed joblib-1.0.1 textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib textblob -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:22:22.924624Z",
     "start_time": "2021-04-08T08:22:16.777642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"es\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"de\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"fr\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"pt\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"ru\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"zh\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate comments using \"ar\" language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from textblob import TextBlob\n",
    "from textblob.translate import NotTranslated\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "NAN_WORD = \"_NAN_\"\n",
    "\n",
    "\n",
    "def translate(sentence, language):\n",
    "    if hasattr(sentence, \"decode\"):\n",
    "        sentence = sentence.decode(\"utf-8\")\n",
    "\n",
    "    text = TextBlob(sentence)\n",
    "    try:\n",
    "        text = text.translate(to=language)\n",
    "        text = text.translate(to=\"en\")\n",
    "    except NotTranslated:\n",
    "        pass\n",
    "\n",
    "    return str(text)\n",
    "\n",
    "\n",
    "languages = [\"es\", \"de\", \"fr\", \"pt\", \"ru\", \"ar\"]\n",
    "thread_count = 10\n",
    "\n",
    "\n",
    "sentences = ['Due to the 4 months of purchase, I have problems with the ram memory.',\n",
    "             'It was a very long process to solve my problem',\n",
    "             'They took a long time to communicate once the action plan was defined.'\n",
    "            ]\n",
    "\n",
    "results = {'en':sentences}\n",
    "\n",
    "\n",
    "parallel = Parallel(thread_count, backend=\"threading\", verbose=5)\n",
    "for language in languages:\n",
    "    print('Translate comments using \"{0}\" language'.format(language))\n",
    "    translated_data = parallel(delayed(translate)(sentence, language) for sentence in sentences)\n",
    "    results[language] = translated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:22:39.104336Z",
     "start_time": "2021-04-08T08:22:39.099276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': ['Due to the 4 months of purchase, I have problems with the ram memory.',\n",
       "  'It was a very long process to solve my problem',\n",
       "  'They took a long time to communicate once the action plan was defined.'],\n",
       " 'es': ['Due to the 4 months of purchase, I have problems with the RAM.',\n",
       "  'It was a very long process to solve my problem.',\n",
       "  'They took a long time to communicate once the action plan was defined.'],\n",
       " 'de': ['Due to the 4 month purchase I have problems with the RAM memory.',\n",
       "  'It was a very long process to solve my problem',\n",
       "  'Communication took a long time after the action plan was set.'],\n",
       " 'fr': ['Due to the 4 months of purchase, I am having problems with the RAM memory.',\n",
       "  'It was a very long process to resolve my issue',\n",
       "  'They took a long time to communicate once the action plan was defined.'],\n",
       " 'pt': ['Due to the 4 months of purchase, I am having problems with ram.',\n",
       "  'It was a very long process to solve my problem',\n",
       "  'They took a long time to communicate after the action plan was defined.'],\n",
       " 'ru': ['Due to 4 months of purchase, I have problems with RAM.',\n",
       "  'The solution to my problem was very long',\n",
       "  'After the action plan was determined, it took them a long time to communicate.'],\n",
       " 'zh': ['Since I purchased it for 4 months, I have a problem with my RAM memory.',\n",
       "  'Solving my problem is a long process',\n",
       "  'Once the action plan was developed, they spent a long time communicating.'],\n",
       " 'ar': ['Due to 4 months of purchase, I have RAM issues.',\n",
       "  'It was a very long process to solve my problem',\n",
       "  'They took a long time to communicate once the business plan was determined.']}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:53:07.431618Z",
     "start_time": "2021-04-08T07:53:07.401682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>pt</th>\n",
       "      <th>ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Due to the 4 months of purchase, I have proble...</td>\n",
       "      <td>Due to the 4 months of purchase, I have proble...</td>\n",
       "      <td>Due to the 4 month purchase I have problems wi...</td>\n",
       "      <td>Due to the 4 months of purchase, I am having p...</td>\n",
       "      <td>Due to the 4 months of purchase, I am having p...</td>\n",
       "      <td>Due to 4 months of purchase, I have problems w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a very long process to solve my problem</td>\n",
       "      <td>It was a very long process to solve my problem.</td>\n",
       "      <td>It was a very long process to solve my problem</td>\n",
       "      <td>It was a very long process to resolve my issue</td>\n",
       "      <td>It was a very long process to solve my problem</td>\n",
       "      <td>The solution to my problem was very long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They took a long time to communicate once the ...</td>\n",
       "      <td>They took a long time to communicate once the ...</td>\n",
       "      <td>Communication took a long time after the actio...</td>\n",
       "      <td>They took a long time to communicate once the ...</td>\n",
       "      <td>They took a long time to communicate after the...</td>\n",
       "      <td>After the action plan was determined, it took ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Due to the 4 months of purchase, I have proble...   \n",
       "1     It was a very long process to solve my problem   \n",
       "2  They took a long time to communicate once the ...   \n",
       "\n",
       "                                                  es  \\\n",
       "0  Due to the 4 months of purchase, I have proble...   \n",
       "1    It was a very long process to solve my problem.   \n",
       "2  They took a long time to communicate once the ...   \n",
       "\n",
       "                                                  de  \\\n",
       "0  Due to the 4 month purchase I have problems wi...   \n",
       "1     It was a very long process to solve my problem   \n",
       "2  Communication took a long time after the actio...   \n",
       "\n",
       "                                                  fr  \\\n",
       "0  Due to the 4 months of purchase, I am having p...   \n",
       "1     It was a very long process to resolve my issue   \n",
       "2  They took a long time to communicate once the ...   \n",
       "\n",
       "                                                  pt  \\\n",
       "0  Due to the 4 months of purchase, I am having p...   \n",
       "1     It was a very long process to solve my problem   \n",
       "2  They took a long time to communicate after the...   \n",
       "\n",
       "                                                  ru  \n",
       "0  Due to 4 months of purchase, I have problems w...  \n",
       "1           The solution to my problem was very long  \n",
       "2  After the action plan was determined, it took ...  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:00:34.412215Z",
     "start_time": "2021-04-12T07:00:34.380326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_legs</th>\n",
       "      <th>num_wings</th>\n",
       "      <th>num_specimen_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>falcon</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white ant</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num_legs  num_wings  num_specimen_seen\n",
       "falcon            2          2                 10\n",
       "dog               4          0                  2\n",
       "spider            8          0                  1\n",
       "fish              0          0                  8\n",
       "white ant         6          2                  6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_legs</th>\n",
       "      <th>num_wings</th>\n",
       "      <th>num_specimen_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>falcon</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_legs  num_wings  num_specimen_seen\n",
       "falcon         4          2                 10\n",
       "dog            8          0                  2\n",
       "spider        16          0                  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_legs</th>\n",
       "      <th>num_wings</th>\n",
       "      <th>num_specimen_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>falcon</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white ant</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num_legs  num_wings  num_specimen_seen\n",
       "falcon            4          2                 10\n",
       "dog               8          0                  2\n",
       "spider           16          0                  1\n",
       "fish              0          0                  8\n",
       "white ant         6          2                  6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'num_legs': [2, 4, 8, 0, 6],\n",
    "                   'num_wings': [2, 0, 0, 0, 2],\n",
    "                   'num_specimen_seen': [10, 2, 1, 8, 6]},\n",
    "                  index=['falcon', 'dog', 'spider', 'fish', 'white ant'])\n",
    "display(df)\n",
    "\n",
    "def test(df1):\n",
    "    def test_(index, row):\n",
    "        df1.loc[index].num_legs=df1.loc[index].num_legs*2\n",
    "#         row.num_legs = row.num_legs*2\n",
    "        return 1\n",
    "    [test_(index, row) for index, row in df1.iterrows()]        \n",
    "    return df1\n",
    "    \n",
    "    \n",
    "display(test(df[0:3]))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:26:49.048709Z",
     "start_time": "2021-04-12T07:26:49.044512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T09:49:59.781660Z",
     "start_time": "2021-04-13T09:49:59.773636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2]\n",
      "[0.44444444 4.         2.        ]\n",
      "3.99999996\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:72: FutureWarning:\n",
      "\n",
      "Pass classes=[0, 1, 2], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    " \n",
    "class_weight = 'balanced'\n",
    "label = [0] * 9 + [1]*1 + [2, 2]\n",
    "print(label) # [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2]\n",
    "classes=[0, 1, 2]\n",
    "weight = compute_class_weight(class_weight, classes, label)\n",
    "print(weight) #[ 0.44444444 4.         2.        ]\n",
    "print(.44444444 * 9) # 3.99999996\n",
    "print(4 * 1) # 4\n",
    "print(2 * 2) # 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:11:50.838939Z",
     "start_time": "2021-04-14T12:11:48.758910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.60597828 0.73336936 0.13894716 0.31267308]\n",
      "  [0.99724328 0.12816238 0.17899311 0.75292543]\n",
      "  [0.66216051 0.78431013 0.0968944  0.05857129]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models, layers, initializers\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "def get_model(rnn_layer):\n",
    "    inputs = layers.Input(shape=(3, 4))\n",
    "    x = rnn_layer(inputs)\n",
    "    model = models.Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def predict(rnn_layer, data):\n",
    "    outputs = get_model(rnn_layer).predict(data)\n",
    "    print('-'*40, type(rnn_layer).__name__, '-'*40)\n",
    "    if isinstance(outputs, list):  \n",
    "        for output in outputs:\n",
    "            print(output, output.shape)\n",
    "    else:\n",
    "        print(outputs, outputs.shape)\n",
    "    \n",
    "np.random.seed(2021)\n",
    "data = np.random.rand(1, 3, 4)\n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:10:33.055158Z",
     "start_time": "2021-04-14T12:10:30.249871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- LSTM ----------------------------------------\n",
      "[[-0.00038722  0.02867693]] (1, 2)\n",
      "---------------------------------------- GRU ----------------------------------------\n",
      "[[ 0.00614149 -0.01545692]] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = layers.LSTM(units=2, \n",
    "                        kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        recurrent_initializer = initializers.RandomNormal(seed=2021)\n",
    "                       )\n",
    "predict(rnn_layer, data)\n",
    "\n",
    "rnn_layer = layers.GRU(units=2, \n",
    "                        kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        recurrent_initializer = initializers.RandomNormal(seed=2021)\n",
    "                       )\n",
    "predict(rnn_layer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:10:34.905352Z",
     "start_time": "2021-04-14T12:10:33.685510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- LSTM ----------------------------------------\n",
      "[[[-0.00172656  0.00940116]\n",
      "  [ 0.01072936  0.04589876]\n",
      "  [-0.00038722  0.02867693]]] (1, 3, 2)\n",
      "---------------------------------------- GRU ----------------------------------------\n",
      "[[[ 0.00662032 -0.01183234]\n",
      "  [-0.0032729  -0.00783275]\n",
      "  [ 0.00614149 -0.01545692]]] (1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = layers.LSTM(units=2, \n",
    "                        kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        return_sequences=True)\n",
    "predict(rnn_layer, data)\n",
    "\n",
    "rnn_layer = layers.GRU(units=2, \n",
    "                       kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       return_sequences=True)\n",
    "predict(rnn_layer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:11:11.825794Z",
     "start_time": "2021-04-14T12:11:10.601088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f053825cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---------------------------------------- LSTM ----------------------------------------\n",
      "[[-0.00038722  0.02867693]] (1, 2)\n",
      "[[-0.00038722  0.02867693]] (1, 2)\n",
      "[[-0.00079747  0.05748591]] (1, 2)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0538039d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---------------------------------------- GRU ----------------------------------------\n",
      "[[ 0.00614149 -0.01545692]] (1, 2)\n",
      "[[ 0.00614149 -0.01545692]] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = layers.LSTM(units=2, \n",
    "                        kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        return_state=True)\n",
    "predict(rnn_layer, data)\n",
    "\n",
    "rnn_layer = layers.GRU(units=2, \n",
    "                       kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       return_state=True)\n",
    "predict(rnn_layer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:11:55.225307Z",
     "start_time": "2021-04-14T12:11:52.646962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- LSTM ----------------------------------------\n",
      "[[[-0.00172656  0.00940116]\n",
      "  [ 0.01072936  0.04589876]\n",
      "  [-0.00038722  0.02867693]]] (1, 3, 2)\n",
      "[[-0.00038722  0.02867693]] (1, 2)\n",
      "[[-0.00079747  0.05748591]] (1, 2)\n",
      "---------------------------------------- GRU ----------------------------------------\n",
      "[[[ 0.00662032 -0.01183234]\n",
      "  [-0.0032729  -0.00783275]\n",
      "  [ 0.00614149 -0.01545692]]] (1, 3, 2)\n",
      "[[ 0.00614149 -0.01545692]] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = layers.LSTM(units=2, \n",
    "                        kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        return_sequences=True,\n",
    "                        return_state=True)\n",
    "predict(rnn_layer, data)\n",
    "\n",
    "rnn_layer = layers.GRU(units=2, \n",
    "                       kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       return_sequences=True,\n",
    "                       return_state=True)\n",
    "predict(rnn_layer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:52:10.664823Z",
     "start_time": "2021-04-14T12:52:08.187082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9bb4229c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---------------------------------------- Bidirectional ----------------------------------------\n",
      "[[[-0.00172656  0.00940116  0.00276289  0.03511165]\n",
      "  [ 0.01072936  0.04589876  0.00661553  0.03663033]\n",
      "  [-0.00038722  0.02867693 -0.00785343 -0.00329136]]] (1, 3, 4)\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9bb43ad378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---------------------------------------- Bidirectional ----------------------------------------\n",
      "[[[ 0.00662032 -0.01183234  0.00526874 -0.01576701]\n",
      "  [-0.0032729  -0.00783275 -0.00273875 -0.00760575]\n",
      "  [ 0.00614149 -0.01545692  0.00773718 -0.01140916]]] (1, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = layers.Bidirectional(layers.LSTM(units=2, \n",
    "                        kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                        return_sequences=True))\n",
    "predict(rnn_layer, data)\n",
    "\n",
    "rnn_layer = layers.Bidirectional(layers.GRU(units=2, \n",
    "                       kernel_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       recurrent_initializer = initializers.RandomNormal(seed=2021),\n",
    "                       return_sequences=True))\n",
    "predict(rnn_layer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T12:53:38.260018Z",
     "start_time": "2021-04-14T12:53:37.051762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9b107992f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[[ 0.00662032 -0.01183234  0.00526874 -0.01576701]\n",
      "  [-0.0032729  -0.00783275 -0.00273875 -0.00760575]\n",
      "  [ 0.00614149 -0.01545692  0.00773718 -0.01140916]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00614149, -0.01545692,  0.00773718, -0.01140916]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = get_model(rnn_layer).predict(data)\n",
    "print(outputs)\n",
    "outputs[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T04:37:06.095681Z",
     "start_time": "2021-04-14T13:38:28.903671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-14 21:38:30.724251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "TensorBoard 2.3.0 at http://3b132921d8c9:6006/ (Press CTRL+C to quit)\n",
      "E0414 21:44:18.235365 140501210752768 directory_watcher.py:196] Unable to get size of /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/events.out.tfevents.1618404832.3b132921d8c9.31102.989.v2: /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/events.out.tfevents.1618404832.3b132921d8c9.31102.989.v2; No such file or directory\n",
      "W0414 21:44:18.239319 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_19'\n",
      "W0414 21:44:18.240098 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_3'\n",
      "W0414 21:44:18.240203 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_5'\n",
      "W0414 21:44:18.240287 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_23'\n",
      "W0414 21:44:18.240368 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_6'\n",
      "W0414 21:44:18.240447 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_7'\n",
      "W0414 21:44:18.240527 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_22'\n",
      "W0414 21:44:18.240611 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_13'\n",
      "W0414 21:44:18.240690 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_9'\n",
      "W0414 21:44:18.240766 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_1'\n",
      "W0414 21:44:18.240856 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_24'\n",
      "W0414 21:44:18.240931 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_11'\n",
      "W0414 21:44:18.241005 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_12'\n",
      "W0414 21:44:18.241103 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_14'\n",
      "W0414 21:44:18.241180 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_8'\n",
      "W0414 21:44:18.241256 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_10'\n",
      "W0414 21:44:18.241332 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_4'\n",
      "W0414 21:44:18.241408 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_21'\n",
      "W0414 21:44:18.241499 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_20'\n",
      "W0414 21:44:18.241607 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_2'\n",
      "E0414 22:51:24.358670 140501210752768 directory_watcher.py:196] Unable to get size of /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/events.out.tfevents.1618407857.3b132921d8c9.27217.4724399.v2: /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/events.out.tfevents.1618407857.3b132921d8c9.27217.4724399.v2; No such file or directory\n",
      "E0414 22:51:24.359551 140501210752768 directory_watcher.py:196] Unable to get size of /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/pg_1/events.out.tfevents.1618408484.3b132921d8c9.27217.5198974.v2: /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/pg_1/events.out.tfevents.1618408484.3b132921d8c9.27217.5198974.v2; No such file or directory\n",
      "W0414 22:51:24.363090 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_19'\n",
      "W0414 22:51:24.363213 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_3'\n",
      "W0414 22:51:24.363306 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_23'\n",
      "W0414 22:51:24.363393 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_21'\n",
      "W0414 22:51:24.363479 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_5'\n",
      "W0414 22:51:24.363586 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_6'\n",
      "W0414 22:51:24.363674 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_22'\n",
      "W0414 22:51:24.363758 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_7'\n",
      "W0414 22:51:24.363854 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_15'\n",
      "W0414 22:51:24.363934 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_17'\n",
      "W0414 22:51:24.364013 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_9'\n",
      "W0414 22:51:24.364091 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_24'\n",
      "W0414 22:51:24.364169 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_8'\n",
      "W0414 22:51:24.364247 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_18'\n",
      "W0414 22:51:24.364324 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_10'\n",
      "W0414 22:51:24.364410 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_4'\n",
      "W0414 22:51:24.364488 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_16'\n",
      "W0414 22:51:24.364585 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_20'\n",
      "W0414 22:51:24.364666 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_2'\n",
      "E0415 08:23:44.370672 140501210752768 directory_watcher.py:196] Unable to get size of /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/events.out.tfevents.1618411880.3b132921d8c9.27217.7622637.v2: /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/events.out.tfevents.1618411880.3b132921d8c9.27217.7622637.v2; No such file or directory\n",
      "E0415 08:23:44.371941 140501210752768 directory_watcher.py:196] Unable to get size of /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/pg_1/events.out.tfevents.1618411882.3b132921d8c9.27217.7622652.v2: /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/pg_snps/pg_1/events.out.tfevents.1618411882.3b132921d8c9.27217.7622652.v2; No such file or directory\n",
      "W0415 08:23:44.375653 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_3'\n",
      "W0415 08:23:44.375781 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_13'\n",
      "W0415 08:23:44.375876 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_5'\n",
      "W0415 08:23:44.375972 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_6'\n",
      "W0415 08:23:44.376060 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_7'\n",
      "W0415 08:23:44.376145 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_19'\n",
      "W0415 08:23:44.376230 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_9'\n",
      "W0415 08:23:44.376331 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_15'\n",
      "W0415 08:23:44.376429 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_17'\n",
      "W0415 08:23:44.376555 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_11'\n",
      "W0415 08:23:44.376689 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_14'\n",
      "W0415 08:23:44.376773 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_12'\n",
      "W0415 08:23:44.376855 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_16'\n",
      "W0415 08:23:44.376937 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_8'\n",
      "W0415 08:23:44.377018 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_10'\n",
      "W0415 08:23:44.377099 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_18'\n",
      "W0415 08:23:44.377188 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_4'\n",
      "W0415 08:23:44.377270 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_20'\n",
      "W0415 08:23:44.377351 140501210752768 plugin_event_multiplexer.py:263] Deleting accumulator 'pg_2'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/tf/eipi10/jian-xu3/snps_classification/models/{}'.format('snps_18510_c8')\n",
    "logs_path = '{}/hpt/{}'.format(dataset_path, 'pg_snps')\n",
    "! tensorboard --logdir {logs_path} --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:34:34.463128Z",
     "start_time": "2021-04-15T04:37:17.439202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-15 12:37:19.343900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "TensorBoard 2.3.0 at http://3b132921d8c9:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir /tf/eipi10/jian-xu3/snps_classification/models/snps_18510_c8/hpt/snps_18510_c8_hpt_pg_snps_0413 --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:42:05.259610Z",
     "start_time": "2021-04-15T10:42:05.256347Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "dataset_name='snps_18510_c8'\n",
    "dataset_path='/tf/eipi10/jian.xu3/snps-classification/models/snps_18510_c8'\n",
    "path = '/home/grid/eipi10/jian.xu3/snps-classification/models/snps_18510_c8/abcde/eee.vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:44:01.036480Z",
     "start_time": "2021-04-15T10:44:01.032042Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_safe_file_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        index = path.index(dataset_name) + len(dataset_name) + 1\n",
    "        path = os.path.join(dataset_path, path[index:])\n",
    "        return path\n",
    "    else:\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:44:01.743483Z",
     "start_time": "2021-04-15T10:44:01.738945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/eipi10/jian.xu3/snps-classification/models/snps_18510_c8/abcde/eee.vector'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_safe_file_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:40:29.466290Z",
     "start_time": "2021-04-15T10:40:29.458965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.index('snps_18510_c8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:41:27.905640Z",
     "start_time": "2021-04-15T10:41:27.884283Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d4fdb27b8efe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "path.index(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T10:41:38.428152Z",
     "start_time": "2021-04-15T10:41:38.422047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/eipi10/jian.xu3/snps-classification/models/snps_18510_c8'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:13:06.930804Z",
     "start_time": "2021-04-20T09:13:04.581946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "\n",
    "hostname = 'https://hp.sharepoint.com'\n",
    "server_relative_path = '/teams/CSGITRPA/RPADev'\n",
    "input_folder = '/Shared Documents/snps_classification/input'\n",
    "site_url = hostname + server_relative_path\n",
    "\n",
    "document_client_id = 'c9a0e93c-8592-4bfd-b9c3-08cc93480ab2'\n",
    "document_client_secret = 'coL0KKIJUZBCQP9gDrThcr7V3xVl3kA4CZj2Be/cj7g=' \n",
    "\n",
    "credentials = ClientCredential(document_client_id, document_client_secret)\n",
    "document_client_context = ClientContext(site_url).with_credentials(credentials)\n",
    "\n",
    "folder = document_client_context.web.get_folder_by_server_relative_url(input_folder)\n",
    "\n",
    "document_client_context.load(folder)\n",
    "document_client_context.execute_query()\n",
    "\n",
    "print(len(folder.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T03:38:17.021722Z",
     "start_time": "2021-04-29T03:38:17.016673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m输出红色字符\u001b[0m\n",
      "\u001b[31m输出红色字符\u001b[0m\n",
      "\u001b[31m输出红色字符\n",
      "输出红色字符\n",
      "\u001b[31m输出红色字符\u001b[0m\n",
      "恢复默认输出\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[0;31m%s\\033[0m\" % \"输出红色字符\")     # 标准写法\n",
    "print(\"\\033[31m%s\\033[0m\" % \"输出红色字符\")       # 显示方式为0时，可以省略\n",
    "print(\"\\033[31m%s\" % \"输出红色字符\")\n",
    "print(\"输出红色字符\")                             # 由于上面没有结尾，继续按照上面的输出\n",
    "print(\"\\033[31m%s\\033[0m\" % \"输出红色字符\")\n",
    "print(\"恢复默认输出\")                             # 恢复默认输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T03:35:40.926642Z",
     "start_time": "2021-04-29T03:35:40.921072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m输出红色字符\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[0;31m%s\\033[0m\" % \"输出红色字符\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T03:43:32.394908Z",
     "start_time": "2021-04-29T03:43:32.386634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m你好麽，\u001b[1m我很好。\n",
      "\u001b[30;1m你好麽，\u001b[31;1m我很好。\n",
      "\u001b[32;1m你好麽，\u001b[1m我很好。\n",
      "\u001b[33;1m你好麽，\u001b[34;1m我很好。\n",
      "\u001b[35;1m你好麽，\u001b[36;1m我很好。\n",
      "\u001b[37;1m你好麽，\u001b[38;1m我很好。\n",
      "\u001b[41;1m你好麽，\u001b[0m我很好。\n",
      "\u001b[42;1m你好麽，\u001b[0m我很好。\n",
      "\u001b[43;1m你好麽，\u001b[0m我很好。\n",
      "\u001b[44;1m你好麽，\u001b[0m我很好。\n",
      "\u001b[45;1m你好麽，\u001b[0m我很好。\n",
      "\u001b[46;1m你好麽，\u001b[0m我很好。\n",
      "\u001b[47;1m你好麽，\u001b[0m我很好。\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[0m你好麽，\\033[1m我很好。\")\n",
    "print(\"\\033[30;1m你好麽，\\033[31;1m我很好。\")\n",
    "print(\"\\033[32;1m你好麽，\\033[1m我很好。\")\n",
    "print(\"\\033[33;1m你好麽，\\033[34;1m我很好。\")\n",
    "print(\"\\033[35;1m你好麽，\\033[36;1m我很好。\")\n",
    "print(\"\\033[37;1m你好麽，\\033[38;1m我很好。\")\n",
    "\n",
    "print(\"\\033[41;1m你好麽，\\033[0m我很好。\")\n",
    "print(\"\\033[42;1m你好麽，\\033[0m我很好。\")\n",
    "print(\"\\033[43;1m你好麽，\\033[0m我很好。\")\n",
    "print(\"\\033[44;1m你好麽，\\033[0m我很好。\")\n",
    "print(\"\\033[45;1m你好麽，\\033[0m我很好。\")\n",
    "print(\"\\033[46;1m你好麽，\\033[0m我很好。\")\n",
    "print(\"\\033[47;1m你好麽，\\033[0m我很好。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "154px",
    "width": "230px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T02:21:29.989910Z",
     "start_time": "2020-12-21T02:21:27.619248Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T02:21:29.994898Z",
     "start_time": "2020-12-21T02:21:29.992469Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# base_path = '/tf/eipi10/qbz95'\n",
    "# sys.path.append(base_path)\n",
    "\n",
    "# from qbz95 import config\n",
    "# import pandas as pd\n",
    "# config = config.get_config('jupyter')\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# # 代码自动重新加载\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# # #当module有新的方法的时候，需要运行下面方法。\n",
    "# # %reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T02:35:46.253743Z",
     "start_time": "2020-12-21T02:35:46.113398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,136,394\n",
      "Trainable params: 2,136,266\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers, optimizers, losses\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    ")\n",
    "\n",
    "def get_block(x, filters, conv_count, kernel_size=(3, 3), padding='same', use_bn=True, \n",
    "              use_dropout=True, drop_out_rate=0.3):\n",
    "    for i in range(conv_count):\n",
    "        x = layers.Conv2D(filters, kernel_size, padding=padding, activation='relu')(x)\n",
    "    if use_bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    if use_dropout: x = layers.Dropout(drop_out_rate)(x)\n",
    "    return x    \n",
    "\n",
    "def get_model(input_shape, learning_rate=0.001, use_bn=True, use_dropout=True, drop_out_rate=0.3):   \n",
    "    input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = get_block(input, 64, conv_count=2, use_bn=use_bn, use_dropout=use_dropout, drop_out_rate=drop_out_rate)\n",
    "        \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    if use_dropout: x = layers.Dropout(drop_out_rate)(x)  \n",
    " \n",
    "    x = layers.Dense(10)(x)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=x, name='vgg') \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])      \n",
    "    model.checkpoint_path = './checkpoints/{}/checkpoint'.format(model.name)\n",
    "    return model   \n",
    "\n",
    "# 创建模型\n",
    "use_bn = True\n",
    "use_dropout = True\n",
    "drop_out_rate = 0.3\n",
    "model = get_model((32, 32, 1), use_bn=use_bn, use_dropout=use_dropout, drop_out_rate=drop_out_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T02:38:51.986232Z",
     "start_time": "2020-12-21T02:38:51.961790Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Model Name:  vgg\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "total_weights: 2136394\n",
      "trainable_weights: 2136266\n",
      "non_trainable_weights: 128\n",
      "========================================================================================================================\n",
      "InputLayer(input_shape=[(None, 32, 32, 1)], batch_size=None)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Conv2D(filters=64, kernel_size=(3, 3), padding=same, activation=relu, output_shape=(None, 32, 32, 64),\n",
      "       trainable_weights=640, non_trainable_weights=0)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Conv2D(filters=64, kernel_size=(3, 3), padding=same, activation=relu, output_shape=(None, 32, 32, 64),\n",
      "       trainable_weights=36928, non_trainable_weights=0)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "BatchNormalization(axis=ListWrapper([3]), momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
      "                   trainable_weights=128, non_trainable_weights=128)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MaxPooling2D(pool_size=(2, 2), padding=(2, 2), output_shape=valid)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dropout(rate=0.3, noise_shape=None, output_shape=(None, 16, 16, 64))\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Flatten(output_shape=(None, 16384))\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dense(units=128, activation=relu, output_shape=(None, 128), trainable_weights=2097280, non_trainable_weights=0)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dropout(rate=0.3, noise_shape=None, output_shape=(None, 128))\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dense(units=10, activation=linear, output_shape=(None, 10), trainable_weights=1290, non_trainable_weights=0)\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_weight_num(obj, trainable=True):\n",
    "    '''得到模型可训练参数的个数'''\n",
    "    if trainable:\n",
    "        return int(np.sum([np.prod(p.shape) for p in obj.trainable_weights]))\n",
    "    else:\n",
    "        return int(np.sum([np.prod(p.shape) for p in obj.non_trainable_weights]))\n",
    "\n",
    "def show_model(model):\n",
    "    print('='*120)\n",
    "    if model.name is not None:\n",
    "        print('Model Name: ', model.name)       \n",
    "        print('-'*120)\n",
    "    trainable_weights =  get_weight_num(model)   \n",
    "    non_trainable_weights =  get_weight_num(model, False)  \n",
    "    total_weights = trainable_weights + non_trainable_weights\n",
    "    print('total_weights: {}'.format(total_weights))\n",
    "    print('trainable_weights: {}'.format(trainable_weights))\n",
    "    print('non_trainable_weights: {}'.format(non_trainable_weights))  \n",
    "    print('='*120)\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if i>0: print('-'*120) \n",
    "        if isinstance(layer, tf.python.keras.layers.convolutional.Conv2D):\n",
    "            print(\"Conv2D(filters={}, kernel_size={}, padding={}, activation={}, output_shape={},\\n       trainable_weights={}, non_trainable_weights={})\".format(\n",
    "                layer.filters, layer.kernel_size, layer.padding, layer.activation.__name__, layer.output.shape, get_weight_num(layer), get_weight_num(layer, False)))\n",
    "        elif isinstance(layer, tf.python.keras.engine.input_layer.InputLayer):\n",
    "            print(\"InputLayer(input_shape={}, batch_size={})\".format(\n",
    "                layer.input_shape, layer.batch_size))  \n",
    "        elif isinstance(layer, tf.python.keras.layers.pooling.MaxPooling2D):\n",
    "            print(\"MaxPooling2D(pool_size={}, padding={}, output_shape={})\".format(\n",
    "                layer.pool_size, layer.strides, layer.padding, layer.output.shape)) \n",
    "        elif isinstance(layer, tf.python.keras.layers.core.Dense):\n",
    "            print(\"Dense(units={}, activation={}, output_shape={}, trainable_weights={}, non_trainable_weights={})\".format(\n",
    "                layer.units, layer.activation.__name__, layer.output.shape, get_weight_num(layer), get_weight_num(layer, False)))  \n",
    "        elif isinstance(layer, tf.python.keras.layers.core.Flatten):\n",
    "            print(\"Flatten(output_shape={})\".format(layer.output.shape))        \n",
    "        elif isinstance(layer, tf.python.keras.layers.core.Dropout ):\n",
    "            print(\"Dropout(rate={}, noise_shape={}, output_shape={})\".format(layer.rate, layer.noise_shape, layer.output.shape))     \n",
    "        elif isinstance(layer, tf.python.keras.layers.normalization_v2.BatchNormalization ):\n",
    "            print(\"BatchNormalization(axis={}, momentum={}, epsilon={}, center={}, scale={},\\n                   trainable_weights={}, non_trainable_weights={})\".format(\n",
    "                layer.axis, layer.momentum, layer.epsilon, layer.center, layer.scale, get_weight_num(layer), get_weight_num(layer, False)))            \n",
    "        else:\n",
    "            print(layer)           \n",
    "    print('='*120)   \n",
    "show_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T02:21:30.758211Z",
     "start_time": "2020-12-21T02:21:30.751130Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,136,394\n",
      "Trainable params: 2,136,266\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:48:08.203728Z",
     "start_time": "2020-12-21T09:48:08.147602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= reshuffle_each_iteration=True =========================\n",
      "------------------------- first -------------------------\n",
      "train_dataset: [6 4 8 7 5]\n",
      "val_dataset: [6 5 4 7 1]\n",
      "------------------------- second -------------------------\n",
      "train_dataset: [8 3 2 1 9]\n",
      "val_dataset: [6 3 7 8 2]\n",
      "========================= reshuffle_each_iteration=False =========================\n",
      "------------------------- first -------------------------\n",
      "train_dataset: [8 4 5 9 2]\n",
      "val_dataset: [ 7 10  1  3  6]\n",
      "------------------------- second -------------------------\n",
      "train_dataset: [5 2 8 4 9]\n",
      "val_dataset: [ 1  3  6 10  7]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "train_data=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "def test_reshuffle_each_iteration(reshuffle_each_iteration):\n",
    "    print('='*25, 'reshuffle_each_iteration={}'.format(reshuffle_each_iteration), '='*25)   \n",
    "    train_val_dataset = tf.data.Dataset.from_tensor_slices(train_data) \n",
    "    train_val_dataset = train_val_dataset.shuffle(100, reshuffle_each_iteration = reshuffle_each_iteration)\n",
    "\n",
    "    train_size = int(0.5*train_data.shape[0])\n",
    "    train_dataset = train_val_dataset.take(train_size).shuffle(100, reshuffle_each_iteration = True).batch(5) \n",
    "    val_dataset = train_val_dataset.skip(train_size).shuffle(100, reshuffle_each_iteration = True).batch(5) \n",
    "\n",
    "    print('-'*25, 'first', '-'*25) \n",
    "    for data in train_dataset:\n",
    "        print('train_dataset:', data.numpy())\n",
    "       \n",
    "    for data in val_dataset:\n",
    "        print('val_dataset:', data.numpy())    \n",
    "\n",
    "    print('-'*25, 'second', '-'*25)     \n",
    "    for data in train_dataset:\n",
    "        print('train_dataset:', data.numpy())\n",
    "\n",
    "    for data in val_dataset:\n",
    "        print('val_dataset:', data.numpy())      \n",
    "\n",
    "test_reshuffle_each_iteration(True)\n",
    "\n",
    "test_reshuffle_each_iteration(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T03:29:26.814270Z",
     "start_time": "2020-12-22T03:29:26.770117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "显示目录树\n",
      "tmp\n",
      "├──file01.txt\n",
      "├──file02.txt\n",
      "├──folder1\n",
      "│   └──file11.txt\n",
      "├──folder2\n",
      "│   ├──file21.txt\n",
      "│   └──file22.txt\n",
      "└──folder3\n",
      "    ├──folder30\n",
      "    │   ├──file301.txt\n",
      "    │   └──file302.txt\n",
      "    ├──file31.txt\n",
      "    ├──file32.txt\n",
      "    ├──file33.txt\n",
      "    └──folder34\n",
      "        ├──file341.txt\n",
      "        └──file342.txt\n",
      "--------------------------------------------------\n",
      "显示最多11个文件或目录\n",
      "tmp\n",
      "├──file01.txt\n",
      "├──file02.txt\n",
      "├──folder1\n",
      "│   └──file11.txt\n",
      "├──folder2\n",
      "│   ├──file21.txt\n",
      "│   └──file22.txt\n",
      "└──folder3\n",
      "    ├──folder30\n",
      "    │   ├──file301.txt\n",
      "--------------------------------------------------\n",
      "删除一个目录和一个文件\n",
      "tmp\n",
      "├──file01.txt\n",
      "├──file02.txt\n",
      "├──folder1\n",
      "│   └──file11.txt\n",
      "└──folder3\n",
      "    ├──folder30\n",
      "    │   ├──file301.txt\n",
      "    │   └──file302.txt\n",
      "    ├──file31.txt\n",
      "    ├──file33.txt\n",
      "    └──folder34\n",
      "        ├──file341.txt\n",
      "        └──file342.txt\n",
      "--------------------------------------------------\n",
      "显示两层目录树\n",
      "tmp\n",
      "├──file01.txt\n",
      "├──file02.txt\n",
      "├──folder1\n",
      "│   └──file11.txt\n",
      "└──folder3\n",
      "    ├──folder30\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def show_tree(path, max_depth=10, max_num=100):\n",
    "    def _show_tree(path, depth, max_num, prefix):\n",
    "        if max_num<=0 or depth>max_depth:\n",
    "            return max_num\n",
    "        if depth==1: \n",
    "            print(path)\n",
    "            max_num=max_num-1\n",
    "        items = os.listdir(path)\n",
    "        for i, item in enumerate(items):\n",
    "            if max_num<=0: return max_num\n",
    "            newitem = path +'/'+ item\n",
    "            if i==len(items)-1:\n",
    "                print(prefix  + \"└──\" + item)            \n",
    "                new_prefix = prefix+\"    \"                \n",
    "            else:\n",
    "                print(prefix  + \"├──\" + item)\n",
    "                new_prefix = prefix+\"│   \"\n",
    "            max_num=max_num-1\n",
    "            if os.path.isdir(newitem):\n",
    "                max_num = _show_tree(newitem, depth=depth+1, max_num=max_num, prefix=new_prefix)         \n",
    "        return max_num\n",
    "    _show_tree(path, depth=1, max_num=max_num, prefix=\"\")\n",
    "        \n",
    "def create_file(file_path):\n",
    "    file = open(file_path,'a')\n",
    "    file.write(file_path)\n",
    "    file.close()\n",
    "                                \n",
    "def prepare(base_path):\n",
    "    \n",
    "    if os.path.exists(base_path):\n",
    "        shutil.rmtree(base_path)\n",
    "    os.makedirs(base_path)\n",
    "    create_file(os.path.join(base_path, \"file01.txt\"))\n",
    "    create_file(os.path.join(base_path, \"file02.txt\"))\n",
    "    \n",
    "    folder1 = os.path.join(base_path, \"folder1\")\n",
    "    folder2 = os.path.join(base_path, \"folder2\")\n",
    "    folder3 = os.path.join(base_path, \"folder3\")\n",
    "    \n",
    "    os.makedirs(folder1)\n",
    "    os.makedirs(folder2)\n",
    "    os.makedirs(folder3)\n",
    "    \n",
    "    create_file(os.path.join(folder1, \"file11.txt\"))\n",
    "    \n",
    "    create_file(os.path.join(folder2, \"file21.txt\"))\n",
    "    create_file(os.path.join(folder2, \"file22.txt\"))    \n",
    "    \n",
    "    folder30 = os.path.join(folder3, \"folder30\")\n",
    "    os.makedirs(folder30)\n",
    "    \n",
    "    create_file(os.path.join(folder30, \"file301.txt\"))      \n",
    "    create_file(os.path.join(folder30, \"file302.txt\"))     \n",
    "    \n",
    "    create_file(os.path.join(folder3, \"file31.txt\"))\n",
    "    create_file(os.path.join(folder3, \"file32.txt\"))      \n",
    "    create_file(os.path.join(folder3, \"file33.txt\")) \n",
    "    \n",
    "    folder34 = os.path.join(folder3, \"folder34\")\n",
    "    os.makedirs(folder34)\n",
    "    \n",
    "    create_file(os.path.join(folder34, \"file341.txt\"))      \n",
    "    create_file(os.path.join(folder34, \"file342.txt\"))     \n",
    "\n",
    "    \n",
    "base_path = 'tmp'   \n",
    "prepare(base_path)\n",
    "\n",
    "print('-'*50)\n",
    "print('显示目录树')\n",
    "show_tree(base_path) \n",
    "\n",
    "print('-'*50)\n",
    "print('显示最多11个文件或目录')\n",
    "show_tree(base_path, max_num=11)\n",
    "\n",
    "print('-'*50)\n",
    "print('删除一个目录和一个文件')\n",
    "shutil.rmtree(os.path.join(base_path, \"folder2\"))\n",
    "os.remove(os.path.join(base_path, \"folder3/file32.txt\"))\n",
    "show_tree(base_path) \n",
    "\n",
    "print('-'*50)\n",
    "print('显示两层目录树')\n",
    "show_tree(base_path, max_depth=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

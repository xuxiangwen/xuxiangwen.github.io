{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f343c65",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daf2d84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:30:25.753967Z",
     "start_time": "2022-08-10T10:30:22.076852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf \n",
    "\n",
    "from pprint import pprint \n",
    "from datasets import load_dataset, load_metric, Audio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from transformers import AutoTokenizer \n",
    "from transformers import AutoFeatureExtractor\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "from transformers import TFAutoModel\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab667bdc",
   "metadata": {},
   "source": [
    "# Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e1d086",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "https://huggingface.co/docs/transformers/installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81b8114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T05:48:01.749831Z",
     "start_time": "2022-08-10T05:48:01.655312Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "libavutil      56. 31.100 / 56. 31.100\n",
      "libavcodec     58. 54.100 / 58. 54.100\n",
      "libavformat    58. 29.100 / 58. 29.100\n",
      "libavdevice    58.  8.100 / 58.  8.100\n",
      "libavfilter     7. 57.100 /  7. 57.100\n",
      "libavresample   4.  0.  0 /  4.  0.  0\n",
      "libswscale      5.  5.100 /  5.  5.100\n",
      "libswresample   3.  5.100 /  3.  5.100\n",
      "libpostproc    55.  5.100 / 55.  5.100\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#apt update\n",
    "# pip install -U pip\n",
    "#pip install -U transformers\n",
    "#pip install -U torch\n",
    "#pip install -U torchvision \n",
    "#pip install -U tensorflow\n",
    "#pip install -U datasets \n",
    "\n",
    "#apt-get install -y libsndfile1\n",
    "#pip install -U soundfile\n",
    "#pip install -U librosa\n",
    "\n",
    "# apt install -y ffmpeg\n",
    "ffmpeg -version \n",
    "# ffmpeg -encoders\n",
    "# ffmpeg -decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16130dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.529Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "2022-08-10 05:48:07.484559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7368 MB memory:  -> device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74773733",
   "metadata": {},
   "source": [
    "## Quick tour\n",
    "\n",
    "https://huggingface.co/docs/transformers/quicktour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02900d3",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b6809",
   "metadata": {},
   "source": [
    "#### Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4b0f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"We are very happy to show you the 🤗 Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880bb49",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.533Z"
    }
   },
   "outputs": [],
   "source": [
    "results = classifier([\"We are very happy to show you the 🤗 Transformers library.\", \n",
    "                      \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea9ac0",
   "metadata": {},
   "source": [
    "#### Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ecc3a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.535Z"
    }
   },
   "outputs": [],
   "source": [
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731314c0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.537Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18947a95",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.538Z"
    }
   },
   "outputs": [],
   "source": [
    "print(speech_recognizer.feature_extractor.sampling_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab36c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.539Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae843d66",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.541Z"
    }
   },
   "outputs": [],
   "source": [
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cb6588",
   "metadata": {},
   "source": [
    "#### Use another model and tokenizer in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936263af",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.542Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 会报错\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68fe50",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.544Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb0478",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.545Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier([\"你们的服务实在太差了\", \"爱死你们了\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bad3e",
   "metadata": {},
   "source": [
    "### AutoClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc6ed8",
   "metadata": {},
   "source": [
    "#### AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3895a82",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.547Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4797a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.549Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer(\"台湾是中国不可分割的领土\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f971e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.550Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "print(type(pt_batch)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d63d86",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.552Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"tf\",\n",
    ")\n",
    "\n",
    "print(type(tf_batch)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba01c9a",
   "metadata": {},
   "source": [
    "#### AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a4114",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.553Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e681d46",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.555Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_outputs = pt_model(**pt_batch)\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51deca9b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.556Z"
    }
   },
   "outputs": [],
   "source": [
    "# 会报错\n",
    "# model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "# tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# tf_outputs = tf_model(tf_batch)\n",
    "# tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n",
    "# tf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a34ee",
   "metadata": {},
   "source": [
    "### Save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e2652",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.557Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89213228",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.559Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf_save_directory = \"./tf_save_pretrained\"\n",
    "# tokenizer.save_pretrained(tf_save_directory)\n",
    "# tf_model.save_pretrained(tf_save_directory)\n",
    "# tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b62f86",
   "metadata": {},
   "source": [
    "### Custom model builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbb3c0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.560Z"
    }
   },
   "outputs": [],
   "source": [
    "my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)\n",
    "my_model = AutoModel.from_config(my_config)\n",
    "my_model = TFAutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa0857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T13:29:15.091890Z",
     "start_time": "2022-08-08T13:29:15.088658Z"
    }
   },
   "source": [
    "# Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298bc86a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T13:29:38.832219Z",
     "start_time": "2022-08-08T13:29:38.829785Z"
    }
   },
   "source": [
    "## Pipelines for inference\n",
    "\n",
    "https://huggingface.co/docs/transformers/pipeline_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111580e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T14:00:00.156310Z",
     "start_time": "2022-08-08T14:00:00.153572Z"
    }
   },
   "source": [
    "### Pipeline usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cc58c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.563Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = pipeline(task=\"text-generation\")\n",
    "generator(\n",
    "    \"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone\"\n",
    ")  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbe5c5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.564Z"
    }
   },
   "outputs": [],
   "source": [
    "generator(\n",
    "    [\n",
    "        \"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone\",\n",
    "        \"Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee73b6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.565Z"
    }
   },
   "outputs": [],
   "source": [
    "generator(\n",
    "    \"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone\",\n",
    "    num_return_sequences=2,\n",
    ")  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb9a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T13:59:22.970714Z",
     "start_time": "2022-08-08T13:59:22.966197Z"
    }
   },
   "source": [
    "#### Choose a model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fb3ce",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.567Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a353a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.568Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "generator(\n",
    "    \"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0b88e",
   "metadata": {},
   "source": [
    "### Audio pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99d54f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.570Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "audio_file = ds[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d37b37",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.571Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_classifier = pipeline(\n",
    "    task=\"audio-classification\", model=\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05413d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.573Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = audio_classifier(audio_file)\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0d6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T14:04:31.155768Z",
     "start_time": "2022-08-08T14:03:32.210Z"
    }
   },
   "source": [
    "### Vision pipeline\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f563836",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.575Z"
    }
   },
   "outputs": [],
   "source": [
    "vision_classifier = pipeline(task=\"image-classification\")\n",
    "preds = vision_classifier(\n",
    "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450a9c2",
   "metadata": {},
   "source": [
    "## Load pretrained instances with an AutoClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cb783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T01:28:21.337350Z",
     "start_time": "2022-08-09T01:28:21.333326Z"
    }
   },
   "source": [
    "### AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd881606",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.577Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fef5e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.578Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence = \"Let's try to tokenize!\"\n",
    "print('-'*50)\n",
    "tokens = tokenizer(sequence)\n",
    "print(tokens, type(tokens)) \n",
    "\n",
    "print(tokenizer.decode(tokens.input_ids)) \n",
    "\n",
    "# 下面input_ids内容好像不对\n",
    "print('-'*50)\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(input_ids, type(input_ids)) \n",
    "\n",
    "print('-'*50)\n",
    "final_inputs = tokenizer.prepare_for_model(input_ids)\n",
    "print(final_inputs, type(final_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50607b8",
   "metadata": {},
   "source": [
    "### AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291814d4",
   "metadata": {},
   "source": [
    "For audio and vision tasks, a feature extractor processes the audio signal or image into the correct input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f4a36",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.580Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6f484",
   "metadata": {},
   "source": [
    "### AutoProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9236a",
   "metadata": {},
   "source": [
    "Multimodal tasks require a processor that combines two types of preprocessing tools. For example, the LayoutLMV2 model requires a feature extractor to handle images and a tokenizer to handle text; a processor combines both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f855c4c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.582Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d4687",
   "metadata": {},
   "source": [
    "### AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3e285",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.583Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882385d6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.585Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a183e11",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.586Z"
    }
   },
   "outputs": [],
   "source": [
    "# 报错\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "# model = TFAutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f0eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T01:37:33.840911Z",
     "start_time": "2022-08-09T01:37:30.839817Z"
    }
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371e8e8",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223e50d",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ec438",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c9224",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.588Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb91777",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.590Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "pprint(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d6f80",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.591Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af977e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.592Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "pprint(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9886e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:01:55.857718Z",
     "start_time": "2022-08-09T02:01:55.854116Z"
    }
   },
   "source": [
    "#### Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5574541",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.594Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True)\n",
    "pprint(encoded_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7039c",
   "metadata": {},
   "source": [
    "#### Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ee16b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.596Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
    "pprint(encoded_input) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01583c4",
   "metadata": {},
   "source": [
    "#### Build tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eeae18",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.598Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_input, type(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7f7ec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.599Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\", \n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(encoded_input, type(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566a3ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:05:17.424429Z",
     "start_time": "2022-08-09T02:05:17.421959Z"
    }
   },
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a9b3f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.601Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a0250",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.602Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cc402",
   "metadata": {},
   "source": [
    "- array is the speech signal loaded - and potentially resampled - as a 1D array.\n",
    "- path points to the location of the audio file.\n",
    "- sampling_rate refers to how many data points in the speech signal are measured per second. 采样率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf2031",
   "metadata": {},
   "source": [
    "#### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e6771",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.604Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd234f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.605Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29400e30",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.607Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eca35b",
   "metadata": {},
   "source": [
    "#### Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45da42",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.608Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbeb41",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.610Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_input = [dataset[0][\"audio\"][\"array\"], dataset[1][\"audio\"][\"array\"]]\n",
    "feature_extractor(audio_input, sampling_rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788691e4",
   "metadata": {},
   "source": [
    "#### Pad and truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5ef20",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.611Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset[0][\"audio\"][\"array\"].shape, dataset[1][\"audio\"][\"array\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d262ea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.612Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        max_length=100000,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c5888",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.614Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_dataset = preprocess_function(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8ac88",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.615Z"
    }
   },
   "outputs": [],
   "source": [
    "print(processed_dataset[\"input_values\"][0].shape, processed_dataset[\"input_values\"][0].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e089f6b",
   "metadata": {},
   "source": [
    "### Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf5ee2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.617Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"food101\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf533a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.618Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59363331",
   "metadata": {},
   "source": [
    "#### Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2253ab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.619Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b9007",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84571db4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.621Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Normalize, RandomResizedCrop, ColorJitter, ToTensor\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_transforms = Compose(\n",
    "    [RandomResizedCrop(feature_extractor.size), ColorJitter(brightness=0.5, hue=0.5), ToTensor(), normalize]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d47e11",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.622Z"
    }
   },
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2fe84",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.623Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d154e2f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.625Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113826fb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.626Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = dataset[0][\"pixel_values\"] \n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae9014",
   "metadata": {},
   "source": [
    "### Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390e705",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.628Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lj_speech = load_dataset(\"lj_speech\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ac04c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.629Z"
    }
   },
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])\n",
    "print(lj_speech[0][\"audio\"])\n",
    "print(lj_speech[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7378f3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.630Z"
    }
   },
   "outputs": [],
   "source": [
    "lj_speech = lj_speech.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcacb81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:44:27.542004Z",
     "start_time": "2022-08-09T02:44:27.538590Z"
    }
   },
   "source": [
    "#### Processor\n",
    "A processor combines a feature extractor and tokenizer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c2d99",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.631Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b481319",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.633Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example[\"input_values\"] = processor(audio[\"array\"], sampling_rate=16000)\n",
    "\n",
    "    with processor.as_target_processor():\n",
    "        example[\"labels\"] = processor(example[\"text\"]).input_ids\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64116794",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.634Z"
    }
   },
   "outputs": [],
   "source": [
    "prepare_dataset(lj_speech[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf456eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T03:30:30.194180Z",
     "start_time": "2022-08-09T03:30:30.190479Z"
    }
   },
   "source": [
    "## Fine-tune a pretrained model\n",
    "https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0994870",
   "metadata": {},
   "source": [
    "### Prepare a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d851d1d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:30:54.242136Z",
     "start_time": "2022-08-10T10:30:50.936641Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_review_full (/root/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8280b1c9ef004d50846716f63956b317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc8de38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:31:05.919184Z",
     "start_time": "2022-08-10T10:30:54.244927Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb604d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:01.072156Z",
     "start_time": "2022-08-10T10:31:05.922978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_function at 0x7ffabdcfeca0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f71eb3947494de7a0b49e3a305d8926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f7036517664ea2af71443d4641e8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True) \n",
    " \n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14069cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:01.230494Z",
     "start_time": "2022-08-10T10:34:01.075332Z"
    }
   },
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625ff33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T04:12:11.425021Z",
     "start_time": "2022-08-09T04:12:11.420989Z"
    }
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a8db4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.642Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eeac2a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.643Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ea951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T04:57:36.923224Z",
     "start_time": "2022-08-10T04:57:36.920050Z"
    }
   },
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af0dad",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.645Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f968e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.646Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cff8f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.647Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23558019",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0723ce7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.648Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff20119",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.650Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80845ea4",
   "metadata": {},
   "source": [
    "#### Convert dataset to TensorFlow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80caecc6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.651Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644793c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.652Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = small_train_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "tf_validation_dataset = small_eval_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f32bc",
   "metadata": {},
   "source": [
    "#### Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c7aac",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.654Z"
    }
   },
   "outputs": [],
   "source": [
    "# 报错\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8fb55",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.655Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85112ebe",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T05:47:57.657Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61c7d7",
   "metadata": {},
   "source": [
    "### Train in native PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1cb54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:30:30.222585Z",
     "start_time": "2022-08-10T10:30:30.218059Z"
    }
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "# del pytorch_model\n",
    "# del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c07431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:01.393266Z",
     "start_time": "2022-08-10T10:34:01.233035Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868144b1",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5f2b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:01.400035Z",
     "start_time": "2022-08-10T10:34:01.396728Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8ea069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:06.092964Z",
     "start_time": "2022-08-10T10:34:01.403926Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bcddf",
   "metadata": {},
   "source": [
    "#### Optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74188002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:06.099865Z",
     "start_time": "2022-08-10T10:34:06.095895Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e69f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:06.108034Z",
     "start_time": "2022-08-10T10:34:06.102304Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f27afbdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:34:08.437981Z",
     "start_time": "2022-08-10T10:34:06.110611Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b5769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:25:15.471058Z",
     "start_time": "2022-08-10T10:25:15.466794Z"
    }
   },
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ebca54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:38:05.613048Z",
     "start_time": "2022-08-10T10:34:08.441513Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53dddb84d4145ffafed3e85c9b13391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7159ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:49:37.279719Z",
     "start_time": "2022-08-10T10:49:09.208327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.578}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34dc413",
   "metadata": {},
   "source": [
    "### Additional resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d48b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T10:50:26.554564Z",
     "start_time": "2022-08-10T10:50:26.548936Z"
    }
   },
   "source": [
    "- [Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples) includes scripts to train common NLP tasks in PyTorch and TensorFlow.\n",
    "\n",
    "- [Transformers Notebooks](https://huggingface.co/docs/transformers/notebooks) contains various notebooks on how to fine-tune a model for specific tasks in PyTorch and TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4589b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

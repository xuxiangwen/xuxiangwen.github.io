{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541eb2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:05.623421Z",
     "iopub.status.busy": "2024-05-09T03:49:05.622421Z",
     "iopub.status.idle": "2024-05-09T03:49:05.627433Z",
     "shell.execute_reply": "2024-05-09T03:49:05.627433Z",
     "shell.execute_reply.started": "2024-05-09T03:49:05.623421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:06.082503Z",
     "iopub.status.busy": "2024-05-09T03:49:06.082503Z",
     "iopub.status.idle": "2024-05-09T03:49:06.140017Z",
     "shell.execute_reply": "2024-05-09T03:49:06.139021Z",
     "shell.execute_reply.started": "2024-05-09T03:49:06.082503Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIANFAN_AK=HCCPsQy5p0Ex1rSEL6oorGQb\n",
      "QIANFAN_SK=TCVRfPCfbtLr0eDPZRXcywMxcgaNuLDE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.embeddings import QianfanEmbeddingsEndpoint\n",
    "from langchain.chat_models import QianfanChatEndpoint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "print(f\"QIANFAN_AK={os.environ['QIANFAN_AK']}\")\n",
    "print(f\"QIANFAN_SK={os.environ['QIANFAN_SK']}\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b61a3-92eb-4891-90ee-1d10607b05ad",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4336d784-65c2-4a11-8489-b445b1fad177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:07.747973Z",
     "iopub.status.busy": "2024-05-09T03:49:07.747973Z",
     "iopub.status.idle": "2024-05-09T03:49:07.755982Z",
     "shell.execute_reply": "2024-05-09T03:49:07.755982Z",
     "shell.execute_reply.started": "2024-05-09T03:49:07.747973Z"
    }
   },
   "outputs": [],
   "source": [
    "# # account for deprecation of LLM model\n",
    "# import datetime\n",
    "# # Get the current date\n",
    "# current_date = datetime.datetime.now().date()\n",
    "\n",
    "# # Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "# target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# # Set the model variable based on the current date\n",
    "# if current_date > target_date:\n",
    "#     llm_model = \"gpt-3.5-turbo\"\n",
    "# else:\n",
    "#     llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84e441b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:08.260989Z",
     "iopub.status.busy": "2024-05-09T03:49:08.259989Z",
     "iopub.status.idle": "2024-05-09T03:49:08.270988Z",
     "shell.execute_reply": "2024-05-09T03:49:08.269989Z",
     "shell.execute_reply.started": "2024-05-09T03:49:08.260989Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:08.702056Z",
     "iopub.status.busy": "2024-05-09T03:49:08.702056Z",
     "iopub.status.idle": "2024-05-09T03:49:09.720135Z",
     "shell.execute_reply": "2024-05-09T03:49:09.719139Z",
     "shell.execute_reply.started": "2024-05-09T03:49:08.702056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a09c35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:09.722133Z",
     "iopub.status.busy": "2024-05-09T03:49:09.722133Z",
     "iopub.status.idle": "2024-05-09T03:49:09.752131Z",
     "shell.execute_reply": "2024-05-09T03:49:09.751139Z",
     "shell.execute_reply.started": "2024-05-09T03:49:09.722133Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92dff22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:12.491176Z",
     "iopub.status.busy": "2024-05-09T03:49:12.491176Z",
     "iopub.status.idle": "2024-05-09T03:49:12.509392Z",
     "shell.execute_reply": "2024-05-09T03:49:12.508392Z",
     "shell.execute_reply.started": "2024-05-09T03:49:12.491176Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "943237a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:13.157359Z",
     "iopub.status.busy": "2024-05-09T03:49:13.157359Z",
     "iopub.status.idle": "2024-05-09T03:49:13.831685Z",
     "shell.execute_reply": "2024-05-09T03:49:13.830668Z",
     "shell.execute_reply.started": "2024-05-09T03:49:13.157359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-Bot-4\", temperature = 0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdcdb42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:27.086871Z",
     "iopub.status.busy": "2024-05-09T03:49:27.085840Z",
     "iopub.status.idle": "2024-05-09T03:49:27.102845Z",
     "shell.execute_reply": "2024-05-09T03:49:27.101848Z",
     "shell.execute_reply.started": "2024-05-09T03:49:27.086871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7abc20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:28.140074Z",
     "iopub.status.busy": "2024-05-09T03:49:28.140074Z",
     "iopub.status.idle": "2024-05-09T03:49:28.253804Z",
     "shell.execute_reply": "2024-05-09T03:49:28.252890Z",
     "shell.execute_reply.started": "2024-05-09T03:49:28.140074Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad44d1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:49:38.600430Z",
     "iopub.status.busy": "2024-05-09T03:49:38.599441Z",
     "iopub.status.idle": "2024-05-09T03:50:07.697338Z",
     "shell.execute_reply": "2024-05-09T03:50:07.696336Z",
     "shell.execute_reply.started": "2024-05-09T03:49:38.600430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-09 11:49:38] oauth.py:222 [t:32800]: trying to refresh access_token for ak `HCCPsQ***`\n",
      "[INFO] [05-09 11:49:40] oauth.py:237 [t:32800]: sucessfully refresh access_token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Choosing a name for a company that manufactures Queen Size Sheet Sets depends on various factors, including the brand's image, target audience, and market positioning. Here are some suggestions that might help:\\n\\n1. **Luxury Linens Co.**: This name suggests a high-end, luxurious product, which could be appealing to customers looking for quality sheets.\\n2. **Queen's Comfort Bedding**: Directly references the product (Queen Size Sheets) while also suggesting comfort and royalty, which are desirable qualities in bedding.\\n3. **Elegant Sleep Solutions**: This name implies that the sheets are not just a product but a solution for a better sleep experience, emphasizing elegance.\\n4. **Boutique Bedding Co.**: Suggests a more personalized or unique approach to bedding, which could attract customers looking for something different.\\n5. **Royal Rest Sheets**: Combines the idea of royalty (fitting for Queen Size) with restful sleep, creating a positive association.\\n\\nRemember, the best name for your company will be one that resonates with your target audience and accurately reflects your brand's values and mission. It's also important to ensure that the name you choose is not already trademarked or in use by another company in your industry.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "febee243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:50:24.826098Z",
     "iopub.status.busy": "2024-05-09T03:50:24.826098Z",
     "iopub.status.idle": "2024-05-09T03:50:24.850118Z",
     "shell.execute_reply": "2024-05-09T03:50:24.849109Z",
     "shell.execute_reply.started": "2024-05-09T03:50:24.826098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f31aa8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:50:25.320439Z",
     "iopub.status.busy": "2024-05-09T03:50:25.320439Z",
     "iopub.status.idle": "2024-05-09T03:50:25.340438Z",
     "shell.execute_reply": "2024-05-09T03:50:25.339438Z",
     "shell.execute_reply.started": "2024-05-09T03:50:25.320439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-Bot-4\", temperature = 0.9) \n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f5d5b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:50:27.454678Z",
     "iopub.status.busy": "2024-05-09T03:50:27.454678Z",
     "iopub.status.idle": "2024-05-09T03:50:27.463686Z",
     "shell.execute_reply": "2024-05-09T03:50:27.462687Z",
     "shell.execute_reply.started": "2024-05-09T03:50:27.454678Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c1eb2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:50:31.797867Z",
     "iopub.status.busy": "2024-05-09T03:50:31.797867Z",
     "iopub.status.idle": "2024-05-09T03:50:31.801860Z",
     "shell.execute_reply": "2024-05-09T03:50:31.800871Z",
     "shell.execute_reply.started": "2024-05-09T03:50:31.797867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78458efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:50:32.296529Z",
     "iopub.status.busy": "2024-05-09T03:50:32.295531Z",
     "iopub.status.idle": "2024-05-09T03:51:00.823373Z",
     "shell.execute_reply": "2024-05-09T03:51:00.822367Z",
     "shell.execute_reply.started": "2024-05-09T03:50:32.296529Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mChoosing a name for a company that manufactures Queen Size Sheet Sets depends on the branding, target audience, and overall marketing strategy of the business. However, here are some suggestions that might help:\n",
      "\n",
      "1. **Luxury Linen Crafters**: This name suggests high-quality, handmade sheets that are luxurious and crafted with care.\n",
      "2. **Queen's Comfort Collection**: This name directly references the product (Queen Size Sheet Sets) and suggests comfort and elegance.\n",
      "3. **Boutique Bed Sheets**: This name suggests a more boutique, upscale approach to bed sheets, appealing to customers who appreciate unique and stylish home decor.\n",
      "4. **Palatial Sheets**: This name evokes a sense of grandeur and luxury, appealing to customers who want to feel like royalty in their own beds.\n",
      "5. **Elegant Ease Bedding**: This name combines elements of elegance and comfort, appealing to customers who value both style and practicality.\n",
      "\n",
      "Remember, the best name for your company will be one that resonates with your target audience and reflects your brand's unique values and mission.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mCompany manufactures luxurious, high-quality Queen Size Sheet Sets, prioritizing comfort and elegance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Company manufactures luxurious, high-quality Queen Size Sheet Sets, prioritizing comfort and elegance.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c129ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:51:00.825359Z",
     "iopub.status.busy": "2024-05-09T03:51:00.824368Z",
     "iopub.status.idle": "2024-05-09T03:51:00.839360Z",
     "shell.execute_reply": "2024-05-09T03:51:00.838367Z",
     "shell.execute_reply.started": "2024-05-09T03:51:00.825359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016187ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:14.268577Z",
     "iopub.status.busy": "2024-05-09T03:53:14.268577Z",
     "iopub.status.idle": "2024-05-09T03:53:14.289721Z",
     "shell.execute_reply": "2024-05-09T03:53:14.287576Z",
     "shell.execute_reply.started": "2024-05-09T03:53:14.268577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-Bot-4\", temperature = 0.9) \n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb0730e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:18.719523Z",
     "iopub.status.busy": "2024-05-09T03:53:18.719523Z",
     "iopub.status.idle": "2024-05-09T03:53:18.730523Z",
     "shell.execute_reply": "2024-05-09T03:53:18.729523Z",
     "shell.execute_reply.started": "2024-05-09T03:53:18.719523Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6accf92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:22.395672Z",
     "iopub.status.busy": "2024-05-09T03:53:22.394672Z",
     "iopub.status.idle": "2024-05-09T03:53:22.403665Z",
     "shell.execute_reply": "2024-05-09T03:53:22.402676Z",
     "shell.execute_reply.started": "2024-05-09T03:53:22.395672Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7a46121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:24.317091Z",
     "iopub.status.busy": "2024-05-09T03:53:24.317091Z",
     "iopub.status.idle": "2024-05-09T03:53:24.324097Z",
     "shell.execute_reply": "2024-05-09T03:53:24.323109Z",
     "shell.execute_reply.started": "2024-05-09T03:53:24.317091Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89603117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:37.674305Z",
     "iopub.status.busy": "2024-05-09T03:53:37.674305Z",
     "iopub.status.idle": "2024-05-09T03:53:37.682297Z",
     "shell.execute_reply": "2024-05-09T03:53:37.681299Z",
     "shell.execute_reply.started": "2024-05-09T03:53:37.674305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51b04f45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:38.290040Z",
     "iopub.status.busy": "2024-05-09T03:53:38.290040Z",
     "iopub.status.idle": "2024-05-09T03:53:52.481708Z",
     "shell.execute_reply": "2024-05-09T03:53:52.481708Z",
     "shell.execute_reply.started": "2024-05-09T03:53:38.290040Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'English_Review': 'æ±æ­ï¼è¿ä¸ªåè½ææªå¼æ¾ä¸çº¿ãæ¨ä¹å¯ä»¥ç¨ä¸­ææè±æé®æä¸äºå¶ä»çé®é¢ï¼æä¼å°½åä¸ºæ¨è§£ç­ã',\n",
       " 'summary': 'è¯¥è¯è®ºæåºæé¡¹åè½å°æªå¼æ¾ä¸çº¿ï¼ä½ç¨æ·ä»å¯ä»¥è¯¢é®ä¸­è±æçå¶ä»é®é¢ï¼è¯è®ºèä¼å°½ååç­ã',\n",
       " 'followup_message': 'éå¸¸æè°¢æ¨ççè§£åèå¿ãéå¯¹æ¨æå°çåè½ï¼æä»¬æ·±è¡¨æ­æï¼å ä¸ºç®åè¯¥åè½ç¡®å®è¿æªå¼æ¾ä¸çº¿ãæä»¬æ­£å¨åªåå®åå¹¶å°½å¿«æ¨åºï¼ä»¥æ»¡è¶³æ¨çéæ±ã\\n\\nå¨æ­¤æé´ï¼å¦ææ¨æä»»ä½ä¸­è±æçå¶ä»é®é¢ï¼æ¬¢è¿éæ¶åæä»¬æé®ãæä»¬å°ç«­å°½æè½ä¸ºæ¨æä¾æ»¡æçç­æ¡åè§£å³æ¹æ¡ãåæ¬¡æè°¢æ¨çæ¯æåå³æ³¨ï¼æå¾è½ä¸ºæ¨å¸¦æ¥æ´å¥½çæå¡ä½éªã'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ade83f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:52.483215Z",
     "iopub.status.busy": "2024-05-09T03:53:52.483215Z",
     "iopub.status.idle": "2024-05-09T03:53:52.498225Z",
     "shell.execute_reply": "2024-05-09T03:53:52.497224Z",
     "shell.execute_reply.started": "2024-05-09T03:53:52.483215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f590e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:52.499224Z",
     "iopub.status.busy": "2024-05-09T03:53:52.499224Z",
     "iopub.status.idle": "2024-05-09T03:53:52.514224Z",
     "shell.execute_reply": "2024-05-09T03:53:52.513223Z",
     "shell.execute_reply.started": "2024-05-09T03:53:52.499224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31b06fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:52.516226Z",
     "iopub.status.busy": "2024-05-09T03:53:52.516226Z",
     "iopub.status.idle": "2024-05-09T03:53:53.103326Z",
     "shell.execute_reply": "2024-05-09T03:53:53.102283Z",
     "shell.execute_reply.started": "2024-05-09T03:53:52.516226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f50bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:53.151340Z",
     "iopub.status.busy": "2024-05-09T03:53:53.151340Z",
     "iopub.status.idle": "2024-05-09T03:53:53.166184Z",
     "shell.execute_reply": "2024-05-09T03:53:53.165142Z",
     "shell.execute_reply.started": "2024-05-09T03:53:53.151340Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-Bot-4\", temperature = 0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eefec24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:53.167170Z",
     "iopub.status.busy": "2024-05-09T03:53:53.167170Z",
     "iopub.status.idle": "2024-05-09T03:53:53.182179Z",
     "shell.execute_reply": "2024-05-09T03:53:53.181186Z",
     "shell.execute_reply.started": "2024-05-09T03:53:53.167170Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f98018a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:53.183684Z",
     "iopub.status.busy": "2024-05-09T03:53:53.182179Z",
     "iopub.status.idle": "2024-05-09T03:53:53.197860Z",
     "shell.execute_reply": "2024-05-09T03:53:53.196860Z",
     "shell.execute_reply.started": "2024-05-09T03:53:53.183684Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11b2e2ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:53.225038Z",
     "iopub.status.busy": "2024-05-09T03:53:53.224044Z",
     "iopub.status.idle": "2024-05-09T03:53:53.243965Z",
     "shell.execute_reply": "2024-05-09T03:53:53.242973Z",
     "shell.execute_reply.started": "2024-05-09T03:53:53.225038Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1387109d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:54.715298Z",
     "iopub.status.busy": "2024-05-09T03:53:54.715298Z",
     "iopub.status.idle": "2024-05-09T03:53:54.731467Z",
     "shell.execute_reply": "2024-05-09T03:53:54.730293Z",
     "shell.execute_reply.started": "2024-05-09T03:53:54.715298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fb7d560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:55.513439Z",
     "iopub.status.busy": "2024-05-09T03:53:55.512433Z",
     "iopub.status.idle": "2024-05-09T03:53:55.520433Z",
     "shell.execute_reply": "2024-05-09T03:53:55.519433Z",
     "shell.execute_reply.started": "2024-05-09T03:53:55.513439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d86b2131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:53:56.076634Z",
     "iopub.status.busy": "2024-05-09T03:53:56.076634Z",
     "iopub.status.idle": "2024-05-09T03:54:21.554255Z",
     "shell.execute_reply": "2024-05-09T03:54:21.553262Z",
     "shell.execute_reply.started": "2024-05-09T03:53:56.076634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by an idealized physical body known as a black body. A black body is an object that absorbs all incident radiation, regardless of frequency or angle of incidence, and re-emits it as thermal radiation. The radiation emitted by a black body is characterized by a specific spectrum and intensity that depends only on the body's temperature. This radiation is called black body radiation.\\n\\nThe spectrum of black body radiation is described by Planck's law, which states that the intensity of radiation emitted at a given frequency is proportional to the temperature of the black body and varies with frequency in a specific way. The shape of the spectrum changes with temperature, shifting to higher frequencies as the temperature increases.\\n\\nBlack body radiation plays a fundamental role in many areas of physics, including thermodynamics, quantum mechanics, and astronomy. For example, the radiation emitted by stars can be approximated as black body radiation, allowing astronomers to estimate their temperatures and other properties.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b717379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:54:21.558255Z",
     "iopub.status.busy": "2024-05-09T03:54:21.556255Z",
     "iopub.status.idle": "2024-05-09T03:54:31.823895Z",
     "shell.execute_reply": "2024-05-09T03:54:31.822887Z",
     "shell.execute_reply.started": "2024-05-09T03:54:21.557258Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to the question \"what is 2 + 2\" is 4. This is a basic addition problem in mathematics, where two numbers are added together to produce a sum. In this case, 2 + 2 equals 4.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29e5be01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T03:54:31.825895Z",
     "iopub.status.busy": "2024-05-09T03:54:31.824888Z",
     "iopub.status.idle": "2024-05-09T03:55:01.608054Z",
     "shell.execute_reply": "2024-05-09T03:55:01.607038Z",
     "shell.execute_reply.started": "2024-05-09T03:54:31.825895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"DNA, or deoxyribonucleic acid, is the genetic material of all living organisms, including humans. It is the carrier of genetic information and is responsible for storing and transmitting the genetic code of the organism. Every cell in the human body contains DNA because it is necessary for the cell to function properly.\\n\\nFirstly, DNA provides the instructions for the production of proteins, which are essential for the structure, function, and regulation of the human body's cells, tissues, and organs. Proteins play a crucial role in almost all biological processes, including metabolism, cell division, and immune responses.\\n\\nSecondly, DNA also contains the genetic information that determines the unique characteristics of each individual, such as eye color, hair color, and blood type. This information is passed down from generation to generation through DNA.\\n\\nFinally, DNA is also involved in the repair and maintenance of the cell's genetic material, ensuring the stability and integrity of the genome. This is essential for maintaining the health and function of the cell and preventing genetic diseases.\\n\\nIn summary, every cell in the human body contains DNA because it is essential for the cell's structure, function, and regulation. DNA provides the genetic instructions for protein production, determines individual characteristics, and maintains the stability and integrity of the genome.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f0121-cf7b-464d-bb3d-6357719188ed",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912633a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6378a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9456d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c46ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

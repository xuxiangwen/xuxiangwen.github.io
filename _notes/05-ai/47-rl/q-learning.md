参考:

- [一个 Q-learning 算法的简明教程](https://blog.csdn.net/itplus/article/details/9361915)

问题：

![image-20200610083326462](images/image-20200610083326462.png)

![image-20200610083339539](images/image-20200610083339539.png)

转移规则：

![image-20200610083025566](images/image-20200610083025566.png)

算法：

![image-20200610083250594](images/image-20200610083250594.png)

初始状态：

![image-20200610083407306](images/image-20200610083407306.png)

![image-20200610083000170](images/image-20200610083000170.png)

![image-20200610083438214](images/image-20200610083438214.png)

假设 $ \gamma =0.8 $，

1. 第一次：初始状态为房间1，从R矩阵第二行可以看到有两个非负值，即有两种行为可能，状态3或者状态5，假设我们选择了随机状态5，则

   ![image-20200610084039282](images/image-20200610084039282.png)

   更新Q矩阵。

   ![image-20200610084050722](images/image-20200610084050722.png)

   ![image-20200610083000170](images/image-20200610083000170.png)

   由于这时已经处于状态5了，已经达到目标状态，则任务完成。

2. 第二次：初始状态为房间3，它有三个可能行为：1，2， 4。随机选择状态1，则

   ![image-20200610085429629](images/image-20200610085429629.png)

   更新Q矩阵。

   ![image-20200610085536757](images/image-20200610085536757.png)

   ![image-20200610083000170](images/image-20200610083000170.png)

   接下来，状态变成了1，而1有两种可能行为：3和5，假设随机选择了5，则

   ![image-20200610084039282](images/image-20200610084039282.png)

   矩阵Q没有任何变化。由于达到目标状态，则任务完成。

3. 再次循环随机选择初始状态，最终矩阵Q将收敛到：

   ![image-20200610090059087](images/image-20200610090059087.png)

   把每个元素除以矩阵最大值（500）再乘以100，则可得

   ![image-20200610090235886](images/image-20200610090235886.png)

   也就是：

   ![image-20200610090301345](images/image-20200610090301345.png)

   
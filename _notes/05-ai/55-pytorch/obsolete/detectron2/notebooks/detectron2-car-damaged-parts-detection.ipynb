{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><img src=\"https://raw.githubusercontent.com/facebookresearch/detectron2/master/.github/Detectron2-Logo-Horz.svg\"><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> <a href=\"https://github.com/facebookresearch/detectron2\">Detectron2</a> is a PyTorch based modular object detection library</center></h2>\n",
    "\n",
    "<h4 style=\"text-align: right, line-height: 3.5em;\"> Detectron 2 is a next-generation open-source object detection system from Facebook AI Research. It can be used to train various state-of-the-art models like <a href=\"http://densepose.org/\">Densepose </a> and <a href=\"https://ai.facebook.com/blog/improving-scene-understanding-through-panoptic-segmentation/\">panoptic feature pyramid networks</a> for detection tasks such as bounding-box detection, instance and semantic segmentation, and person keypoint detection. With a modular design, Detectron2 is flexible and extensible, and able to provide fast training on single or multiple GPU servers. </h4>\n",
    "    \n",
    "    \n",
    "<h4> I hope that releasing Detectron2 will continue to accelerate progress in the area of object detection and segmentation. This Kernel is my attempt of contributing to the progress. </h4>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have created another notebook [Detectron2 Car Damage Detection](https://www.kaggle.com/lplenka/detectron2-car-damage-detection) where I have shown step by step installation Dectectron 2 and other supporting libraries. There I have also shown how to use Detectron 2 for detecting damage in cars using Image Segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a ><img src=\"https://i.ibb.co/dP12V6R/damages.jpg\" alt=\"damages\" border=\"0\"></a>\n",
    "<a ><img src=\"https://i.ibb.co/0QhJGSd/parts.jpg\" alt=\"parts\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left image shows the damages and right image shows the parts, both of these can be plotted using this notebook [https://www.kaggle.com/lplenka/coco-data-visualization](https://www.kaggle.com/lplenka/coco-data-visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Problem Statement</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The challenge here is to detect that the **hood ** has damages and not other parts of car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Detecting Damaged Parts - Idea</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't think of any way where we can train a image segmentation model that can directly detect the damaged parts. So I decided to build two image segmentation models. One model to segment the damages which returns the \"damage\" polygon(s). One model to segment the parts of the car which returns the \"parts\" polygon(s). \n",
    "\n",
    "I had two approaches on how to move forward after getting the output from two models:\n",
    "*  After getting the predicted bounding boxes (polygons) from two models then I can check which damage polygons lie inside which \"part\" polygon and can detect the damaged part. \n",
    "*  After getting the predicted bounding boxes (polygons) from two models then I can check how far the damage is from different parts and return the part nearest to a damage.\n",
    "\n",
    "\n",
    "Note: There should be some way to train a single model that does both the tasks, but it can be in next versions. Feel free to suggest new approaches and implement your own approach.\n",
    "\n",
    "In this notebook I have implemented the second approach for now. I will add the first approach soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Source Dataset</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we will train two models, first for only damages and second for only parts, you can find annotation for both in the dataset I have published here. [Coco Car Damage Dataset](https://www.kaggle.com/lplenka/coco-car-damage-detection-dataset)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Let's begin!</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since I have already shown the installation steps, here I will directly start with all installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Installation</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Install Pycocotools\n",
    "# !pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "# # Install detectron 2\n",
    "# !python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Import Libraries</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import random\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)# Import Libraries\n",
    "\n",
    "# For visualization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from tensorboard.backend.event_processing import event_accumulator as ea\n",
    "from PIL import Image\n",
    "\n",
    "# Scipy for calculating distance\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Set constant variables</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am visualizing some images in the 'val/' directory\n",
    "\n",
    "dataDir='../data/coco_car_damage_detection/val'\n",
    "dataType='COCO_val_annos'\n",
    "mul_dataType='COCO_mul_val_annos'\n",
    "annFile='{}/{}.json'.format(dataDir,dataType)\n",
    "mul_annFile='{}/{}.json'.format(dataDir,mul_dataType)\n",
    "img_dir = \"../data/coco_car_damage_detection/img\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; border:0' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Initialize the COCO API</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize coco api for instance annotations\n",
    "coco=COCO(annFile)\n",
    "mul_coco=COCO(mul_annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px' > Import Libraries required for training</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113 True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.__version__.startswith(\"1.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Set base params\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# To find out inconsistent CUDA versions, if there is no \"failed\" word in this output then things are fine.\n",
    "# !python -m detectron2.utils.collect_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>  Register Car Damage Dataset </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register Train Dataset, so that we can use its Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/coco_car_damage_detection\"\n",
    "img_dir = \"img/\"\n",
    "train_dir = \"train/\"\n",
    "val_dir = \"val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"car_dataset_val\", {}, os.path.join(dataset_dir,val_dir,\"COCO_val_annos.json\"), os.path.join(dataset_dir,img_dir))\n",
    "register_coco_instances(\"car_mul_dataset_val\", {}, os.path.join(dataset_dir,val_dir,\"COCO_mul_val_annos.json\"), os.path.join(dataset_dir,img_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; ' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Load trained model </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will load two pretained models:\n",
    "\n",
    "* Damage Segmentation model weights -  This can be easily created using this notebook [\n",
    "Detectron2 Car Damage Detection](https://www.kaggle.com/lplenka/detectron2-car-damage-detection). The model is stored in default output directory.\n",
    "\n",
    "* Parts Segmentation Model weights - This can be also created just changing the dataset from damage annotions to parts annotation in [cell 22](https://www.kaggle.com/lplenka/detectron2-car-damage-detection?scriptVersionId=52171508&cellId=37)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; ' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Damage Detection Model </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Checkpoint ../input/coco-damage-detection-trained-models/damage_segmentation_model.pth not found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mROI_HEADS\u001b[38;5;241m.\u001b[39mSCORE_THRESH_TEST \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m \n\u001b[1;32m      8\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODEL\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEVICE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;66;03m#or cpu\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m damage_predictor \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/detectron2/engine/defaults.py:288\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    287\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m DetectionCheckpointer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 288\u001b[0m \u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWEIGHTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mResizeShortestEdge(\n\u001b[1;32m    291\u001b[0m     [cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST, cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMIN_SIZE_TEST], cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mMAX_SIZE_TEST\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mINPUT\u001b[38;5;241m.\u001b[39mFORMAT\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/detectron2/checkpoint/detection_checkpoint.py:52\u001b[0m, in \u001b[0;36mDetectionCheckpointer.load\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_file:\n\u001b[1;32m     51\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# don't load if not readable\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_sync:\n\u001b[1;32m     55\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcasting model states from main worker ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fvcore/common/checkpoint.py:153\u001b[0m, in \u001b[0;36mCheckpointer.load\u001b[0;34m(self, path, checkpointables)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[1;32m    152\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mget_local_path(path)\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path)\n\u001b[1;32m    155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_file(path)\n\u001b[1;32m    156\u001b[0m incompatible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(checkpoint)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Checkpoint ../input/coco-damage-detection-trained-models/damage_segmentation_model.pth not found!"
     ]
    }
   ],
   "source": [
    "#get configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (damage) + 1\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 1 # only has one class (damage) + 1\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"../input/coco-damage-detection-trained-models/damage_segmentation_model.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \n",
    "cfg['MODEL']['DEVICE']='cuda'#or cpu\n",
    "damage_predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; ' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Parts Segmentation Model </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_mul = get_cfg()\n",
    "cfg_mul.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg_mul.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has five classes (headlamp,hood,rear_bumper,front_bumper_door) + 1\n",
    "cfg_mul.MODEL.RETINANET.NUM_CLASSES = 6 # only has five classes (headlamp,hood,rear_bumper,front_bumper_door) + 1\n",
    "cfg_mul.MODEL.WEIGHTS = os.path.join(\"../input/coco-damage-detection-trained-models/part_segmentation_model.pth\")\n",
    "cfg_mul.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \n",
    "cfg_mul['MODEL']['DEVICE']='cuda' #or cpu\n",
    "part_predictor = DefaultPredictor(cfg_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Model Inference </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_damage_part(damage_dict, parts_dict):\n",
    "  \"\"\"\n",
    "  Returns the most plausible damaged part for the list of damages by checking the distance \n",
    "  between centers centers of damage_polygons and parts_polygons\n",
    "\n",
    "  Parameters\n",
    "  -------------\n",
    "   damage_dict: dict\n",
    "                Dictionary that maps damages to damage polygon centers.\n",
    "   parts_dict: dict\n",
    "                Dictionary that maps part labels to parts polygon centers.\n",
    "  Return\n",
    "  ----------\n",
    "  part_name: str\n",
    "            The most plausible damaged part name.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    max_distance = 10e9\n",
    "    assert len(damage_dict)>0, \"AssertError: damage_dict should have atleast one damage\"\n",
    "    assert len(parts_dict)>0, \"AssertError: parts_dict should have atleast one part\"\n",
    "    max_distance_dict = dict(zip(damage_dict.keys(),[max_distance]*len(damage_dict)))\n",
    "    part_name = dict(zip(damage_dict.keys(),['']*len(damage_dict)))\n",
    "\n",
    "    for y in parts_dict.keys():\n",
    "        for x in damage_dict.keys():\n",
    "          dis = distance.euclidean(damage_dict[x], parts_dict[y])\n",
    "          if dis < max_distance_dict[x]:\n",
    "            part_name[x] = y.rsplit('_',1)[0]\n",
    "\n",
    "    return list(set(part_name.values()))\n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "damage_class_map= {0:'damage'}\n",
    "parts_class_map={0:'headlamp',1:'rear_bumper', 2:'door', 3:'hood', 4: 'front_bumper'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(16,12))\n",
    "im = io.imread(\"../input/coco-car-damage-detection-dataset/val/32.jpg\")\n",
    "\n",
    "#damage inference\n",
    "damage_outputs = damage_predictor(im)\n",
    "damage_v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"car_dataset_val\"), \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    ")\n",
    "damage_out = damage_v.draw_instance_predictions(damage_outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "#part inference\n",
    "parts_outputs = part_predictor(im)\n",
    "parts_v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"car_mul_dataset_val\"), \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    ")\n",
    "parts_out = parts_v.draw_instance_predictions(parts_outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "#plot\n",
    "ax1.imshow(damage_out.get_image()[:, :, ::-1],)\n",
    "ax2.imshow(parts_out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Create damage polygons </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now allowing multiple polygons of same class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_prediction_classes = [ damage_class_map[el] + \"_\" + str(indx) for indx,el in enumerate(damage_outputs[\"instances\"].pred_classes.tolist())]\n",
    "damage_polygon_centers = damage_outputs[\"instances\"].pred_boxes.get_centers().tolist()\n",
    "damage_dict = dict(zip(damage_prediction_classes,damage_polygon_centers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Create parts polygons </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now allowing multiple polygons of same class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parts_prediction_classes = [ parts_class_map[el] + \"_\" + str(indx) for indx,el in enumerate(parts_outputs[\"instances\"].pred_classes.tolist())]\n",
    "parts_polygon_centers =  parts_outputs[\"instances\"].pred_boxes.get_centers().tolist()\n",
    "\n",
    "\n",
    "\n",
    "#Remove centers which lie in beyond 800 units\n",
    "parts_polygon_centers_filtered = list(filter(lambda x: x[0] < 800 and x[1] < 800, parts_polygon_centers))\n",
    "parts_dict = dict(zip(parts_prediction_classes,parts_polygon_centers_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Damaged Parts </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Damaged Parts: \",detect_damage_part(damage_dict,parts_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ouput looks correct 😃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Some insights from the performance of model </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model confuses between front and rear bumper.\n",
    "* Center of polygon was mostly different from center of bbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Conclusion </center></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is definitely a lot of scope for improvement. But this notebook can be a good begining for other complex approaches.\n",
    "* Data augmentation and training on larger data can significantly improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do give this notebook an upvote if you liked my work, thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8f6855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T13:49:09.025068Z",
     "start_time": "2022-08-22T13:49:05.145899Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Skeleton code showing how to load and run the TensorFlow SavedModel export package from Lobe.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sys \n",
    "from threading import Lock\n",
    "from pprint import pprint \n",
    "from PIL import Image \n",
    "from tensorflow.keras import Model, models, layers, regularizers, preprocessing, datasets, metrics, losses, optimizers\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# printing only warnings and error messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    raise ImportError(\"ERROR: Failed to import libraries. Please refer to READEME.md file\\n\")\n",
    "\n",
    "EXPORT_MODEL_VERSION = 1\n",
    "\n",
    "base_path = os.path.abspath('/tf/eipi10/jian-xu3/qbz95')\n",
    "sys.path.append(base_path)\n",
    "\n",
    "import qbz95\n",
    "from qbz95 import tf as qtf\n",
    "\n",
    "\n",
    "# set gpu memory\n",
    "qtf.utils.set_gpu_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7b1e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T13:49:09.043445Z",
     "start_time": "2022-08-22T13:49:09.028102Z"
    }
   },
   "outputs": [],
   "source": [
    "class TFModel:\n",
    "    def __init__(self, dir_path, classes) -> None:\n",
    "        # Assume model is in the parent directory for this file\n",
    "        self.model_dir = dir_path\n",
    "        # make sure our exported SavedModel folder exists\n",
    "        with open(os.path.join(self.model_dir, \"signature.json\"), \"r\") as f:\n",
    "            self.signature = json.load(f)\n",
    "        self.model_file = os.path.join(self.model_dir, self.signature.get(\"filename\"))\n",
    "        if not os.path.isfile(self.model_file):\n",
    "            raise FileNotFoundError(f\"Model file does not exist\")\n",
    "        self.inputs = self.signature.get(\"inputs\")\n",
    "        self.outputs = self.signature.get(\"outputs\")\n",
    "        self.lock = Lock()\n",
    "\n",
    "        # loading the saved model\n",
    "        self.model = tf.saved_model.load(tags=self.signature.get(\"tags\"), export_dir=self.model_dir)\n",
    "        self.predict_fn = self.model.signatures[\"serving_default\"]\n",
    "\n",
    "        # Look for the version in signature file.\n",
    "        # If it's not found or the doesn't match expected, print a message\n",
    "        version = self.signature.get(\"export_model_version\")\n",
    "        if version is None or version != EXPORT_MODEL_VERSION:\n",
    "            print(\n",
    "                f\"There has been a change to the model format. Please use a model with a signature 'export_model_version' that matches {EXPORT_MODEL_VERSION}.\"\n",
    "            )\n",
    "            \n",
    "        self.classes = classes\n",
    "\n",
    "    def predict(self, image: Image.Image) -> dict:\n",
    "        # pre-processing the image before passing to model\n",
    "        image = self.process_image(image, self.inputs.get(\"Image\").get(\"shape\"))\n",
    "\n",
    "        with self.lock:\n",
    "            # create the feed dictionary that is the input to the model\n",
    "            feed_dict = {}\n",
    "            # first, add our image to the dictionary (comes from our signature.json file)\n",
    "            feed_dict[list(self.inputs.keys())[0]] = tf.convert_to_tensor(image)\n",
    "            # run the model!\n",
    "            outputs = self.predict_fn(**feed_dict)\n",
    "            # return the processed output\n",
    "            return self.process_output(outputs)\n",
    "        \n",
    "    def predict_from_arrays(self, image_arrays):\n",
    "        predictions = []\n",
    "        for image_array in tqdm(image_arrays):\n",
    "            image = Image.fromarray(image_array)\n",
    "            outputs = self.predict(image)\n",
    "            prediction = outputs['predictions'][0]['label']\n",
    "            predictions.append(self.classes.index(prediction))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def process_image(self, image, input_shape) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a PIL Image, center square crop and resize to fit the expected model input, and convert from [0,255] to [0,1] values.\n",
    "        \"\"\"\n",
    "        width, height = image.size\n",
    "        # ensure image type is compatible with model and convert if not\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        # center crop image (you can substitute any other method to make a square image, such as just resizing or padding edges with 0)\n",
    "        if width != height:\n",
    "            square_size = min(width, height)\n",
    "            left = (width - square_size) / 2\n",
    "            top = (height - square_size) / 2\n",
    "            right = (width + square_size) / 2\n",
    "            bottom = (height + square_size) / 2\n",
    "            # Crop the center of the image\n",
    "            image = image.crop((left, top, right, bottom))\n",
    "        # now the image is square, resize it to be the right shape for the model input\n",
    "        input_width, input_height = input_shape[1:3]\n",
    "        if image.width != input_width or image.height != input_height:\n",
    "            image = image.resize((input_width, input_height))\n",
    "\n",
    "        # make 0-1 float instead of 0-255 int (that PIL Image loads by default)\n",
    "        image = np.asarray(image) / 255.0\n",
    "        # pad with an extra batch dimension as expected by the model\n",
    "        return np.expand_dims(image, axis=0).astype(np.float32)\n",
    "\n",
    "    def process_output(self, outputs) -> dict:\n",
    "        # do a bit of postprocessing\n",
    "        out_keys = [\"label\", \"confidence\"]\n",
    "        results = {}\n",
    "        # since we actually ran on a batch of size 1, index out the items from the returned numpy arrays\n",
    "        for key, tf_val in outputs.items():\n",
    "            val = tf_val.numpy().tolist()[0]\n",
    "            if isinstance(val, bytes):\n",
    "                val = val.decode()\n",
    "            results[key] = val\n",
    "        confs = results[\"Confidences\"]\n",
    "        labels = self.signature.get(\"classes\").get(\"Label\")\n",
    "        output = [dict(zip(out_keys, group)) for group in zip(labels, confs)]\n",
    "        sorted_output = {\"predictions\": sorted(output, key=lambda k: k[\"confidence\"], reverse=True)}\n",
    "        return sorted_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25a7446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T13:49:15.584518Z",
     "start_time": "2022-08-22T13:49:09.046298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Predicted: {'predictions': [{'label': 'bird', 'confidence': \"\n",
      " \"0.9999884366989136}, {'label': 'cat', 'confidence': 6.133375336503377e-06}, \"\n",
      " \"{'label': 'deer', 'confidence': 4.627039288607193e-06}, {'label': 'frog', \"\n",
      " \"'confidence': 7.819590450708347e-07}, {'label': 'dog', 'confidence': \"\n",
      " \"2.5593249741717727e-10}, {'label': 'car', 'confidence': \"\n",
      " \"2.1317153771349684e-12}, {'label': 'plane', 'confidence': \"\n",
      " \"3.66488862369764e-14}, {'label': 'horse', 'confidence': \"\n",
      " \"6.278238274718502e-15}, {'label': 'truck', 'confidence': \"\n",
      " \"4.8913437963339895e-15}, {'label': 'ship', 'confidence': \"\n",
      " '4.249912043104342e-17}]}')\n"
     ]
    }
   ],
   "source": [
    "classes =  ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "dir_path = \"/tf/eipi10/jian-xu3/adp_claim_image/output/cifar10_50_TensorFlow\"\n",
    "model = TFModel(dir_path=dir_path, classes=classes) \n",
    "\n",
    "image_path = \"/tf/eipi10/xuxiangwen.github.io/_notes/05-ai/54-tensorflow/image_classification/output/cifar10/data/cifar10_test/bird/1047.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "outputs = model.predict(image)\n",
    "pprint(f\"Predicted: {outputs}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d55ebd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T13:50:40.334408Z",
     "start_time": "2022-08-22T13:50:39.262750Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec746db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T02:32:24.943153Z",
     "start_time": "2022-08-24T02:21:45.780541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- 1000 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:02<00:00, 81.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane     0.8270    0.8510    0.8388      1000\n",
      "         car     0.9654    0.5860    0.7293      1000\n",
      "        bird     0.9031    0.6620    0.7640      1000\n",
      "         cat     0.7894    0.4010    0.5318      1000\n",
      "        deer     0.7905    0.5850    0.6724      1000\n",
      "         dog     0.7722    0.6340    0.6963      1000\n",
      "        frog     0.7125    0.8920    0.7922      1000\n",
      "       horse     0.4866    0.9660    0.6472      1000\n",
      "        ship     0.8743    0.9110    0.8923      1000\n",
      "       truck     0.7132    0.9150    0.8016      1000\n",
      "\n",
      "    accuracy                         0.7403     10000\n",
      "   macro avg     0.7834    0.7403    0.7366     10000\n",
      "weighted avg     0.7834    0.7403    0.7366     10000\n",
      "\n",
      "------------------------- 500 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:03<00:00, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane     0.7698    0.8460    0.8061      1000\n",
      "         car     0.9262    0.8540    0.8887      1000\n",
      "        bird     0.8874    0.6700    0.7635      1000\n",
      "         cat     0.7733    0.4230    0.5469      1000\n",
      "        deer     0.8296    0.6720    0.7425      1000\n",
      "         dog     0.6371    0.8620    0.7327      1000\n",
      "        frog     0.8601    0.7990    0.8284      1000\n",
      "       horse     0.6130    0.9220    0.7364      1000\n",
      "        ship     0.9302    0.7730    0.8443      1000\n",
      "       truck     0.7456    0.9320    0.8284      1000\n",
      "\n",
      "    accuracy                         0.7753     10000\n",
      "   macro avg     0.7972    0.7753    0.7718     10000\n",
      "weighted avg     0.7972    0.7753    0.7718     10000\n",
      "\n",
      "------------------------- 200 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:03<00:00, 81.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane     0.8121    0.7910    0.8014      1000\n",
      "         car     0.9416    0.8540    0.8956      1000\n",
      "        bird     0.7912    0.7920    0.7916      1000\n",
      "         cat     0.6887    0.6880    0.6883      1000\n",
      "        deer     0.8074    0.5700    0.6682      1000\n",
      "         dog     0.7188    0.8640    0.7847      1000\n",
      "        frog     0.7764    0.8470    0.8101      1000\n",
      "       horse     0.8773    0.7010    0.7793      1000\n",
      "        ship     0.6923    0.9720    0.8087      1000\n",
      "       truck     0.9160    0.8400    0.8764      1000\n",
      "\n",
      "    accuracy                         0.7919     10000\n",
      "   macro avg     0.8022    0.7919    0.7904     10000\n",
      "weighted avg     0.8022    0.7919    0.7904     10000\n",
      "\n",
      "------------------------- 100 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:04<00:00, 80.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane     0.8577    0.7170    0.7810      1000\n",
      "         car     0.8307    0.8980    0.8630      1000\n",
      "        bird     0.7722    0.6170    0.6859      1000\n",
      "         cat     0.5271    0.7110    0.6054      1000\n",
      "        deer     0.7576    0.4500    0.5646      1000\n",
      "         dog     0.9727    0.4630    0.6274      1000\n",
      "        frog     0.5127    0.9460    0.6650      1000\n",
      "       horse     0.5882    0.7800    0.6707      1000\n",
      "        ship     0.9187    0.7350    0.8167      1000\n",
      "       truck     0.9038    0.8080    0.8532      1000\n",
      "\n",
      "    accuracy                         0.7125     10000\n",
      "   macro avg     0.7641    0.7125    0.7133     10000\n",
      "weighted avg     0.7641    0.7125    0.7133     10000\n",
      "\n",
      "------------------------- 50 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:03<00:00, 81.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane     0.9507    0.2700    0.4206      1000\n",
      "         car     0.9510    0.7180    0.8182      1000\n",
      "        bird     0.7983    0.6490    0.7159      1000\n",
      "         cat     0.5650    0.7780    0.6546      1000\n",
      "        deer     0.6822    0.7020    0.6920      1000\n",
      "         dog     0.7507    0.7560    0.7534      1000\n",
      "        frog     0.8209    0.6280    0.7116      1000\n",
      "       horse     0.5141    0.8770    0.6482      1000\n",
      "        ship     0.9066    0.6700    0.7706      1000\n",
      "       truck     0.6275    0.9570    0.7580      1000\n",
      "\n",
      "    accuracy                         0.7005     10000\n",
      "   macro avg     0.7567    0.7005    0.6943     10000\n",
      "weighted avg     0.7567    0.7005    0.6943     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_image_counts = [1000, 500, 200, 100, 50]\n",
    "for train_image_count in train_image_counts:\n",
    "    print('-'*25, train_image_count, '-'*25)\n",
    "    dir_path = f\"/tf/eipi10/jian-xu3/adp_claim_image/output/cifar10_{train_image_count}_TensorFlow\"\n",
    "    model = TFModel(dir_path=dir_path, classes=classes) \n",
    "    prediction_labels = model.predict_from_arrays(test_images)\n",
    "    print(classification_report(test_labels, prediction_labels, digits=4, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbbcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d327f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

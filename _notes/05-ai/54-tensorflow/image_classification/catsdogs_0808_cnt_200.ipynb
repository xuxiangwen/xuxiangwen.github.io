{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![image-20201226152702981](images/image-20201226152702981.png)\n",
    "\n",
    "\n",
    "数据集State-of-the-Art详见\n",
    "\n",
    "- [mnist](https://paperswithcode.com/sota/image-classification-on-mnist)\n",
    "- [fashion-mnist](https://paperswithcode.com/sota/image-classification-on-fashion-mnist)\n",
    "- [cifar-10](https://paperswithcode.com/sota/image-classification-on-cifar-10)\n",
    "\n",
    "\n",
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-17T04:59:53.486015Z",
     "start_time": "2022-08-17T04:59:53.475156Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    " \n",
    "# pip install -U ipyparams \n",
    "#pip install -U tensorflow_hub \n",
    "#pip install -U ipython\n",
    "# pip install -U pymysql pyodbc\n",
    "# pip install -U fasttext\n",
    "# pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "console.log('Starting front end url_querystring_target comm target');\n",
       "const comm = Jupyter.notebook.kernel.comm_manager.new_comm('url_querystring_target', {'init': 1});\n",
       "comm.send({'ipyparams_browser_url': window.location.href});\n",
       "console.log('Sent window.location.href on url_querystring_target comm target');\n",
       "\n",
       "comm.on_msg(function(msg) {\n",
       "    console.log(msg.content.data);\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ipyparams\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import string  \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import stats\n",
    "from sklearn import feature_extraction, feature_selection\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, models, layers, regularizers, preprocessing, datasets, metrics, losses, optimizers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorboard.plugins.hparams import api as hp \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "base_path = os.path.abspath('/tf/eipi10/jian-xu3/qbz95')\n",
    "sys.path.append(base_path)\n",
    "\n",
    "import qbz95\n",
    "from qbz95 import tf as qtf\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# set gpu memory\n",
    "qtf.utils.set_gpu_memory_growth()\n",
    "\n",
    "# auto load the changes of referenced codes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ebablbe auto-completion\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.230Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.232Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"config the strategy of reducing learning rate\"\"\"\n",
    "    lr_times = [(0, 1), (60, 1e-1), (90, 1e-2), (105, 1e-3), (120, 0.5e-3)]\n",
    "    \n",
    "    base_lr = 1e-3\n",
    "    new_lr = base_lr\n",
    "    for border_epoch, times in lr_times:\n",
    "        if epoch>=border_epoch: \n",
    "            new_lr = base_lr*times\n",
    "    if abs(lr - new_lr)>1e-7:\n",
    "        if new_lr > lr > 0.1*new_lr - 1e-7:\n",
    "            print('Epoch %05d: Still keep learning rate %s instead of %s' % \n",
    "                  (epoch + 1, round(lr, 7), round(new_lr, 7))) \n",
    "            return lr   \n",
    "        print('Epoch %05d: LearningRateScheduler reducing learning rate to %s from %s.' % \n",
    "              (epoch + 1, round(new_lr, 7), round(lr, 7)))\n",
    "    return new_lr\n",
    "\n",
    "data_generator = preprocessing.image.ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False) \n",
    "\n",
    "notebook_name_params = qbz95.utils.get_notebook_name().split('.')[0].split('_')\n",
    "\n",
    "output_path = os.path.abspath('./output')\n",
    "data_name = notebook_name_params[0]\n",
    "data_path = os.path.join(output_path, data_name)\n",
    "program_path = os.path.join(data_path, qbz95.utils.get_notebook_name().split('.')[0])\n",
    "word_vectors_path = '/tf/eipi10/xuxiangwen.github.io/_notes/05-ai/54-tensorflow/models/word_vectors'\n",
    "classes = ['cats', 'dogs']\n",
    "\n",
    "train_image_count =  int(notebook_name_params[3])\n",
    "use_data_augmentation = True if len(notebook_name_params)>=5 and notebook_name_params[4]=='aug' else False\n",
    "\n",
    "params = {\n",
    "    'data_name': data_name,\n",
    "    'data_path': data_path,\n",
    "    'train_image_count':train_image_count,\n",
    "    'use_data_augmentation': use_data_augmentation,\n",
    "    'augmentation_generator': data_generator,       \n",
    "    'program_name': qbz95.utils.get_notebook_name(),\n",
    "    'program_path': program_path,\n",
    "    'classes': classes,\n",
    "    'word_vectors_path': word_vectors_path,\n",
    "    'sample_perecent': 1,    \n",
    "    'validation_percent': 0.0,  \n",
    "    'use_stop_words': True,    \n",
    "    'batch_size': 32,    \n",
    "    'epochs': 3,    \n",
    "    'steps_per_epoch': int(train_image_count*len(classes)/32),\n",
    "    'learning_rate':0.001,\n",
    "    'clip_value':None,\n",
    "    'dropout':0.1,\n",
    "    'metrics':['accuracy'], \n",
    "    'loss': losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    'restore_best_checkpoint':True,\n",
    "    'use_savedmodel':True,\n",
    "    'use_bias_initializer':False,\n",
    "    'use_class_weight':False,\n",
    "    'class_weight': [1.0, 1.0],\n",
    "    'callbacks': {\n",
    "        'ModelCheckpoint': {\n",
    "            'enabled': True,\n",
    "            'monitor': 'val_accuracy',               \n",
    "        },\n",
    "        'EarlyStopping': {\n",
    "            'enabled': True,\n",
    "            'patience': 40,   \n",
    "            'monitor': 'val_accuracy',            \n",
    "        },\n",
    "        'ReduceLROnPlateau': {\n",
    "            'enabled': False,\n",
    "            'monitor': 'val_loss',\n",
    "            'patience': 15,\n",
    "            'factor': np.sqrt(0.1),            \n",
    "        },\n",
    "        'LearningRateScheduler': {\n",
    "            'enabled': False,\n",
    "            'schedule': lr_schedule,            \n",
    "        }             \n",
    "    },\n",
    "    'fine_tune_callbacks': {\n",
    "        'ModelCheckpoint': {\n",
    "            'enabled': True,\n",
    "            'monitor': 'val_accuracy',               \n",
    "        },\n",
    "        'EarlyStopping': {\n",
    "            'enabled': True,\n",
    "            'patience': 40,   \n",
    "            'monitor': 'val_accuracy',            \n",
    "        },\n",
    "        'ReduceLROnPlateau': {\n",
    "            'enabled': True,\n",
    "            'monitor': 'val_loss',\n",
    "            'patience': 15,\n",
    "            'factor': np.sqrt(0.1),            \n",
    "        }            \n",
    "    },    \n",
    "    'model_params':{\n",
    "        'mlp':{'dropout':0.3, 'layer_count':1, 'units':128, 'epochs':20},\n",
    "        'lenet':{'dropout':0.4, 'epochs':20},\n",
    "        'custom':{'dropout':0.4, 'epochs':20},\n",
    "        'vgg':{'dropout':0.4, 'epochs':20, 'learning_rate':0.001},\n",
    "        'resnet':{'dropout':0.4, 'epochs':20},\n",
    "        'pretrained':{'dropout':0.3, 'epochs':20, 'learning_rate':0.0001}       \n",
    "    },\n",
    "    'embedding_paths':{\n",
    "    },\n",
    "    'keras_layper_paths':{\n",
    "    },\n",
    "    'model_resutls':{\n",
    "        'show_top_n':20,\n",
    "        'show_exclude_columns':qtf.classification.ModelResults.exclude_columns1\n",
    "    }\n",
    "}\n",
    "\n",
    "params = qtf.classification.Params(params)\n",
    "model_results=qtf.classification.ProgramModelResults(params.program_path)\n",
    "# model_results.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.233Z"
    }
   },
   "outputs": [],
   "source": [
    "params.use_data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.234Z"
    }
   },
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.235Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l $train_dir\n",
    "!ls -l $train_dir/cats | wc -l\n",
    "!ls -l $train_dir/dogs | wc -l\n",
    "!ls -l $train_dir/cats | head -5\n",
    "\n",
    "!ls -l $validation_dir/cats | wc -l \n",
    "!ls -l $validation_dir/dogs | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.237Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_to_array(img_file):\n",
    "    img = load_img(img_file) \n",
    "    img = img.resize((160, 160))\n",
    "    x = img_to_array(img) \n",
    "    return x\n",
    "\n",
    "def images_to_array(image_folder):\n",
    "    files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "    x = np.array([image_to_array(file) for file in files])\n",
    "    return x \n",
    "\n",
    "def load_image_folder(image_folder, classes):\n",
    "    x = None\n",
    "    y = None\n",
    "    for i, class_ in enumerate(classes):\n",
    "        folder = os.path.join(image_folder, class_) \n",
    "        x_ = images_to_array(folder)\n",
    "        y_ = [i]*len(x_)\n",
    "        if x is None:\n",
    "            x = x_\n",
    "            y = y_\n",
    "        else:\n",
    "            x = np.concatenate([x, x_])\n",
    "            y = np.concatenate([y, y_])\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "train_images, train_labels = load_image_folder(train_dir, params.classes)\n",
    "print(train_images.shape, train_labels.shape)\n",
    "\n",
    "test_images, test_labels = load_image_folder(validation_dir, params.classes)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.237Z"
    }
   },
   "outputs": [],
   "source": [
    "if params.train_image_count*len(classes)<len(train_images):\n",
    "    _, train_images, _, train_labels = train_test_split(train_images, train_labels, test_size=params.train_image_count*len(classes), random_state=42)\n",
    "\n",
    "    print(train_images.shape, train_labels.shape)\n",
    "    print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.238Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Data Explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.240Z"
    }
   },
   "outputs": [],
   "source": [
    "qtf.utils.show_images(train_images, train_labels, classes=params.classes, x_num=3, y_num=3, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.241Z"
    }
   },
   "outputs": [],
   "source": [
    "qtf.utils.plot_distribution(train_labels, test_labels, params.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Prepare Data\n",
    "\n",
    "\n",
    "### Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.242Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_datasets = qtf.classification.Datasets(train_images, train_labels, test_images, test_labels, batch_size=params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.243Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_images, sample_labels = iter(raw_datasets.train_dataset).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.245Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_datasets.train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.246Z"
    }
   },
   "outputs": [],
   "source": [
    "qtf.utils.show_images(sample_images.numpy(), sample_labels, classes=params.classes, x_num=3, y_num=8, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.247Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator.fit(train_images)\n",
    "generator = {'train':qtf.classification.AugmentGenerator('augment', data_generator), \n",
    "             'val_test':qtf.classification.DatasetGenerator('val_test')}\n",
    "augment_datasets = qtf.classification.Datasets(train_images, train_labels, test_images, test_labels, \n",
    "                                               generator=generator, batch_size=params.batch_size, \n",
    "                                               use_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, labels = iter(augment_datasets.train_dataset).next() \n",
    "qtf.utils.show_images(images, labels, classes=params.classes, x_num=3, y_num=8, figsize=(12, 4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see orgin images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.249Z"
    }
   },
   "outputs": [],
   "source": [
    "qtf.utils.show_images(train_images, train_labels, classes=params.classes, x_num=3, y_num=8, figsize=(12, 4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create data augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.250Z"
    }
   },
   "outputs": [],
   "source": [
    "augment_datasets = qtf.classification.Datasets(train_images, train_labels, test_images, test_labels, \n",
    "                                               generator=generator, batch_size=params.batch_size, \n",
    "                                               use_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.252Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'use_data_augmentation = {params.use_data_augmentation}')\n",
    "if params.use_data_augmentation:\n",
    "    datasets = augment_datasets\n",
    "else:\n",
    "    datasets = raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.253Z"
    }
   },
   "outputs": [],
   "source": [
    "images, labels = iter(augment_datasets.train_dataset).next() \n",
    "qtf.utils.show_images(images, labels, classes=params.classes, x_num=3, y_num=8, figsize=(12, 4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.254Z"
    }
   },
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.255Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper = qtf.classification.Classification(params, datasets=datasets, model_results=model_results, task_type='image')\n",
    "model = qtf.classification.image_models.mlp1(helper, name='mlp1', preprocess_fun=rescale)\n",
    "model.summary()\n",
    "history = helper.train(model)\n",
    "helper.model_summary(model, history, show_sample_analysis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### LeNet\n",
    "\n",
    "![image-20201019113632136](images/image-20201019113632136.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.257Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper = qtf.classification.Classification(params, datasets=datasets, model_results=model_results, task_type='image')\n",
    "model = qtf.classification.image_models.lenet1(helper, name='lenet1', preprocess_fun=rescale)\n",
    "model.summary()\n",
    "history = helper.train(model)\n",
    "helper.model_summary(model, history, show_sample_analysis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.259Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper = qtf.classification.Classification(params, datasets=datasets, model_results=model_results, task_type='image')\n",
    "model = qtf.classification.image_models.custom1(helper, name='custom1', preprocess_fun=rescale)\n",
    "model.summary()\n",
    "history = helper.train(model)\n",
    "helper.model_summary(model, history, show_sample_analysis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.260Z"
    }
   },
   "outputs": [],
   "source": [
    "rescale1 = tf.keras.layers.Rescaling(1./255.0)\n",
    "for data, label in datasets.train_dataset.take(1):\n",
    "    print(data[0][0][0:5]) \n",
    "    print(rescale(data)[0][0][0:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.261Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "helper = qtf.classification.Classification(params, datasets=datasets, model_results=model_results, task_type='image')\n",
    "model = qtf.classification.image_models.vgg1(helper, name='vgg8', dense_layer_count=1, block_count=3, \n",
    "                                             preprocess_fun=rescale)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.262Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = helper.train(model)\n",
    "helper.model_summary(model, history, show_sample_analysis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet\n",
    "\n",
    "see https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/blob/master/chapter2-deep-networks/resnet-cifar10-2.2.1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.264Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper = qtf.classification.Classification(params, datasets=datasets, model_results=model_results, task_type='image')\n",
    "model = qtf.classification.image_models.resnet_v1(helper, name='resnet_v1', depth=20, preprocess_fun=rescale)\n",
    "model.summary()\n",
    "history = helper.train(model)\n",
    "helper.model_summary(model, history, show_sample_analysis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model + Fune-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.265Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = [160, 160, 3]\n",
    "\n",
    "def resize(shape):\n",
    "    def resize_(x):\n",
    "        return tf.image.resize(x, shape)\n",
    "    return resize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.266Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_fun =  [rescale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.267Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_images1 = resize(input_shape[:-1])(sample_images)\n",
    "print(sample_images1.shape, type(sample_images1)) \n",
    "qtf.utils.show_images(sample_images1.numpy(), sample_labels, classes=params.classes, x_num=3, y_num=8, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.268Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.269Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretrained_model(helper, base_model, dropout=None, name='pretrained_model', last_activation=None, preprocess_fun=None):\n",
    "    if dropout is None:\n",
    "        dropout = helper.params.get_model_param(name, 'dropout')\n",
    "\n",
    "    input_shape = qbz95.tf.classification.get_input_shape(helper.datasets.train_dataset)\n",
    "    input = layers.Input(shape=input_shape)\n",
    "    x = qbz95.tf.classification.image_models.process_funs(input, preprocess_fun)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if dropout > 0: x = layers.Dropout(dropout)(x)\n",
    "    x = helper.get_dense_layer(len(helper.params.classes), activation=last_activation)(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=x, name=name)\n",
    "    helper.compile(model)\n",
    "    return model\n",
    "\n",
    "def fine_tuning(helper, model, base_model, fine_tune_at, learning_rate=0.00001):\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=helper.params.metrics)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.270Z"
    }
   },
   "outputs": [],
   "source": [
    "helper = qtf.classification.Classification(params, datasets=datasets, model_results=model_results, task_type='image')\n",
    "model = pretrained_model(helper, base_model, dropout=0.2, name='pretrained-MobileNetV2', preprocess_fun=preprocess_fun)\n",
    "print(f'len(model.trainable_variables)={len(model.trainable_variables)}')\n",
    "model.summary()\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(datasets.test_dataset)\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.272Z"
    }
   },
   "outputs": [],
   "source": [
    "history = helper.train(model, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.273Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fine_tuning(helper, model, base_model, fine_tune_at=100, learning_rate=0.00001)\n",
    "print(f'len(model.trainable_variables)={len(model.trainable_variables)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.274Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = helper.train(model, epochs=10)\n",
    "helper.model_summary(model, history, show_sample_analysis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T07:04:19.365239Z",
     "start_time": "2021-07-21T07:04:19.280940Z"
    }
   },
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.275Z"
    }
   },
   "outputs": [],
   "source": [
    "data_model_results = qtf.classification.DataModelResults(params.data_path) \n",
    "data_model_results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.276Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "predictors = qtf.classification.Predictor.get_top_n_predictors(5, data_model_results)\n",
    "\n",
    "best_predictor = predictors[0]\n",
    "best_predictor.model.compile(optimizer=optimizers.Adam(learning_rate=params.learning_rate),\n",
    "                        loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=['accuracy', 'mae'])\n",
    "\n",
    "qtf.utils.plot_model_structure(best_predictor.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.277Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qtf.utils.plot_sample_image_analysis(predictors, test_images, test_labels,\n",
    "                                    sample_count=5, show_error_sample=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.278Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qtf.utils.plot_sample_image_analysis(predictors, test_images, test_labels,\n",
    "                                    sample_count=5, show_error_sample=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.279Z"
    }
   },
   "outputs": [],
   "source": [
    "results = best_predictor.evaluate(test_images, test_labels)\n",
    "print(results)\n",
    "\n",
    "predictions = best_predictor.predict(test_images)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.280Z"
    }
   },
   "outputs": [],
   "source": [
    "top1_predictions = best_predictor.predict_top_k(test_images, test_labels, top_k=1)\n",
    "top1_scores = qtf.utils.score(test_labels, top1_predictions, params.classes)\n",
    "display(top1_scores)\n",
    "print('-'*100)\n",
    "print(classification_report(test_labels, top1_predictions, digits=4, target_names=params.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-17T04:59:53.282Z"
    }
   },
   "outputs": [],
   "source": [
    "qtf.utils.plot_confusion_matrix(test_labels, top1_predictions, params.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Text classification Guide](https://developers.google.com/machine-learning/guides/text-classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.141px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kacjWOkdcrsj"
   },
   "source": [
    "# Stateful RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhsV_BGJcrsu"
   },
   "source": [
    "In this reading notebook you will learn how to retain the state of an RNN when processing long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T00:47:02.333480Z",
     "start_time": "2020-12-16T00:46:59.386800Z"
    },
    "id": "dZopJXLucrsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "print('GPU name: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df6Illw4crs0"
   },
   "source": [
    "So far you have trained RNNs on entire sequences, possibly of varying length. In some applications, such as financial time series modeling or real-time speech processing, the input sequence can be very long. \n",
    "\n",
    "One way to process such sequences is to simply chop up the sequences into separate batches. However, the internal state of the RNN would then normally be reset in between the batches. Persisting an RNN cell's state between batches is useful in such contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB9H_kh8crs0"
   },
   "source": [
    "## Stateful and non-stateful RNN models\n",
    "We will begin by creating two versions of the same RNN model. The first is a regular RNN that does not retain its state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T01:18:07.384262Z",
     "start_time": "2020-12-16T01:18:07.114637Z"
    },
    "id": "YyaZ_DCjcrs1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn (GRU)                    (None, 5)                 120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a regular (non-stateful) RNN\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, LSTM\n",
    "\n",
    "gru = Sequential([\n",
    "    GRU(5, input_shape=(None, 1), name='rnn')\n",
    "])\n",
    "\n",
    "gru.summary()\n",
    "# states = gru.layers[0].states\n",
    "# print(len(states), states[0].shape)\n",
    "# states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pHd394Mcrs1"
   },
   "source": [
    "To persist RNN cell states between batches, you can use the `stateful` argument when you initialize an RNN layer. The default value of this argument is `False`. This argument is available for all RNN layer types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T00:52:32.703514Z",
     "start_time": "2020-12-16T00:52:32.443580Z"
    },
    "id": "BhsAsRkFcrs1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "stateful_rnn (GRU)           (2, 5)                    120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 (2, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a stateful RNN\n",
    "\n",
    "stateful_gru = Sequential([\n",
    "    GRU(5, stateful=True, batch_input_shape=(2, None, 1), name='stateful_rnn')\n",
    "])\n",
    "\n",
    "stateful_gru.summary()\n",
    "states = stateful_gru.layers[0].states\n",
    "print(len(states), states[0].shape)\n",
    "states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjZPSz6Pcrs2"
   },
   "source": [
    "Note that as well as setting `stateful=True`, we have also specified the `batch_input_shape`. This fixes the number of elements in a batch, as well as providing the sequence length and number of features. So the above model will always require a batch of 2 sequences.\n",
    "\n",
    "When using stateful RNNs, it is necessary to supply this argument to the first layer of a `Sequential` model. This is because the model will always assume that each element of every subsequent batch it receives will be a continuation of the sequence from the corresponding element in the previous batch.\n",
    "\n",
    "Another detail is that when defining a model with a stateful RNN using the functional API, you will need to specify the `batch_shape` argument as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T01:11:36.142926Z",
     "start_time": "2020-12-16T01:11:35.873554Z"
    },
    "id": "UtoO6QXacrs2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine the same stateful RNN using the functional API\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "inputs = Input(batch_shape=(2, None, 1))\n",
    "outputs = GRU(5, stateful=True, name='stateful_rnn')(inputs)\n",
    "\n",
    "stateful_gru = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "states = stateful_gru.layers[1].states\n",
    "print(len(states), states[0].shape)\n",
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T01:22:47.590592Z",
     "start_time": "2020-12-16T01:22:46.977454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        [(2, None, 1)]            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_35 (Bidirectio (2, 10)                   280       \n",
      "=================================================================\n",
      "Total params: 280\n",
      "Trainable params: 280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "stateful_rnn\n",
      "2\n",
      "--------------------------------------------------\n",
      "backward_stateful_rnn\n",
      "2\n",
      "(2, 5) <tf.Variable 'bidirectional_35/backward_stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.]], dtype=float32)>\n",
      "(2, 5) <tf.Variable 'bidirectional_35/backward_stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(batch_shape=(2, None, 1))\n",
    "outputs = Bidirectional(layer=LSTM(5, stateful=True, name='stateful_rnn'))(inputs)\n",
    "# outputs = Bidirectional(layer=LSTM(5, stateful=True, name='stateful_rnn'),\n",
    "#                         backward_layer = GRU(5, stateful=True, name='backward_stateful_rnn', go_backwards=True)\n",
    "#                        )(inputs)\n",
    "\n",
    "stateful_gru = Model(inputs=inputs, outputs=outputs)\n",
    "stateful_gru.summary()\n",
    "\n",
    "# Bidirectional里面只有backward_layery有States，原因何在\n",
    "states = stateful_gru.layers[1].layer.states\n",
    "print(stateful_gru.layers[1].layer.name)\n",
    "print(len(states))\n",
    "for state in states:\n",
    "    if state is not None:\n",
    "        print(state.shape , state)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "states = stateful_gru.layers[1].backward_layer.states\n",
    "print(stateful_gru.layers[1].backward_layer.name)\n",
    "print(len(states))\n",
    "for state in states:\n",
    "    if state is not None:\n",
    "        print(state.shape , state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IXB_wvPcrs2"
   },
   "source": [
    "### Inspect the RNN states\n",
    "We can inspect the RNN layer states by retrieving the recurrent layer from each model, and looking at the `states` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:05.990976Z",
     "start_time": "2020-12-14T14:09:05.986359Z"
    },
    "id": "INekGdOkcrs3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "gru.get_layer('rnn').states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:06.679027Z",
     "start_time": "2020-12-14T14:09:06.670923Z"
    },
    "id": "NW-VpXGEcrs3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNeEVLimcrs3"
   },
   "source": [
    "Note that the internal state of the stateful RNN has a state stored for each element in a batch, which is why the shape of the state Variable is `(2, 5)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZiGG1mOcrs3"
   },
   "source": [
    "### Create a simple sequence dataset\n",
    "We will demonstrate the effect of statefulness on a simple sequence dataset consisting of two sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:10.383994Z",
     "start_time": "2020-12-14T14:09:10.374221Z"
    },
    "id": "wMxbAmQecrs3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 9, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the sequence dataset\n",
    "\n",
    "sequence_data = tf.constant([\n",
    "    [[-4.], [-3.], [-2.], [-1.], [0.], [1.], [2.], [3.], [4.]],\n",
    "    [[-40.], [-30.], [-20.], [-10.], [0.], [10.], [20.], [30.], [40.]]\n",
    "], dtype=tf.float32)\n",
    "sequence_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Akgr-N8crs4"
   },
   "source": [
    "### Process the sequence batch with both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8fHsQ-hcrs4"
   },
   "source": [
    "Now see what happens when you pass the batch of sequences through either model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:14.496623Z",
     "start_time": "2020-12-14T14:09:14.484799Z"
    },
    "id": "BSM34a8scrs4"
   },
   "outputs": [],
   "source": [
    "# Process the batch with both models\n",
    "\n",
    "_1 = gru(sequence_data)\n",
    "_2 = stateful_gru(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:19.895049Z",
     "start_time": "2020-12-14T14:09:19.887092Z"
    },
    "id": "xuzolMaEcrs4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "gru.get_layer('rnn').states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:21.575083Z",
     "start_time": "2020-12-14T14:09:21.568350Z"
    },
    "id": "WohRucgocrs5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[ 0.56634927, -0.5143654 ,  0.11323077, -0.3098507 ,  0.38285917],\n",
       "        [-0.09284443,  0.45850012, -0.21524496,  0.42768195, -0.628173  ]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQjQSJROcrs5"
   },
   "source": [
    "The stateful RNN model has updated and retained its state after having processed the input sequence batch. This internal state could then be used as the initial state for processing a continuation of both sequences in the next batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5KDphl5crs5"
   },
   "source": [
    "### Resetting the internal state\n",
    "If you need a stateful RNN to forget (or re-initialise) its state, then you can call an RNN layer's `reset_states()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:23.876046Z",
     "start_time": "2020-12-14T14:09:23.872497Z"
    },
    "id": "ykn78AaCcrs5"
   },
   "outputs": [],
   "source": [
    "# Reset the internal state of the stateful RNN model\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:24.527471Z",
     "start_time": "2020-12-14T14:09:24.521948Z"
    },
    "id": "6lp6BH8xcrs5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umW72Lvzcrs6"
   },
   "source": [
    "Note that `reset_states()` resets the state to `0.`, which is the default initial state for the RNN layers in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVExRUoDcrs6"
   },
   "source": [
    "### Retaining internal state across batches\n",
    "Passing a sequence to a stateful layer as several subsequences produces the same final output as passing the whole sequence at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:09:33.024299Z",
     "start_time": "2020-12-14T14:09:33.010928Z"
    },
    "id": "q2PfFCHccrs6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[ 0.56634927, -0.5143654 ,  0.11323077, -0.3098507 ,  0.38285917],\n",
       "        [-0.09284443,  0.45850012, -0.21524496,  0.42768195, -0.628173  ]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the internal state of the stateful RNN model and process the full sequences\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').reset_states()\n",
    "_ = stateful_gru(sequence_data)\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:08:21.470320Z",
     "start_time": "2020-12-14T14:08:21.460829Z"
    },
    "id": "eXhhfzw8crs6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch: tf.Tensor(\n",
      "[[[ -4.]\n",
      "  [ -3.]\n",
      "  [ -2.]]\n",
      "\n",
      " [[-40.]\n",
      "  [-30.]\n",
      "  [-20.]]], shape=(2, 3, 1), dtype=float32)\n",
      "\n",
      "Second batch: tf.Tensor(\n",
      "[[[ -1.]\n",
      "  [  0.]\n",
      "  [  1.]]\n",
      "\n",
      " [[-10.]\n",
      "  [  0.]\n",
      "  [ 10.]]], shape=(2, 3, 1), dtype=float32)\n",
      "\n",
      "Third batch: tf.Tensor(\n",
      "[[[ 2.]\n",
      "  [ 3.]\n",
      "  [ 4.]]\n",
      "\n",
      " [[20.]\n",
      "  [30.]\n",
      "  [40.]]], shape=(2, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Break the sequences into batches\n",
    "\n",
    "sequence_batch1 = sequence_data[:, :3, :]\n",
    "sequence_batch2 = sequence_data[:, 3:6, :]\n",
    "sequence_batch3 = sequence_data[:, 6:, :]\n",
    "\n",
    "print(\"First batch:\", sequence_batch1)\n",
    "print(\"\\nSecond batch:\", sequence_batch2)\n",
    "print(\"\\nThird batch:\", sequence_batch3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvCREU6tcrs7"
   },
   "source": [
    "Note that the first element in every batch is part of the same sequence, and the second element in every batch is part of the same sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:10:37.603471Z",
     "start_time": "2020-12-14T14:10:37.568417Z"
    },
    "id": "Wxi6YW-6crs7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[ 0.56634927, -0.5143654 ,  0.11323077, -0.3098507 ,  0.38285917],\n",
       "        [-0.09284443,  0.45850012, -0.21524496,  0.42768195, -0.628173  ]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the internal state of the stateful RNN model and process the batches in order\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').reset_states()\n",
    "_ = stateful_gru(sequence_batch1)\n",
    "_ = stateful_gru(sequence_batch2)\n",
    "_ = stateful_gru(sequence_batch3)\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKivCoxFcrs7"
   },
   "source": [
    "Notice that the internal state of the stateful RNN after processing each batch is the same as it was earlier when we processed the entire sequence at once.\n",
    "\n",
    "This property can be used when training stateful RNNs, if we ensure that each example in a batch is a continuation of the same sequence as the corresponding example in the previous batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9jGNP2_crs8"
   },
   "source": [
    "## Further reading and resources\n",
    "* https://www.tensorflow.org/guide/keras/rnn#cross-batch_statefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:01:34.697007Z",
     "start_time": "2020-12-14T14:01:24.961277Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (32, 32)                  6272      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (32, 10)                  330       \n",
      "=================================================================\n",
      "Total params: 6,602\n",
      "Trainable params: 6,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 11.6780 - accuracy: 0.0969 - val_loss: 11.9005 - val_accuracy: 0.0938\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 11.9389 - accuracy: 0.1031 - val_loss: 12.1251 - val_accuracy: 0.0938\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.0928 - accuracy: 0.1031 - val_loss: 12.2499 - val_accuracy: 0.0938\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.1646 - accuracy: 0.1031 - val_loss: 12.2593 - val_accuracy: 0.0938\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.1579 - accuracy: 0.1031 - val_loss: 12.2493 - val_accuracy: 0.0938\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.1400 - accuracy: 0.1031 - val_loss: 12.2474 - val_accuracy: 0.0938\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.1541 - accuracy: 0.1031 - val_loss: 12.2759 - val_accuracy: 0.0938\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.1807 - accuracy: 0.1031 - val_loss: 12.3148 - val_accuracy: 0.0938\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.2199 - accuracy: 0.1031 - val_loss: 12.3634 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.2617 - accuracy: 0.1031 - val_loss: 12.4038 - val_accuracy: 0.0938\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.2957 - accuracy: 0.1031 - val_loss: 12.4352 - val_accuracy: 0.0938\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.3221 - accuracy: 0.1031 - val_loss: 12.4589 - val_accuracy: 0.0938\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3419 - accuracy: 0.1031 - val_loss: 12.4763 - val_accuracy: 0.0938\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3563 - accuracy: 0.1031 - val_loss: 12.4887 - val_accuracy: 0.0938\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3665 - accuracy: 0.1031 - val_loss: 12.4974 - val_accuracy: 0.0938\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3736 - accuracy: 0.1031 - val_loss: 12.5033 - val_accuracy: 0.0938\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3783 - accuracy: 0.1031 - val_loss: 12.5072 - val_accuracy: 0.0938\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3813 - accuracy: 0.1031 - val_loss: 12.5096 - val_accuracy: 0.0938\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3831 - accuracy: 0.1031 - val_loss: 12.5109 - val_accuracy: 0.0938\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3840 - accuracy: 0.1031 - val_loss: 12.5114 - val_accuracy: 0.0938\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.3842 - accuracy: 0.1031 - val_loss: 12.5114 - val_accuracy: 0.0938\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3840 - accuracy: 0.1031 - val_loss: 12.5110 - val_accuracy: 0.0938\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3834 - accuracy: 0.1031 - val_loss: 12.5102 - val_accuracy: 0.0938\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3826 - accuracy: 0.1031 - val_loss: 12.5093 - val_accuracy: 0.0938\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3816 - accuracy: 0.1031 - val_loss: 12.5082 - val_accuracy: 0.0938\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3804 - accuracy: 0.1031 - val_loss: 12.5070 - val_accuracy: 0.0938\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3792 - accuracy: 0.1031 - val_loss: 12.5057 - val_accuracy: 0.0938\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3780 - accuracy: 0.1031 - val_loss: 12.5044 - val_accuracy: 0.0938\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3766 - accuracy: 0.1031 - val_loss: 12.5030 - val_accuracy: 0.0938\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.3753 - accuracy: 0.1031 - val_loss: 12.5016 - val_accuracy: 0.0938\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3739 - accuracy: 0.1031 - val_loss: 12.5002 - val_accuracy: 0.0938\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3725 - accuracy: 0.1031 - val_loss: 12.4988 - val_accuracy: 0.0938\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3711 - accuracy: 0.1031 - val_loss: 12.4973 - val_accuracy: 0.0938\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3698 - accuracy: 0.1031 - val_loss: 12.4959 - val_accuracy: 0.0938\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3684 - accuracy: 0.1031 - val_loss: 12.4945 - val_accuracy: 0.0938\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3670 - accuracy: 0.1031 - val_loss: 12.4931 - val_accuracy: 0.0938\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3656 - accuracy: 0.1031 - val_loss: 12.4916 - val_accuracy: 0.0938\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3643 - accuracy: 0.1031 - val_loss: 12.4902 - val_accuracy: 0.0938\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.3629 - accuracy: 0.1031 - val_loss: 12.4888 - val_accuracy: 0.0938\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3615 - accuracy: 0.1031 - val_loss: 12.4875 - val_accuracy: 0.0938\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.3602 - accuracy: 0.1031 - val_loss: 12.4861 - val_accuracy: 0.0938\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3589 - accuracy: 0.1031 - val_loss: 12.4847 - val_accuracy: 0.0938\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3575 - accuracy: 0.1031 - val_loss: 12.4834 - val_accuracy: 0.0938\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3562 - accuracy: 0.1031 - val_loss: 12.4820 - val_accuracy: 0.0938\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3549 - accuracy: 0.1031 - val_loss: 12.4807 - val_accuracy: 0.0938\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3536 - accuracy: 0.1031 - val_loss: 12.4793 - val_accuracy: 0.0938\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3523 - accuracy: 0.1031 - val_loss: 12.4780 - val_accuracy: 0.0938\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.3511 - accuracy: 0.1031 - val_loss: 12.4767 - val_accuracy: 0.0938\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.3498 - accuracy: 0.1031 - val_loss: 12.4754 - val_accuracy: 0.0938\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.3485 - accuracy: 0.1031 - val_loss: 12.4741 - val_accuracy: 0.0938\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 12.4741 - accuracy: 0.0938\n",
      "\n",
      "MSE: 12.474, RMSE: 3.532\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "# 请注意，我们必须提供完整的 batch_input_shape，因为网络是有状态的。\n",
    "# 第 k 批数据的第 i 个样本是第 k-1 批数据的第 i 个样本的后续。\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "# model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "# model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))      # (320, 8, 16)\n",
    "y_train = np.random.random((batch_size * 10, num_classes))              # (320, 10)\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))     # (96, 8, 16)\n",
    "y_val = np.random.random((batch_size * 3, num_classes))\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print(\"Epoch {:d}/{:d}\".format(i+1, num_epochs))\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_val, y_val), shuffle=False)\n",
    "    model.reset_states()\n",
    "\n",
    "score, _ = model.evaluate(x_val, y_val, batch_size=batch_size)      # 返回误差值和度量值\n",
    "rmse = math.sqrt(score)\n",
    "print(\"\\nMSE: {:.3f}, RMSE: {:.3f}\".format(score, rmse))\n",
    "\n",
    "pre = model.predict(x_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T01:28:03.401699Z",
     "start_time": "2020-12-16T01:28:03.086988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (4, 32)                   6272      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (4, 10)                   330       \n",
      "=================================================================\n",
      "Total params: 6,602\n",
      "Trainable params: 6,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, batch_input_shape=(4, 10, 16)))\n",
    "# model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "# model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Stateful RNNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yuytuIllsv1"
   },
   "source": [
    "\n",
    "# Assignment 2: Transformer Summarizer\n",
    "\n",
    "Welcome to the second assignment of course 4. In this assignment you will explore summarization using the transformer model. Yes, you will implement the transformer decoder from scratch, but we will slowly walk you through it. There are many hints in this notebook so feel free to use them as needed. \n",
    "\n",
    "<img src = \"transformerNews.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-3lxSnXRWPx"
   },
   "source": [
    "## Outline\n",
    "\n",
    "- [Introduction](#0)\n",
    "- [Part 1: Importing the dataset](#1)\n",
    "    - [1.1 Encode & Decode helper functions](#1.1)\n",
    "    - [1.2 Defining parameters](#1.2)\n",
    "    - [1.3 Exploring the data](#1.3)\n",
    "- [Part 2: Summarization with transformer](#2)\n",
    "    - [2.1 Dot product attention](#2.1)\n",
    "        - [Exercise 01](#ex01)\n",
    "    - [2.2 Causal Attention](#2.2)\n",
    "        - [Exercise 02](#ex02)\n",
    "    - [2.3 Transformer decoder block](#2.3)\n",
    "        - [Exercise 03](#ex03)\n",
    "    - [2.4 Transformer Language model](#2.4)\n",
    "        - [Exercise 04](#ex04)\n",
    "- [Part 3: Training](#3)\n",
    "    - [3.1 Training the model](#3.1)\n",
    "        - [Exercise 05](#ex05)\n",
    "- [Part 4: Evaluation](#4)\n",
    "    - [4.1 Loading in a trained model](#4.1)\n",
    "- [Part 5: Testing with your own input](#5) \n",
    "    - [Exercise 6](#ex06)\n",
    "    - [5.1 Greedy decoding](#5.1)\n",
    "        - [Exercise 07](#ex07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4NlfEQhRWPy"
   },
   "source": [
    "<a name='0'></a>\n",
    "### Introduction\n",
    "\n",
    "Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Anyways who wants to read an article or a long email today, when you can build a transformer to summarize text for you. Let's get started, by completing this assignment you will learn to:  \n",
    "\n",
    "- Use built-in functions to preprocess your data\n",
    "- Implement DotProductAttention\n",
    "- Implement Causal Attention\n",
    "- Understand how attention works\n",
    "- Build the transformer model\n",
    "- Evaluate your model\n",
    "- Summarize an article\n",
    "\n",
    "As you can tell, this model is slightly different than the ones you have already implemented. This is heavily based on attention and does not rely on sequences, which allows for parallel computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:57:16.712719Z",
     "start_time": "2021-08-16T01:57:16.708503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuDevice(id=0, process_index=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "import os\n",
    "\n",
    "print(jax.devices())\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false'\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='.30'\n",
    "# 内存分配由平台决定，据说非常慢\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:57:21.440171Z",
     "start_time": "2021-08-16T01:57:21.436034Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CChWzW-rEHVb",
    "outputId": "a0b3e98b-7fc6-492d-c8ad-3a263b54f670"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "\n",
    "# to print the entire np array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEL2rvaHRWP4"
   },
   "source": [
    "<a name='1'></a>\n",
    "## Part 1: Importing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trax makes it easy to work with Tensorflow's datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:57:24.982291Z",
     "start_time": "2021-08-16T01:57:24.853555Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VInmKSkhEhle"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/jax/lib/xla_bridge.py:356: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
      "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
      "/usr/local/lib/python3.6/dist-packages/jax/lib/xla_bridge.py:369: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n"
     ]
    }
   ],
   "source": [
    "# This will download the dataset if no data_dir is specified.\n",
    "# Downloading and processing can take bit of time,\n",
    "# so we have the data already in 'data/' for you\n",
    "\n",
    "# Importing CNN/DailyMail articles dataset\n",
    "train_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                 data_dir='data/',\n",
    "                                 keys=('article', 'highlights'),\n",
    "                                 train=True)\n",
    "\n",
    "# This should be much faster as the data is downloaded already.\n",
    "eval_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                data_dir='data/',\n",
    "                                keys=('article', 'highlights'),\n",
    "                                train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "## 1.1 Tokenize & Detokenize helper functions\n",
    "\n",
    "Just like in the previous assignment, the cell above loads in the encoder for you. Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your [Trax](https://github.com/google/trax) models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following: \n",
    "\n",
    "- <span style='color:blue'> word2Ind: </span> a dictionary mapping the word to its index.\n",
    "- <span style='color:blue'> ind2Word:</span> a dictionary mapping the index to its word.\n",
    "- <span style='color:blue'> word2Count:</span> a dictionary mapping the word to the number of times it appears. \n",
    "- <span style='color:blue'> num_words:</span> total number of words that have appeared. \n",
    "\n",
    "Since you have already implemented these in previous assignments of the specialization, we will provide you with helper functions that will do this for you. Run the cell below to get the following functions:\n",
    "\n",
    "- <span style='color:blue'> tokenize: </span> converts a text sentence to its corresponding token list (i.e. list of indices). Also converts words to subwords.\n",
    "- <span style='color:blue'> detokenize: </span> converts a token list to its corresponding sentence (i.e. string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:22.873156Z",
     "start_time": "2021-08-16T01:58:22.868047Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "djTiSLcaNFGa"
   },
   "outputs": [],
   "source": [
    "def tokenize(input_str, EOS=1):\n",
    "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  \n",
    "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
    "    # we get around it by making a 1-element stream with `iter`.\n",
    "    inputs =  next(trax.data.tokenize(iter([input_str]),\n",
    "                                      vocab_dir='vocab_dir/',\n",
    "                                      vocab_file='summarize32k.subword.subwords'))\n",
    "    \n",
    "    # Mark the end of the sentence with EOS\n",
    "    return list(inputs) + [EOS]\n",
    "\n",
    "def detokenize(integers):\n",
    "    \"\"\"List of ints to str\"\"\"\n",
    "  \n",
    "    s = trax.data.detokenize(integers,\n",
    "                             vocab_dir='vocab_dir/',\n",
    "                             vocab_file='summarize32k.subword.subwords')\n",
    "    \n",
    "    return wrapper.fill(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WvhaFbCRWQS"
   },
   "source": [
    "<a name='1.2'></a>\n",
    "\n",
    "## 1.2 Preprocessing for Language Models: Concatenate It!\n",
    "\n",
    "This week you will use a language model -- Transformer Decoder -- to solve\n",
    "an input-output problem. As you know, language models only predict the next\n",
    "word, they have no notion of inputs. To create a single input suitable for\n",
    "a language model, we concatenate inputs with targets putting a separator\n",
    "in between. We also need to create a mask -- with 0s at inputs and 1s at targets -- so that the model is not penalized for mis-predicting the article and only focuses on the summary. See the preprocess function below for how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:27.914699Z",
     "start_time": "2021-08-16T01:58:27.653736Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "c4rgPxYSRWQS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1478,)\n",
      "[   27    82   343   229 14980    61   209   475 20374  5346   565   285\n",
      "  7573 13365     5   246  1922  1908   527    50 18156  7403    45   320\n",
      "  3969  2185   320  2444    28    82  1186     3     9   184    10    59\n",
      "     3   343 20178  4271 19967  1019   117 26336  3732    80   186   233\n",
      "   285   213  1501   632 24385    17  2111   239   213    55   527    82\n",
      " 26336  3846     3    52   146  1349   161   646  1248   671 19967  1019\n",
      "   213   632   117 19718  4348 19810    20  3732   957   186  2704   213\n",
      "   632  1353  2458  6415 10475   691    82  7828  1838 19718  4348     3\n",
      "    27    82   343   229 14980    61   209   475 20374  5346   565   285\n",
      "  7573 13365     5   246  1922  1908   527 18156  7403    45   320  3969\n",
      "  2185   320  2444    50    82  1186     3     9   184    10    59     3\n",
      "   343 20178  4271 19967  1019   117 26336  3732    80   186   233   285\n",
      "   213  1501   632 24385    17  2111   239   213    55   527    82  2067\n",
      "  7828   379     9   343     2  9033   691  4615   167  6597   778 12167\n",
      "  6174 20174     4     2  2243  2065   285   213 25521  5597  6710     6\n",
      "   230   458   229 19266 10280  8463  2304    50   292  1043     3 10724\n",
      "  1019   213   119   262  1585     2 23340  9181     4 11548 10779 10440\n",
      "   163     2    28  3707   527  7493   809  4615     2   897   213   646\n",
      "   412   117  7673  8503   117  4021 18049    47     7    26   125   395\n",
      "  3309   602   320   191    31   292  1184   256  2323  9627    41   973\n",
      "    28 22715    36 14065   368 11548 10779 10440   163  1113 23707  6050\n",
      " 13459  1628   312    33  3224   213  2993   186   490   213  2292   238\n",
      "     2   285     7     5   163  3466  1099     9   343   146  1349   161\n",
      "   646  1248   671 19967  1019   213   632   117 19718  4348 19810    20\n",
      "  3732   957   186   233   213   632  1353  2458  6415 10475   691    82\n",
      "  7828  1838 19718  4348   379   639    87  6676  1850  5646  4164  4385\n",
      "     7    26  8561    28  3732   246     2   469  1534   285  7573   229\n",
      " 10280  8463  2304  1922  9683   123  2175  9342  1782    56   229   654\n",
      "   817  3898    36  5006  1113  1782   223    33   483   320   923   109\n",
      " 26336  1260   809   213   164  5629   124    19   124   213  2175 19799\n",
      "   285  1041    64   210   635   711   527    28    82 26336  1186  3898\n",
      "  2764   104     2  6688  5496 23709     4     2    43   970   132   213\n",
      "   119   262  1585     2  1689  2514   285  7573   143  1151  2942   213\n",
      "    82  2292   238    90   103    86   578  5540  1248   213 20509  1036\n",
      "   527   213  1184     3   305   127    68 26336    66   345    28   621\n",
      " 24211  7511   131 11109    17  2210  6644   112    70   186   285   213\n",
      "    86  2473  2453   320  1151   320  2444   213 26336    65     3  2905\n",
      "  5496 23709     4  5754  7573   527   523   655    64   527  1414    90\n",
      "  1353  1429   320   669 27439  6050 13459  1628 21184 10815 11557 29725\n",
      "   391    50  2982    71  8068   213    82 26336  2342    59   186  2342\n",
      "    96   166    41   615  2951     3  1561  2065 10547   375 20247 26368\n",
      "   275  1779    18   209   475   285  7573 19620     5   132   669 27439\n",
      "  6050 13459  1628  2935 13531  4836 11290  1245 29725     2    28   632\n",
      "  1480    23    46   239   254   213  1109 12865   132   213  6996     3\n",
      "     9  1261   834   285 13894   527  1327  1838  3040   320  3275  7447\n",
      "  1463   132    28   847  7439   320    28  1184   186   146   103    39\n",
      "  1365  1477   477     2 11012  5964   320  2444    28    82    36     3\n",
      "   244  7573    23  3697 11498   285   103   229  8272   527  2935 13531\n",
      "  4836 11290  1245   171     3  2764   104     2  6688  5496 23709     4\n",
      "     2    43   970   132   213   119   262  1585     2  1689  2514   285\n",
      "  7573   143  1151  2942   213    82  2292   238    90   103    86   578\n",
      "  5540  1248   213 20509  1036   527   213  1184   379    27  1098  5312\n",
      "    23 14487  7573 29725     4     5  2210  6644  2175  1727  4840  4808\n",
      " 15522  2332   285   143  1151   149   691  3427   320 23117    78 26336\n",
      "   186 18156  1600  2185     3 17895   809   213   117 18235   185    78\n",
      "  5386  2078    80  1900   132   119   262     2  6474  1774 17912 20982\n",
      "  3955   127   285    94  2185  1435  2458  6278   527   213  1430   527\n",
      "  1660  1019 26336   274     3    69   969  3080   233  6655   210   213\n",
      "  2300     7     5  2175  2586    28  2390     6 19100     4   332   285\n",
      "    49  1151   149   320   690   213  2326     7     5  1319   349     2\n",
      "  3347     2 20952  3072   186   116  2891 15750    17    78   213  2993\n",
      "     3   342     2  7573    23  6503   213  2065   213  4449  2278  1353\n",
      "   836 19266  1019   266   181 11519  2316     3   405  2694  1005  1121\n",
      "  1402   527   213 16875     4  6970  1049    78  7573  1043     2  1480\n",
      "  2266    28   669 27439  6050 13459  1628  4449  2278 29725   391   132\n",
      "  2210  6644   143   430 10642   185  1248  4130   215     3    27  4449\n",
      "  2278   229    28  6655  6021   690  1966   285    49  1350   872  1466\n",
      "   320   690    28  2993  1248   445  7643     3     9  4759  1353   230\n",
      "    78   163   641   527  4228   446  2210  6644  3568     2  1248  3696\n",
      "  2633  1260   213    94   772  4948   527   213  2175   809   695   993\n",
      "     3   312   103   721   354    44  5838   318     6 16595 21232     5\n",
      "  4853   127   103  1353   320  1477  2185  1269    71   213  2067   186\n",
      " 12173    16   103   880   122    77  1353    28   917     3  5674     2\n",
      "   132   420  7573  1353 11284    21   132  3221   691   213 10999  1138\n",
      "   527  5530   186  1396 14001    95   213  3846   527   213 18156  1600\n",
      "  1891     3     9  4716  2663   285   166   103    40   213    82 25066\n",
      "    28  2423   103   133   213 18156  1600    53 22174    26   186   285\n",
      "  7573  1353  2388    50  3568   403  1746     3  2905  5496 23709     4\n",
      "   127  4601 27439  6050 13459  1628   312   407 17585  1469    64   527\n",
      "  1591     2   186 16808    16 13169  3035 13862     5   320 12242     4\n",
      "   236 13178  2982     2  1095   107  7573    49   234   245    28 11148\n",
      "     4  1838   213  4018   748 23707  6050 13459  1628   223    33    49\n",
      " 21184 10815 11557  5964    71  1866    82 15672     5   285   191   213\n",
      "   292  3926   615 16336  2299  1019 10637   634    74  4546  1806     2\n",
      "    33   234    18    28  1496   809 14223    16    44  1781  1838   109\n",
      "  1259  4157  1160     3 13510     4  5086  3077     2  6518  1757   527\n",
      "   982     6   230  2210  6644  4853     2 13014    78 13419     2   793\n",
      "  6676  1850  5646   285    22  1202 29725     4    26  1029  7573  1435\n",
      "   981   824 15775   114 23707  6050 13459  1628   252   374  9751  1186\n",
      "    41  4201   320 19799   213 25617     4   186    41  1435  6939   374\n",
      "    55    41  1435   973  4617 29725   391    22   127 23707  6050 13459\n",
      "  1628  1888   104    41  1186    28    82  2210  6644     3   223    33\n",
      " 29725     4   165  1260   163  2210  6644   112    78    28    65 22566\n",
      "     2  1019   419     2   103 29725     4     5  8227   320  1260  9006\n",
      " 15459     4    78    28  9006  1848  2029 23707  6050 13459  1628    52\n",
      " 29725     4     5   141   811   320 18096     4   213  2185     2    35\n",
      "   103 29725     4     5  1048   122    33   483   213  5047   558   527\n",
      "    82   930   285  7573  7828   193   104  4172 29725   391   368 11548\n",
      " 10779 10440   163   969   285   213   315   302    19  4391   285  7573\n",
      "    23   757  1298  2297     3   321  1106  7270 19341  7552   940     2\n",
      "    22   465     2   213   274  1847  1202     7    26  1350  1815   320\n",
      "  2073 17012 19359   647    31  2067   229   116 24211     3   198  1435\n",
      "    54 20996  1019 11406   163  1922   682 26336   108  3732   246     2\n",
      "    22  2065     3   174  2410     2   213  2150  1036   527   213  7573\n",
      "  2292   238     2  2210  6644     2   229   452 14720    17   320   213\n",
      " 20509  2993   186   108  1211    19   126   412 18289    78  1922  1908\n",
      " 23707  6050 13459  1628 11174    16  2685    28    82  1186   825    33\n",
      " 15420    14  1269    28    82   186  6939  2067  4617 29725   391    22\n",
      "   969 23707  6050 13459  1628   244    33  6803  3078  7270  3732   109\n",
      "   292  2067   229  4172 29725   391  7573   229   764   320  5224     3\n",
      "   200   368 11548 10779 10440   163   969   285   213   315   302    19\n",
      "  4391   285  7573    23   757  1298  2297    10   321  1106  7270 19341\n",
      "  7552   940     2    22   465     2   213   274  1847  1202     7    26\n",
      "  1350  1815   320  2073 17012 19359   647    31  2067   229   116 24211\n",
      "  2104     1     0     9   343  1353  6044   691   778 12167  6174 20174\n",
      "     4   809  4615   167 16346 27439  6774  1628    52    43  1349  7573\n",
      "     7     5   646  1248 19967  1019   117 19718  4348 19810    20  3732\n",
      "  6053 27439  6774  1628   946   233   285   213   632  1353  2458  6415\n",
      " 10475   691 19718  4348    82  7828 16346 27439  6774  1628  3117    23\n",
      " 10547   375 11137  7573 19620     5   132   669 27439  6050 13459  1628\n",
      "  2935 13531  4836 11290  1245 29725 27439  6774  1628  6840   834   285\n",
      " 13894  1463   132    28   847  7439   320    28  1184   186   146   103\n",
      "    39  1365  1477   477     2 11012  5964   320  2444    28    82    36\n",
      "  2104     1]\n",
      "(1478,)\n",
      "(1478,)\n"
     ]
    }
   ],
   "source": [
    "# Special tokens\n",
    "SEP = 0 # Padding or separator token\n",
    "EOS = 1 # End of sentence token\n",
    "\n",
    "# Concatenate tokenized inputs and targets using 0 as separator.\n",
    "def preprocess(stream):\n",
    "    for (article, summary) in stream:\n",
    "        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n",
    "        mask = [0] * (len(list(article)) + 2) + [1] * (len(list(summary)) + 1) # Accounting for EOS and SEP\n",
    "        yield joint, joint, np.array(mask)\n",
    "\n",
    "# You can combine a few data preprocessing steps into a pipeline like this.\n",
    "input_pipeline = trax.data.Serial(\n",
    "    # Tokenizes\n",
    "    trax.data.Tokenize(vocab_dir='vocab_dir/',\n",
    "                       vocab_file='summarize32k.subword.subwords'),\n",
    "    # Uses function defined above\n",
    "    preprocess,\n",
    "    # Filters out examples longer than 2048\n",
    "    trax.data.FilterByLength(2048)\n",
    ")\n",
    "\n",
    "# Apply preprocessing to data streams.\n",
    "train_stream = input_pipeline(train_stream_fn())\n",
    "eval_stream = input_pipeline(eval_stream_fn())\n",
    "\n",
    "train_input, train_target, train_mask = next(train_stream)\n",
    "print(train_input.shape)\n",
    "print(train_input)\n",
    "print(train_target.shape)\n",
    "print(train_mask.shape)\n",
    "\n",
    "assert sum((train_input - train_target)**2) == 0  # They are the same in Language Model (LM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:42.652656Z",
     "start_time": "2021-08-16T01:58:42.646122Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "uKFoGsUKSa_I",
    "outputId": "bc4d6634-d716-4311-d49c-1956bca2bc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example mask:\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prints mask, 0s on article, 1s on summary\n",
    "print(f'Single example mask:\\n\\n {train_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:43.784790Z",
     "start_time": "2021-08-16T01:58:43.571333Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "S4uHyCkbSuUo",
    "outputId": "52845be8-f2fc-4803-bf7a-ed9725fe2bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example:\n",
      "\n",
      " A new study is backing up long held suspicions that Apple slows down\n",
      "older models of its iPhones to encourage users to buy a new release.\n",
      "The U.S. study analysed worldwide searches for 'iPhone slow' and found\n",
      "that the search term spiked significantly around the time of new\n",
      "iPhone launch. It then compared those results with similar searches\n",
      "for the term 'Samsung Galaxy slow', and discovered the term was\n",
      "unaffected by new releases from Samsung. A new study is backing up\n",
      "long held suspicions that Apple slows down older models of iPhones to\n",
      "encourage users to buy its new release. The U.S. study analysed\n",
      "worldwide searches for 'iPhone slow' and found that the search term\n",
      "spiked significantly around the time of new phone releases . The\n",
      "study, compiled by Harvard University PhD student Laura Trucco,\n",
      "follows claims that the Cupertino-based company is deliberately\n",
      "sabotaging its old products. Writing for the New York Times, Sendhil\n",
      "Mullainathan, a professor of economics at Harvard, described the\n",
      "results as 'striking'. 'Wouldn't many business owners love to make\n",
      "their old product less useful whenever they released a newer one?' Mr\n",
      "Mullainathan wrote. ‘When you sell the device and control the\n",
      "operating system, that's an option'. The study then compared those\n",
      "results with similar searches for the term 'Samsung Galaxy slow', and\n",
      "found the term was unaffected by new releases from Samsung . While\n",
      "some MailOnline readers haven't noticed a slow down, others claim that\n",
      "Apple is sabotaging older phones through software updates. 'This is\n",
      "common knowledge,' one reader wrote. 'If you want to keep your iPhone\n",
      "running at the same pace do not do the software upgrade that comes out\n",
      "within six months of a new iPhone release,' Last year, Catherine\n",
      "Rampell, also writing in the New York Times, raised concerns that\n",
      "Apple could be engineering the new operating system so it only works\n",
      "properly with the newest version of the product. She said her iPhone 4\n",
      "became a lot slower when she downloaded iOS 7 - and that the only\n",
      "solution seemed to be to buy the iPhone 5. Ms Rampell accused Apple of\n",
      "having run out of ideas so was trying to ‘brainwash’ its customers\n",
      "into buying the new iPhone 5S and 5C because they look nice. Her\n",
      "claims fuelled conspiracy theorists who have long held that Apple\n",
      "engages in ‘planned obsolescence’, a term which has been around since\n",
      "the Great Depression in the 1930s. The theory states that\n",
      "manufacturers of everything from cars to microwaves build in a certain\n",
      "lifetime to a product and then it will simply stop working, forcing\n",
      "consumers to buy a new one. And Apple has faced allegations that it is\n",
      "guilty of planned obsolescence before. Last year, Catherine Rampell,\n",
      "also writing in the New York Times, raised concerns that Apple could\n",
      "be engineering the new operating system so it only works properly with\n",
      "the newest version of the product . A security expert has warned\n",
      "Apple’s iOS software contains potentially sinister tools that could be\n",
      "used by governments to spy on iPhone and iPad users. Speaking at the\n",
      "'Hackers on planet Earth' conference in New York, Jonathan Zdziarski\n",
      "said that most users are unaware of the lack of protection for iPhone\n",
      "data. He added files found hidden within the firm's software contain a\n",
      "file-relay service that can be used to access the user's address book,\n",
      "photos, voicemail and any accounts configured on the device. However,\n",
      "Apple has denied the claims the backdoor was created deliberately for\n",
      "government or surveillance purposes. His investigation followed\n",
      "earlier reports of the NSA spying on Apple products, which suggested a\n",
      "‘backdoor’ in iOS could provide hackers with valuable information. A\n",
      "backdoor is a hidden remote access port that can allow outside sources\n",
      "to access a device with little detection. The conclusion was based on\n",
      "an analysis of 600 million iOS devices, with handsets running the most\n",
      "recent versions of the software at particular risk. When it started\n",
      "using more tamper-resistant screws experts said it was to stop users\n",
      "getting into the phone and fixing it themselves if there was a\n",
      "problem. Meanwhile, in 2012 Apple was sued in Brazil by the Brazilian\n",
      "Institute of Politics and Law Software over the launch of the iPad\n",
      "Air. The organisation claimed that because it had the new retina\n",
      "screen it made the iPad 3 redundant and that Apple was changing its\n",
      "devices too quickly. Ms Rampell said: ‘When major innovations remain\n",
      "out of reach, and degrading durability threatens to tick off loyal\n",
      "customers, companies like Apple can still take a cue from the fashion\n",
      "industry. ‘If you can brainwash consumers into developing new tastes\n",
      "that make the old stuff look uncool for aesthetic rather than\n",
      "functional reasons, you still have a shot at harvesting more sales\n",
      "from your existing customer base. Dom Ferkin, managing direction of\n",
      "UK-based iOS experts, Creation Application, told MailOnline that he\n",
      "doesn’t believe Apple are doing this intentionally. ‘On every hardware\n",
      "release they tend to upgrade the chips and they are faster every time\n",
      "they are released,’ he said. ‘Each year they release a new iOS. If\n",
      "you’re running an iOS 7 on a 5 chip, for example, it’s comparable to\n",
      "running Windows XP on a Windows 95 machine. ‘It’s just enough to annoy\n",
      "the users, but it’s needed if you want the slew of new features that\n",
      "Apple releases each year.’ Mr Mullainathan added that the research\n",
      "does not prove that Apple has done anything wrong. No matter how\n",
      "suggestive, he says, the data alone doesn't allow anyone to determine\n",
      "conclusively whether their phone is any slower. There are other\n",
      "explanations for why an older model iPhone may slow down, he claims.\n",
      "For instance, the latest version of the Apple operating system, iOS,\n",
      "is always tailored to the newest device and may therefore not work as\n",
      "efficiently on older models. ‘Hearing about a new release makes you\n",
      "contemplate getting a new and faster phone,’ he added. ‘And you\n",
      "suddenly notice how slow your old phone is.’ Apple is yet to respond.\n",
      "But Mr Mullainathan added that the research does not prove that Apple\n",
      "has done anything wrong.No matter how suggestive, he says, the data\n",
      "alone doesn't allow anyone to determine conclusively whether their\n",
      "phone is any slower .<EOS><pad>Thestudy was undertaken by student\n",
      "Laura Trucco at Harvard University . It also compared Apple's results\n",
      "with searches for 'Samsung Galaxy slow' Research found that the term\n",
      "was unaffected by Samsung new releases . Study has fuelled suggestions\n",
      "Apple engages in ‘planned obsolescence’ Theory states that\n",
      "manufacturers build in a certain lifetime to a product and then it\n",
      "will simply stop working, forcing consumers to buy a new one .<EOS>\n"
     ]
    }
   ],
   "source": [
    "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
    "print(f'Single example:\\n\\n {detokenize(train_input)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:45.294266Z",
     "start_time": "2021-08-16T01:58:45.242383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b\"Standoff: Goerge Pickering, pictured, allegedly threatened to kill a nurse . A distraught father who caused a four-hour standoff with police in a Texas hospital allegedly pointed his gun at a nurse and yelled 'I'll kill all of y'all'. Police said George Pickering, 57, made the threats from a hospital room after becoming inconsolable over the treatment of his son - a patient in critical care at Tomball Regional Hospital, near Houston. Armed police and a SWAT team descended on the medical center - and eventually convinced Pickering to surrender after a four-hour standoff on Saturday night. Pickering was charged with aggravated assault with a deadly weapon and is being held on a $30,000 bond, a statement from the Tomball Police department said. Detectives said Pickering was in the room with his son and family, waited for a nurse to come, then aimed his 9mm pistol at her. He then allegedly barricaded the room and threatened to kill anybody who came in. At the start of the confrontation, another of Pickering's sons, who was with him in the hospital room, allegedly wrested the gun away from him and handed it to police. Standoff: George Pickering, 57, allegedly threatened to kill a nurse with his pistol at Tomball Regional Hospital, sparking a police standoff . Response: Police and a SWAT team arrived at the hospital. Pickering reportedly had one gun taken from him, but said he had a second . Pickering then allegedly said, 'You don't think that's the only weapon I have?', prompting fears of a second gun and causing the lengthy showdown with police. But when he gave himself up, police found that he was not in fact armed. Early reports stated that Pickering had taken two hostages, but law enforcement later said there were no captives. A spokesman for the Tomball police department said Picerking fell ill during the standoff and was treated in the hospital overnight - and was still there Sunday afternoon. He does not yet have an attorney. Tense: Pickering was said to be distraught over the condition of his son - a critical care patient .\",\n",
       " b'George Pickering, 57, allegedly made threat from hospital room .\\nPolice said he aimed 9mm pistol at nurse inside Tomball Regional Hospital .\\nGun was allegedly wrested away from Pickering - who said he had another .\\nAfter three-hour stand-off with police, he was found to be unarmed .\\nPickering has been charged with aggravated assault with a deadly weapon .')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_stream_fn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4sDS1WIVaYG"
   },
   "source": [
    "<a name='1.3'></a>\n",
    "\n",
    "## 1.3 Batching with bucketing\n",
    "\n",
    "As in the previous week, we use bucketing to create batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:48.480418Z",
     "start_time": "2021-08-16T01:58:48.466282Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oqj1NsbERWQX"
   },
   "outputs": [],
   "source": [
    "# Bucketing to create batched generators.\n",
    "\n",
    "# Buckets are defined in terms of boundaries and batch sizes.\n",
    "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
    "# So below, we'll take a batch of 16 sentences of length < 128 , 8 of length < 256,\n",
    "# 4 of length < 512. And so on. \n",
    "boundaries =  [128, 256,  512, 1024]\n",
    "batch_sizes = [16,    8,    4,    2, 1]\n",
    "\n",
    "# Create the streams.\n",
    "train_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries, batch_sizes)(train_stream)\n",
    "\n",
    "eval_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries, batch_sizes)(eval_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:49.434523Z",
     "start_time": "2021-08-16T01:58:49.416950Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "P6M5OA8QRWQb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1781)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every execution will result in generation of a different article\n",
    "# Try running this cell multiple times to see how the length of the examples affects the batch size\n",
    "input_batch, _, mask_batch = next(train_batch_stream)\n",
    "\n",
    "# Shape of the input_batch\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:50.320722Z",
     "start_time": "2021-08-16T01:58:50.312670Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SjNOlljxTGuQ",
    "outputId": "9227c68c-6369-4ce8-8137-506c594f6ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8476     8 14607  5318 17020 10478   213  5467   328  4878  8420  1387\n",
      "   527  2495  3135   713     2    44    74    42    88   226   101 10128\n",
      "    61  1019    28  1681  4979  8705  3588  1019  1250     7     5  2890\n",
      "   363  1963   320  1151 10409   246     3    27   719   171     2    28\n",
      "   671  6294    76   536   132    28 14039    20  4220 12986     4     2\n",
      "    19    78    28  4873     2 24421    20   194    76  7121  2685  3997\n",
      "     3   244    28   984   527 21327     4     2 25037   204   186 10469\n",
      " 16927    17    95   809  8476 12496  3057   808     7     5  6422  2102\n",
      "   412  1631  1838  3286   239   213  6173 25303 17102    28 12320 22789\n",
      "     4  2890   363  1644 12265   320   288  7511   213  2854   285    23\n",
      " 26635 10693    21    31  8183  1038    62   250  1133 27634     4     9\n",
      "  2890  1644  1359   848   320  1151 10237   412  1132   412   498     3\n",
      "   223    19     2    51  4145    39  2276  4617 27634   391    36   527\n",
      "   213  1631     2  1584  3686    79 14858 22957     4     2   793   213\n",
      "  7938     7     5 15540     3   200   213  1111  1838  2798  7662     4\n",
      "  8787   479     2   213  6518  1108   527  1250     7     5  1088  7938\n",
      "     2  1763   445 22907   320   213 13009   181   213  1272   527   213\n",
      "   175  1133 27634     4   198   229    28   317   320  3067   163   250\n",
      "   320   213   617  1359   412  1132   412   498  4617 27634   391  8787\n",
      "   479   127     2  4195  2035 27634     4   129  6132  2882   320   824\n",
      "   186  1435   892   213  5752    94 16530     5   320  2586   213  8033\n",
      "  4172 27634   391  1191   213   481   253 12151   285 15471  2134  1766\n",
      "  1250     2  1405   809  6173 25303 17102    28 12320 22789     4    18\n",
      "    46 10655   320  4468   246   150  2881 21151 24988     5   186   923\n",
      " 21689   527  1383    35   234 26574  2890  4463  1838 13637   501  6208\n",
      "  1050 21154   467  1766  1250     3    27   984    71   213  2854     2\n",
      "   213  7938 16550     5     2    77   229    92   250   132  5382     3\n",
      "     9   912  1435    90   525   669 27634     4  1254   213   653  1592\n",
      " 27634   391   527   213  1644   285   213  1520  1435   477   132 16774\n",
      " 10076    21  2957     2   127  1096  9721  6379    81     2    28   492\n",
      "  1661  8218   809   184    10    59     3  2890   363  2124  1133 27634\n",
      "     4   321  2890   363  1644    23   545   689   213 18803   320   211\n",
      "    78   209     6   632  1824 20719  1019    44    74    28   719     2\n",
      "   196   256   150  1492  4617 27634   391  9721  6379    81   127     3\n",
      "   716  1520  4853   169   476   213  1587   229   132  6349   527 11842\n",
      "  2707  1250  8461    44   399  1838   566  4853   320  1215   103   320\n",
      "   163   250     3 19334  6399 11955  1584 11196     2   163  7223     6\n",
      "  1411     6   748 10386     2   127   213  1359   229   669 27634     4\n",
      "  1254   213  1591 27634   391   527  1250     7     5  2611 17465    26\n",
      "  2890  3141  1133 27634     4    27   608  8931  2085    23   320   787\n",
      "  1248   163 10130   691   213   175     7     5   448  4853    78  2890\n",
      " 14186  4617 27634   391  1584 11196   793 16235   809  1250     7     5\n",
      "   404  1701  1001   220   719     3 12971   186  1405    90   525    18\n",
      "  2232   320  5965   183   236    28   976 10204   246   132  6173 25303\n",
      " 17102    28 12320 22789     4     7     5 24988     5    32     6    53\n",
      "   186   132   213  1383  4463  3875   527  1676    66     3   200  4853\n",
      "   476   213  2881 21151  4463 10976     5  1435   761   320    18  4133\n",
      "  2333  2211     2   186    77   229    28 21673   232  1019 10236   374\n",
      "  3134     3  6245   527   213   543   719  1353  5099   691   213  1913\n",
      "   320  1477   304 10906    21  1248  3631  4855   527  6208  1050 10295\n",
      "  1838 14527    16    71   213  1580  5127    76   304   285  1041    64\n",
      "   527   213 24988     5   669 27634     4 13670    16  1248  6208   889\n",
      "  4617 27634   391  9721  6379    81   127     3  8476 12496   229   169\n",
      " 26286 26328  1248  4872   320   547   213  3926     2   188 12615    16\n",
      "  2659   527  5570   527   256     6  6208  1050   304    71   213  1580\n",
      "   320   191   796  1019   103   132    28 17213  1019   529     6   338\n",
      "  5389     3    34    28  5944  9505  1644     2 10075  8951     4   304\n",
      "   229 23984    21    64   527   213 24988     5   186 14039    17     3\n",
      "  1486   103     7     5 12932    17   179   132   320  2560    44  4331\n",
      "   463  1838   213  1644     7     5  4463 10976     5     2  1480   952\n",
      "  4237   974   209   102   213  3467  3212   809   213  1348   527   213\n",
      "  1582    23    46  4194  1133 27634     4   267    18   320   211   213\n",
      "  8267  3420 17913   204   238    61   186  9505    90    41    49  4468\n",
      "   285   304   132   213  1923   138  4617 27634   391   127  5904  5670\n",
      "     2    28  2890  2942  3707   809   213   167   527  2254   186    28\n",
      " 14607 13035     3 14394     4 20719   783   358     7    26  1943   213\n",
      "  3631  4855   527   304    76   239   112  8990  5570     8    32    88\n",
      "  5215   121 17119   462    12   318  1807    76   169   144 14527    17\n",
      "    71   213 24988     5  1133 27634     4   449     7     5    28   762\n",
      "   917  4617 27634   391  5670   127     3  8476 12496  1631   793 14607\n",
      "    41    49     7    26   476  7511    41     7   371  1151   217   320\n",
      " 10625   161  1923 20719     3     9    60  1507   229   320   211  1232\n",
      "  6208  1050   304    64   527   213 10541    17 12427   939   527   213\n",
      "  1582    80 15123     4  2124     2   146  1682    64  7270 12438   213\n",
      "  1996  1599    23    46  7914     3   174   213    60    72  1492   527\n",
      "   213  2854     2 10205 12932    17  3859   304    71   213 24988     5\n",
      "     3   200   213  2590 18505    61   527  6284  1599    23   133   103\n",
      " 11565  1019 10075  8951     4   320 23984     4     2   184    10    59\n",
      "     3  2890  1646  1631  9961   132   481     3    34   659     2  5670\n",
      "   127     2   213  4463 10976     5  1435   761   132    28   205   527\n",
      "   669 27634     4  8841 10204     4  4617 27634   391   213  1980   527\n",
      "  1480    39  1151  1181   320  2073     3   392  2221     7     5  2375\n",
      " 14200     4  1164  5556   132  2720     2   103   436    44    74    72\n",
      "    91   171  8994    25   217   320   211    28  4701    71   213 24988\n",
      "     4   320  5631    50  1785     2    22   127     3  4359 16734   100\n",
      "  4359    79     2    28  1520  2890   748 13035     2   316   213   617\n",
      "   314   527  1287    28   669 27634     4  5389   527  1587  4172 27634\n",
      "   391  8851  5240  1435   761  7914   186 12084 23504    14   166   527\n",
      "   213  5862  4331   285  1353  3672     2   186 26126    44   304    71\n",
      "   213 24988     5   229    86   454   213 21154   917  5669     2    22\n",
      "   127  1133 27634     4   198   229    92  2378   250  1248    31   895\n",
      "  4617 27634   391  4359    79   793 14607  1133 27634     4   207   255\n",
      "   425   213   895     3   449     7     5   579    13     7    75  1084\n",
      "   527   571   693  4172 27634   391   392   213  1825  4699  5366  6045\n",
      "    84  5556     2   213   175     7     5  4947   320   781     2   213\n",
      "  1630  1107 19386  1407   213  1644     7     5  7914 24988     4   132\n",
      "    28  3631  4554  4804  5367 12254    93     3  1584 11196   127  6173\n",
      " 25303 17102    28 12320 22789     4     7     5 24988     5  1469   403\n",
      "  2683   320 12978  4554     2    35    22  2266 14527    16    28 15387\n",
      " 15452   527 17184   186  4822    95   105   320  2560   463  4331   171\n",
      " 19386  1728   105     3   244  5670   127   213 24988     5    18   320\n",
      "  1151 16535    21   132   356   320   953   213 11072  1197  4463 20021\n",
      "    47   457  4601 27634     4  2087  7511   103 21322  3505   283  1435\n",
      "    33  1084    33    49  2586   103  4172 27634   391    69   127  8476\n",
      " 12496   170  1151   132   213   789 10993 27634     4    52     7     5\n",
      "    31  1644 27634    76    35    22   969  2035 27634     4   198     7\n",
      "     5    28   621   527   224   370   132  1480    41   143  1995  1838\n",
      "   566   399  4172 27634   391  1250     7     5   266   229 15643  1248\n",
      "  4853  1838   213   184    10    59     3 21115 20905  1276  1249   186\n",
      "   213   624  2890  4463   458 11820  2640     2   127 25004  3335  2809\n",
      " 17572  3335 11645    28     2  8810  1108     6   507   527  1250     7\n",
      "     5 21115   186  8333  8048  4452   186   213  2684     7     5  2028\n",
      " 14380     3   184    10    59     3  2507 26948    45    18    46  4123\n",
      "  3336   304   320  6173 25303 17102    28 12320 22789     4     2   186\n",
      "  8476     7     5  1255  7989    23  1065  1423  2685   354    28  1520\n",
      "     6   601   859 14954   522   412    28 16755 10340  6303 20995  1644\n",
      "  1133 27634     4   129   674    18  1016    28  1331   527   291  1838\n",
      "   872   628   186  1632  4617 27634   391 17572  3335 11645    28   127\n",
      "     3   200    22   969  2035 27634     4    13   362   213    94 18188\n",
      "   739   169   229   291   132  3862   372   498  1248  2929   320  7270\n",
      "    51    49 19497     4   527   213 20719   304   186  1151   217   320\n",
      "  1463    28  4837 20719   238  4172 27634   391   747 12496  1480  1141\n",
      "   213 24988     5     2   186  8351  7888     4     2  1480   601    94\n",
      "   527   213  1644     2  1435    43 12163    16   213   266   186  8476\n",
      " 12496     3  6956  2028 16802 23773  7378 14940   320  1250   320 18752\n",
      "  1248  1520  1631   186 15540   220   719     2   186  8476    23  1065\n",
      "  1320  1631  2685   354    28  1520     6   601   859 14954   522   412\n",
      "    28 16755 10340  6303 20995  1644     3   200  1019   169     2  1250\n",
      "    23   669 27634     4    92  1855 27634   391    35   320   952 14527\n",
      "    16   304    71   213 24988     5     2  9721  6379    81   127  1133\n",
      " 27634     4    13    18    92  3326   285   213   313   186   331   477\n",
      "   809   213   363  1644  1435  2855   416   320 16250     4   374   455\n",
      "  1587   320   191  1084   285    41 10250   824  4617 27634   391    22\n",
      "   127  1133 27634     4   397    13   358     7    26   288   186  2754\n",
      "    13    49     7    26  1399   186   213   762   883  1934  1019   156\n",
      "   229     2    39   103  1151   757 12282  1220    74   272  6995 27634\n",
      "     4   244   457     2   130  1525   229     2   229   285   103     7\n",
      "   371  1151   757 12282  1220     3   200   132   356  1019   103   320\n",
      "  1151   757 12282  1220     2  5407  5626   295     7     5   416   320\n",
      "    18   320  1507    61   186  2005  1019    44   399  1838   213   566\n",
      "   289  4172 27634   391  6497   862 23107   186 14607     7     5  4242\n",
      "  6156  3625   320   824   648    10     1     0   321  4944  1253    23\n",
      "    46 16584    17  1019 19098    16  1923 20719     2  8476 12496   465\n",
      " 16346 27439  6774  1628 19507     5   476  1250   186  8476 12496   317\n",
      "   399 11839 23675   113   213  2854 16346 27439  6774  7583 27634     4\n",
      "   198   229    92  2378   250  1248    31   895  4617 27634   391    28\n",
      "  1520 16973   465 16346 27439  6774  1628    52     7     5   403   263\n",
      "  1019    28  4699  5366  6045    84     6   629  2473     2    28 14607\n",
      " 13035 22690     5  2104     1]\n"
     ]
    }
   ],
   "source": [
    "# print corresponding integer values\n",
    "print(input_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GD-72TENV2Jk"
   },
   "source": [
    "Things to notice:\n",
    " - First we see the corresponding values of the words.\n",
    " - The first 1, which represents the `<EOS>` tag of the article.\n",
    " - Followed by a 0, which represents a `<pad>` tag.\n",
    " - After the first 0 (`<pad>` tag) the corresponding values are of the words that are used for the summary of the article.\n",
    " - The second 1 represents the `<EOS>` tag for the summary.\n",
    " - All the trailing 0s represent `<pad>` tags which are appended to maintain consistent length (If you don't see them then it would mean it is already of max length)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:58:52.193571Z",
     "start_time": "2021-08-16T01:58:51.980380Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bu05ZwbWTE6P",
    "outputId": "3d455bd7-e343-4c25-a467-572d2abd837f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "\n",
      " Tokyo (CNN) -- Beneath the cherry blossoms of Shiba Park, more than\n",
      "2,000 people lined up for a Sunday afternoon march calling for Japan's\n",
      "nuclear power stations to be shut down. A week before, a similar\n",
      "protest -- though in a chilly drizzle, not on a warm, sunny day --\n",
      "drew about 250. And a month of frustration, desperation and anger\n",
      "boiled over at Tokyo Electric Power Company's headquarters Friday as\n",
      "officials from towns around the Fukushima Daiichi nuclear power plant\n",
      "demanded to know when the crisis that has besieged their farming\n",
      "communities would end. \"The nuclear plant situation needs to be\n",
      "resolved as soon as possible. If not, we farmers will die,\" one of the\n",
      "officials, Iwao Suzuki, told the utility's executives. But the\n",
      "response from Naomi Hirose, the managing director of Japan's largest\n",
      "utility, offered little encouragement to the delegation or the rest of\n",
      "the world. \"There is a need to draw an end to the current situation as\n",
      "soon as possible,\" Hirose said, adding, \"We totally agree to this and\n",
      "are taking the utmost endeavors to contain the radiation.\" Since the\n",
      "March 11 earthquake that ravaged northern Japan, workers at Fukushima\n",
      "Daiichi have been struggling to cool down three overheated reactors\n",
      "and keep pools of spent but still potent nuclear fuel from spreading\n",
      "further radioactive contamination across northern Japan. A month into\n",
      "the crisis, the utility acknowledges, there is no end in sight. The\n",
      "problems are so far \"beyond the design capacity\" of the plant that the\n",
      "Japanese are working in uncharted territory, said Michael Friedlander,\n",
      "a former senior operator at U.S. nuclear power plants. \"No nuclear\n",
      "power plant has ever considered the inability to get on long-term core\n",
      "cooling for more than a week, much less three weeks,\" Friedlander\n",
      "said. Some Japanese experts now say the effort is in danger of failing\n",
      "unless Japan seeks more help from international experts to bring it to\n",
      "an end. Tetsunari Iida, an engineer-turned-industry critic, said the\n",
      "situation is \"beyond the reach\" of Japan's closely knit nuclear\n",
      "establishment. \"A real exit strategy has to start with an inspection\n",
      "by the world's top experts on nuclear accidents,\" Iida told reporters\n",
      "at Japan's national press club last week. Engineers and workers so far\n",
      "have managed to stave off a complete meltdown in Fukushima Daiichi's\n",
      "reactors 1-3 and in the spent fuel pool of unit 4. But experts say the\n",
      "overheated fuel rods are likely to have suffered extensive damage, and\n",
      "there is a complication for seemingly every advance. Much of the past\n",
      "week was dominated by the attempt to stop water laced with massive\n",
      "amounts of radioactive particles from pouring into the Pacific Ocean\n",
      "-- water that comes out of the reactors \"screaming with\n",
      "radioactivity,\" Friedlander said. Tokyo Electric is now grappling with\n",
      "where to put the stuff, even dumping thousands of tons of less-\n",
      "radioactive water into the Pacific to make room for it in a reservoir\n",
      "for low-level waste. In a normally functioning plant, coolant water is\n",
      "circulated out of the reactors and chilled. Then it's pumped back in\n",
      "to carry more heat away from the plant's fuel rods, which continue\n",
      "producing energy long after the chain reaction at the heart of the\n",
      "units has been stopped. \"You have to get the recirculation system up\n",
      "and functioning so they can cool that water in the normal way,\" said\n",
      "Gary Was, a nuclear engineering professor at the University of\n",
      "Michigan and a CNN consultant. Normal cooling systems don't require\n",
      "the massive amounts of water -- around 7 metric tons (1,850 gallons)\n",
      "per hour -- now being poured into the reactors. \"That's a big\n",
      "problem,\" Was said. Tokyo Electric officials told CNN they can't say\n",
      "when they'll be able to restore those normal cooling. The first step\n",
      "is to get highly radioactive water out of the flooded basements of the\n",
      "units' turbine plants, then figure out how badly the equipment inside\n",
      "has been damaged. For the first two weeks of the crisis, engineers\n",
      "pumped seawater into the reactors. But the resulting buildup of salt\n",
      "inside has made it harder for coolant to circulate, U.S. nuclear\n",
      "safety officials advised in March. In addition, Was said, the fuel\n",
      "rods are likely in a state of \"partial melt,\" the extent of which will\n",
      "be difficult to determine. After 1979's Three Mile Island accident in\n",
      "Pennsylvania, it took more than two years before operators were able\n",
      "to get a camera into the reactor to examine its condition, he said.\n",
      "Satoshi Sato, a Japanese nuclear industry consultant, called the\n",
      "current line of attack a \"waste of effort.\" Plant instruments are\n",
      "likely damaged and unreliable because of the intense heat that was\n",
      "generated, and pumping more water into the reactors is only making the\n",
      "contamination problem worse, he said. \"There is no happy end with\n",
      "their approach,\" Sato told CNN. \"They must change the approach. That's\n",
      "something I'm sure of 100 percent.\" After the 1986 Chernobyl accident,\n",
      "the world's worst to date, the Soviet Union encased the plant's\n",
      "damaged reactor in a massive concrete sarcophagus. Iida said Fukushima\n",
      "Daiichi's reactors remain too hot to pour concrete, but he suggested\n",
      "pouring a slurry of minerals and sand over them to carry away heat\n",
      "before encasing them. And Was said the reactors have to be cooled in\n",
      "order to let the molten fuel harden again: \"Only when it solidifies\n",
      "are you sure you can contain it.\" He said Tokyo Electric should be in\n",
      "the lead -- \"It's their plant\" -- but he added, \"There's a lot of\n",
      "different areas in which they could benefit from international help.\"\n",
      "Japan's government is consulting with experts from the U.S. Nuclear\n",
      "Regulatory Commission and the French nuclear fuel company Areva, said\n",
      "Hidehiko Nishiyama, deputy director-general of Japan's Nuclear and\n",
      "Industrial Safety Agency and the agency's chief spokesman. U.S. Navy\n",
      "barges have been carrying fresh water to Fukushima Daiichi, and\n",
      "Tokyo's foreign ministry has asked Russia about using a Japanese-built\n",
      "ship outfitted as a floating decontamination plant. \"We already have\n",
      "quite a bit of support from outside countries and organizations,\"\n",
      "Nishiyama said. But he added, \"I think the most urgent issue now is\n",
      "support in whatever form possible with regard to how we can dispose of\n",
      "the cooling water and be able to build a sustainable cooling system.\"\n",
      "General Electric which designed the reactors, and Hitachi, which built\n",
      "most of the plant, are also advising the government and Tokyo\n",
      "Electric. GE chief Jeffrey Immelt flew to Japan to consult with\n",
      "Japanese officials and executives last week, and Tokyo has asked\n",
      "Russian officials about using a Japanese-built ship outfitted as a\n",
      "floating decontamination plant. But for now, Japan has \"no choice\" but\n",
      "to continue pouring water into the reactors, Friedlander said. \"I have\n",
      "no doubt that the men and women working at the power plant are indeed\n",
      "going to exert every human effort to make sure that they resolve\n",
      "this,\" he said. \"What I don't know and what I can't tell and the big\n",
      "question mark for me is, will it be done sooner than later? \"And\n",
      "again, my hope is, is that it'll be done sooner. But in order for it\n",
      "to be done sooner, TEPCO's going to have to step up and ask for more\n",
      "help from the international community.\" Ailing Chang and CNN's Brian\n",
      "Walker contributed to this report.<EOS><pad>Notimetable has been\n",
      "crafted for restoring normal cooling, Tokyo Electric says . Experts\n",
      "say Japan and Tokyo Electric need help resolving the crisis . \"There\n",
      "is no happy end with their approach,\" a Japanese analyst says . It's\n",
      "too early for a Chernobyl-type solution, a CNN consultant advises\n",
      ".<EOS>\n"
     ]
    }
   ],
   "source": [
    "# print the article and its summary\n",
    "print('Article:\\n\\n', detokenize(input_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNFVhgHoncGm"
   },
   "source": [
    "You can see that the data has the following structure:\n",
    "- <span style='color:blue'> [Article] </span> -> `<EOS>` -> `<pad>` -> <span style='color:blue'> [Article Summary] </span> -> `<EOS>` -> (possibly) multiple `<pad>`\n",
    "\n",
    "The loss is taken only on the summary using cross_entropy as loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Un8NHIRoj-1W"
   },
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: Summarization with transformer\n",
    "\n",
    "Now that we have given you the data generator and have handled the preprocessing for you, it is time for you to build your own model. We saved you some time because we know you have already preprocessed data before in this specialization, so we would rather you spend your time doing the next steps. \n",
    "\n",
    "You will be implementing the attention from scratch and then using it in your transformer model. Concretely, you will understand how attention works, how you use it to connect the encoder and the decoder.\n",
    "\n",
    "<img src=\"transformer_decoder_zoomin.png\">\n",
    "\n",
    "<a name='2.1'></a>\n",
    "## 2.1 Dot product attention \n",
    "\n",
    "Now you will implement dot product attention which takes in a query, key, value, and a mask. It returns the output. \n",
    "\n",
    "<img src =\"dotproduct.png\">\n",
    "\n",
    "\n",
    "Here are some helper functions that will help you create tensors and display useful information:\n",
    "   - `create_tensor`  creates a `jax numpy array` from a list of lists.\n",
    "   - `display_tensor` prints out the shape and the actual tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:13.624408Z",
     "start_time": "2021-08-16T01:59:13.620071Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_tensor(t):\n",
    "    \"\"\"Create tensor from list of lists\"\"\"\n",
    "    return jnp.array(t)\n",
    "\n",
    "\n",
    "def display_tensor(t, name):\n",
    "    \"\"\"Display shape and tensor\"\"\"\n",
    "    print(f'{name} shape: {t.shape}\\n')\n",
    "    print(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing it yourself, you can play around with a toy example of `dot product attention` without the softmax  operation. Technically it would not be `dot product attention` without the softmax but this is done to avoid giving away too much of the answer and the idea is to display these tensors to give you a sense of how they look like.\n",
    "\n",
    "The formula for attention is this one:\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$d_{k}$ stands for the dimension of queries and keys.\n",
    "\n",
    "The `query`, `key`, `value` and `mask` vectors are provided for this example.\n",
    "\n",
    "Notice that the masking is done using very negative values that will yield a similar effect to using $-\\infty $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:15.387576Z",
     "start_time": "2021-08-16T01:59:15.363112Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "_0x0HJXwRWQk",
    "outputId": "d6d78a8e-e3cc-47af-9584-2bdcdfcca0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "key shape: (2, 3)\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "value shape: (2, 3)\n",
      "\n",
      "[[0 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "mask shape: (2, 2)\n",
      "\n",
      "[[ 0.e+00  0.e+00]\n",
      " [-1.e+09  0.e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
    "display_tensor(q, 'query')\n",
    "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
    "display_tensor(k, 'key')\n",
    "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
    "display_tensor(v, 'value')\n",
    "m = create_tensor([[0, 0], [-1e9, 0]])\n",
    "display_tensor(m, 'mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query shape: (2, 3)\n",
    "\n",
    "[[1 0 0]\n",
    " [0 1 0]]\n",
    "\n",
    "key shape: (2, 3)\n",
    "\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "\n",
    "value shape: (2, 3)\n",
    "\n",
    "[[0 1 0]\n",
    " [1 0 1]]\n",
    "\n",
    "mask shape: (2, 2)\n",
    "\n",
    "[[ 0.e+00  0.e+00]\n",
    " [-1.e+09  0.e+00]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:17.088785Z",
     "start_time": "2021-08-16T01:59:17.081813Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kVR9u4faRWQo",
    "outputId": "f01ea4ca-4152-4b54-b76a-e4b5917ae2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query dot key shape: (2, 2)\n",
      "\n",
      "[[0.57735026 2.309401  ]\n",
      " [1.1547005  2.8867512 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_dot_k = q @ k.T / jnp.sqrt(3)\n",
    "display_tensor(q_dot_k, 'query dot key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query dot key shape: (2, 2)\n",
    "\n",
    "[[0.57735026 2.309401  ]\n",
    " [1.1547005  2.8867514 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:18.567271Z",
     "start_time": "2021-08-16T01:59:18.563120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key shape: (2, 2)\n",
      "\n",
      "[[ 5.7735026e-01  2.3094010e+00]\n",
      " [-1.0000000e+09  2.8867512e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked = q_dot_k + m\n",
    "display_tensor(masked, 'masked query dot key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "masked query dot key shape: (2, 2)\n",
    "\n",
    "[[ 5.7735026e-01  2.3094010e+00]\n",
    " [-1.0000000e+09  2.8867514e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:20.149619Z",
     "start_time": "2021-08-16T01:59:20.144113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key dot value shape: (2, 3)\n",
      "\n",
      "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
      " [ 2.8867512e+00 -1.0000000e+09  2.8867512e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(masked @ v, 'masked query dot key dot value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "masked query dot key dot value shape: (2, 3)\n",
    "\n",
    "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
    " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the previous dummy tensors to test some of the graded functions, a batch dimension should be added to them so they mimic the shape of real-life examples. The mask is also replaced by a version of it that resembles the one that is used by trax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:22.416447Z",
     "start_time": "2021-08-16T01:59:22.411178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]] (2, 3)\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]] (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(q, q.shape)\n",
    "print(q[None,:], q[None,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T01:59:23.179166Z",
     "start_time": "2021-08-16T01:59:23.170815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n",
      "key with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n",
      "\n",
      "value with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[0 1 0]\n",
      "  [1 0 1]]]\n",
      "\n",
      "boolean mask shape: (2, 2)\n",
      "\n",
      "[[ True  True]\n",
      " [False  True]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_with_batch = q[None,:]\n",
    "display_tensor(q_with_batch, 'query with batch dim')\n",
    "k_with_batch = k[None,:]\n",
    "display_tensor(k_with_batch, 'key with batch dim')\n",
    "v_with_batch = v[None,:]\n",
    "display_tensor(v_with_batch, 'value with batch dim')\n",
    "m_bool = create_tensor([[True, True], [False, True]])\n",
    "display_tensor(m_bool, 'boolean mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]]\n",
    "\n",
    "key with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[1 2 3]\n",
    "  [4 5 6]]]\n",
    "\n",
    "value with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[0 1 0]\n",
    "  [1 0 1]]]\n",
    "\n",
    "boolean mask shape: (2, 2)\n",
    "\n",
    "[[ True  True]\n",
    " [False  True]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex01'></a>\n",
    "### Exercise 01\n",
    "\n",
    "**Instructions:** Implement the dot product attention. Concretely, implement the following equation\n",
    "\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$Q$ - query, \n",
    "$K$ - key, \n",
    "$V$ - values, \n",
    "$M$ - mask, \n",
    "${d_k}$ - depth/dimension of the queries and keys (used for scaling down)\n",
    "\n",
    "You can implement this formula either by `trax` numpy (trax.math.numpy) or regular `numpy` but it is recommended to use `jnp`.\n",
    "\n",
    "Something to take into consideration is that within trax, the masks are tensors of `True/False` values not 0's and $-\\infty$ as in the previous example. Within the graded function don't think of applying the mask by summing up matrices, instead use `jnp.where()` and treat the **mask as a tensor of boolean values with `False` for values that need to be masked and True for the ones that don't.**\n",
    "\n",
    "Also take into account that the real tensors are far more complex than the toy ones you just played with. Because of this avoid using shortened operations such as `@` for dot product or `.T` for transposing. Use `jnp.matmul()` and `jnp.swapaxes()` instead.\n",
    "\n",
    "This is the self-attention block for the transformer decoder. Good luck!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:09:49.982Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kSauPt0NUl_o"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: DotProductAttention\n",
    "def DotProductAttention(query, key, value, mask):\n",
    "    \"\"\"Dot product self-attention.\n",
    "    Args:\n",
    "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
    "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
    "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
    "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
    "\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
    "    \"\"\"\n",
    "\n",
    "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
    "    depth = query.shape[-1]\n",
    "#     print(depth)\n",
    "\n",
    "    # Calculate scaled query key dot product according to formula above\n",
    "    dots = jnp.matmul(query, jnp.swapaxes(key, -1, -2)) / jnp.sqrt(depth)\n",
    "#     print(query.shape)\n",
    "#     print(dots, dots.shape)\n",
    "#     print(mask, mask.shape)\n",
    "    \n",
    "    \n",
    "    # Apply the mask\n",
    "    if mask is not None: # The 'None' in this line does not need to be replaced\n",
    "        dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n",
    "#         print(dots, dots.shape)\n",
    "    \n",
    "    # Softmax formula implementation\n",
    "    # Use trax.fastmath.logsumexp of dots to avoid underflow by division by large numbers\n",
    "    # Hint: Last axis should be used and keepdims should be True\n",
    "    # Note: softmax = e^(dots - logsumexp(dots)) = E^dots / sumexp(dots)\n",
    "    logsumexp = trax.fastmath.logsumexp(dots, axis=-1, keepdims=True)\n",
    "\n",
    "    # Take exponential of dots minus logsumexp to get softmax\n",
    "    # Use jnp.exp()\n",
    "    dots = jnp.exp(dots - logsumexp)\n",
    "\n",
    "    # Multiply dots by value to get self-attention\n",
    "    # Use jnp.matmul()\n",
    "    attention = jnp.matmul(dots, value)\n",
    "\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:09:53.574Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8o0K7VWKRWQw",
    "outputId": "1c51af3a-5f11-480f-b33b-419072d8298c"
   },
   "outputs": [],
   "source": [
    "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
    "              [1.        , 0.        , 1.        ]]], dtype=float32)\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2y2PSiLVRWQ2"
   },
   "source": [
    "<a name='2.2'></a>\n",
    "\n",
    "## 2.2 Causal Attention\n",
    "\n",
    "Now you are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before. \n",
    "\n",
    "<img src = \"causal.png\">\n",
    "\n",
    "In the image above, a word can see everything that is before it, but not what is after it. To implement causal attention, you will have to transform vectors and do many reshapes. You will need to implement the functions below.\n",
    "\n",
    "\n",
    "<a name='ex02'></a>\n",
    "### Exercise 02\n",
    "\n",
    "Implement the following functions that will be needed for Causal Attention:\n",
    "\n",
    "- <span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
    "- <span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention.\n",
    "- <span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. \n",
    "\n",
    "Next there are some toy tensors which may serve to give you an idea of the data shapes and opperations involved in Causal Attention. They are also useful to test out your functions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:07.894863Z",
     "start_time": "2021-08-16T02:01:07.864842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "VRH67YcrRWQ3",
    "outputId": "847a9416-877a-4246-c738-0eacdf46de59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query matrix (2D tensor) shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n",
      "\n",
      "[[[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]]\n",
      "\n",
      "one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor2d = create_tensor(q)\n",
    "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
    "\n",
    "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
    "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
    "\n",
    "tensor3dc = create_tensor([jnp.concatenate([q, q], axis = -1)])\n",
    "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
    "\n",
    "tensor3dc3b = create_tensor([jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1)])\n",
    "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that the following 3 functions would normally be defined within the `CausalAttention` function further below. \n",
    "\n",
    "However this makes these functions harder to test. Because of this, these functions are shown individually using a `closure` (when necessary) that simulates them being inside of the `CausalAttention` function. This is done because they rely on some variables that can be accessed from within `CausalAttention`.\n",
    "\n",
    "### Support Functions\n",
    "\n",
    "<span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
    "\n",
    "**For the closures you only have to fill the inner function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:10.134648Z",
     "start_time": "2021-08-16T02:01:10.128910Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: compute_attention_heads_closure\n",
    "def compute_attention_heads_closure(n_heads, d_head):\n",
    "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
    "    Args:\n",
    "        d_head (int):  dimensionality of heads.\n",
    "        n_heads (int): number of attention heads.\n",
    "    Returns:\n",
    "        function: compute_attention_heads function\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_attention_heads(x):\n",
    "        \"\"\" Compute the attention heads.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
    "        \"\"\"\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "        \n",
    "        # Size of the x's batch dimension\n",
    "        batch_size = x.shape[0]\n",
    "        # Length of the sequence\n",
    "        # Should be size of x's first dimension without counting the batch dim\n",
    "        seqlen = x.shape[1]\n",
    "        # Reshape x using jnp.reshape()\n",
    "        # batch_size, seqlen, n_heads*d_head -> batch_size, seqlen, n_heads, d_head\n",
    "        x = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
    "        # Transpose x using jnp.transpose()\n",
    "        # batch_size, seqlen, n_heads, d_head -> batch_size, n_heads, seqlen, d_head\n",
    "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
    "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
    "        # Reshape x using jnp.reshape()\n",
    "        # batch_size, n_heads, seqlen, d_head -> batch_size*n_heads, seqlen, d_head\n",
    "        x = jnp.reshape(x, (batch_size*n_heads, seqlen, d_head))\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    return compute_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:13.060800Z",
     "start_time": "2021-08-16T02:01:12.967846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "origin:  shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "reshape:  shape: (3, 2, 2, 3)\n",
      "\n",
      "[[[[1 0 0]\n",
      "   [1 0 0]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [1 0 0]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [1 0 0]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [0 1 0]]]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "reshape:  shape: (3, 2, 2, 3)\n",
      "\n",
      "[[[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tensor3dc3b\n",
    "print('-'*50 + '\\n')\n",
    "display_tensor(x, 'origin: ')\n",
    "batch_size = x.shape[0]\n",
    "n_heads = 2\n",
    "d_head = 3\n",
    "\n",
    "seqlen = x.shape[1]\n",
    "x = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
    "print('-'*50 + '\\n')\n",
    "display_tensor(x, 'reshape: ')\n",
    "\n",
    "\n",
    "x = jnp.transpose(x, (0, 2, 1, 3))\n",
    "print('-'*50 + '\\n')\n",
    "display_tensor(x, 'reshape: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:13.810068Z",
     "start_time": "2021-08-16T02:01:13.802485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "output tensor shape: (6, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(tensor3dc3b, \"input tensor\")\n",
    "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
    "display_tensor(result_cah, \"output tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "input tensor shape: (3, 2, 6)\n",
    "\n",
    "[[[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]]\n",
    "\n",
    "output tensor shape: (6, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:32.500848Z",
     "start_time": "2021-08-16T02:01:32.496209Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: dot_product_self_attention\n",
    "def dot_product_self_attention(q, k, v):\n",
    "    \"\"\" Masked dot product self attention.\n",
    "    Args:\n",
    "        q (jax.interpreters.xla.DeviceArray): queries.\n",
    "        k (jax.interpreters.xla.DeviceArray): keys.\n",
    "        v (jax.interpreters.xla.DeviceArray): values.\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
    "    # NOTE: there is a revision underway with the autograder to tolerate better indexing. \n",
    "    # Until then, please index q.shape using negative values (this is equivalent to counting from right to left)\n",
    "    mask_size = q.shape[1]\n",
    "\n",
    "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
    "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
    "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
    "    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return DotProductAttention(q, k, v, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:33.738111Z",
     "start_time": "2021-08-16T02:01:33.288921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ True False False False]\n",
      "  [ True  True False False]\n",
      "  [ True  True  True False]\n",
      "  [ True  True  True  True]]] (1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "mask = jnp.tril(jnp.ones((1, 4, 4), dtype=jnp.bool_), k=0)\n",
    "print(mask, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:01:34.710743Z",
     "start_time": "2021-08-16T02:01:34.201598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.7735026e-01 -1.0000000e+09]\n",
      "  [ 1.1547005e+00  2.8867512e+00]]] (1, 2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[0.        , 1.        , 0.        ],\n",
       "              [0.8496746 , 0.15032548, 0.8496746 ]]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "DeviceArray([[[0.        , 1.        , 0.        ],\n",
    "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:02:46.511978Z",
     "start_time": "2021-08-16T02:02:46.506758Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: compute_attention_output_closure\n",
    "def compute_attention_output_closure(n_heads, d_head):\n",
    "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
    "    Args:\n",
    "        d_head (int):  dimensionality of heads.\n",
    "        n_heads (int): number of attention heads.\n",
    "    Returns:\n",
    "        function: compute_attention_output function\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_attention_output(x):\n",
    "        \"\"\" Compute the attention output.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
    "        \"\"\"\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "        \n",
    "        # Length of the sequence\n",
    "        # Should be size of x's first dimension without counting the batch dim\n",
    "        seqlen = x.shape[1]\n",
    "        # Reshape x using jnp.reshape() to shape (batch_size, n_heads, seqlen, d_head)\n",
    "        x = jnp.reshape(x, ( -1, n_heads, seqlen, d_head))\n",
    "        # Transpose x using jnp.transpose() to shape (batch_size, seqlen, n_heads, d_head)\n",
    "        x = jnp.transpose(x, ( 0, 2, 1 , 3))\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Reshape to allow to concatenate the heads\n",
    "        return jnp.reshape(x, (-1, seqlen, n_heads * d_head))\n",
    "    \n",
    "    return compute_attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:02:47.259981Z",
     "start_time": "2021-08-16T02:02:47.233551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape: (6, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n",
      "output tensor shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(result_cah, \"input tensor\")\n",
    "result_cao = compute_attention_output_closure(2,3)(result_cah)\n",
    "display_tensor(result_cao, \"output tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "input tensor shape: (6, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]]\n",
    "\n",
    "output tensor shape: (3, 2, 6)\n",
    "\n",
    "[[[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Attention Function\n",
    "\n",
    "Now it is time for you to put everything together within the `CausalAttention` or Masked multi-head attention function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"masked-attention.png\"> \n",
    "\n",
    "**Instructions:** Implement the causal attention.\n",
    "Your model returns the causal attention through a $tl.Serial$ with the following:\n",
    "\n",
    "- <span style='color:blue'> [tl.Branch](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch) </span>: consisting of 3 [tl.Dense(d_feature), ComputeAttentionHeads] to account for the queries, keys, and values.\n",
    "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in dot_product_self_attention function and uses it to compute the dot product using $Q$, $K$, $V$.\n",
    "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in restack_attention_heads to allow for parallel computing.\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense)</span>: Final Dense layer, with dimension `d_feature`.\n",
    "\n",
    "Remember that in order for trax to properly handle the functions you just defined, they need to be added as layers using the [`tl.Fn()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:04:24.534972Z",
     "start_time": "2021-08-16T02:04:24.527673Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "B9Adn6DtRWRG"
   },
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "# GRADED FUNCTION: CausalAttention\n",
    "def CausalAttention(d_feature, \n",
    "                    n_heads, \n",
    "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
    "                    dot_product_self_attention=dot_product_self_attention,\n",
    "                    compute_attention_output_closure=compute_attention_output_closure,\n",
    "                    mode='train'):\n",
    "    \"\"\"Transformer-style multi-headed causal attention.\n",
    "\n",
    "    Args:\n",
    "        d_feature (int):  dimensionality of feature embedding.\n",
    "        n_heads (int): number of attention heads.\n",
    "        compute_attention_heads_closure (function): Closure around compute_attention heads.\n",
    "        dot_product_self_attention (function): dot_product_self_attention function. \n",
    "        compute_attention_output_closure (function): Closure around compute_attention_output. \n",
    "        mode (str): 'train' or 'eval'.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: Multi-headed self-attention model.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert d_feature % n_heads == 0\n",
    "    d_head = d_feature // n_heads\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n",
    "    # Since you are dealing with closures you might need to call the outer \n",
    "    # function with the correct parameters to get the actual uncalled function.\n",
    "    ComputeAttentionHeads = tl.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n",
    "        \n",
    "\n",
    "    return tl.Serial(\n",
    "        tl.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # queries\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # keys\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # values\n",
    "        ),\n",
    "        \n",
    "        tl.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n",
    "        # HINT: The second argument to tl.Fn() is an uncalled function\n",
    "        # Since you are dealing with closures you might need to call the outer \n",
    "        # function with the correct parameters to get the actual uncalled function.\n",
    "        tl.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n",
    "        tl.Dense(d_feature) # Final dense layer\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:04:25.301354Z",
     "start_time": "2021-08-16T02:04:25.297112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Branch_out3[\n",
      "    [Dense_512, AttnHeads]\n",
      "    [Dense_512, AttnHeads]\n",
      "    [Dense_512, AttnHeads]\n",
      "  ]\n",
      "  DotProductAttn_in3\n",
      "  AttnOutput\n",
      "  Dense_512\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the causal attention model\n",
    "print(CausalAttention(d_feature=512, n_heads=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Serial[\n",
    "  Branch_out3[\n",
    "    [Dense_512, AttnHeads]\n",
    "    [Dense_512, AttnHeads]\n",
    "    [Dense_512, AttnHeads]\n",
    "  ]\n",
    "  DotProductAttn_in3\n",
    "  AttnOutput\n",
    "  Dense_512\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6zwtPjqRWRJ"
   },
   "source": [
    "<a name='2.3'></a>\n",
    "\n",
    "## 2.3 Transformer decoder block\n",
    "\n",
    "Now that you have implemented the causal part of the transformer, you will implement the transformer decoder block. Concretely you will be implementing this image now.\n",
    "\n",
    "<img src = \"transformer_decoder_1.png\" style = \"height:300px\"> \n",
    "\n",
    "To implement this function, you will have to call the `CausalAttention` or Masked multi-head attention function you implemented above. You will have to add a feedforward which consists of: \n",
    "\n",
    "- <span style='color:blue'> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: used to layer normalize\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: the dense layer\n",
    "- <span style='color:blue'> [ff_activation](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu) </span>: feed forward activation (we use ReLu) here.\n",
    "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: dense layer\n",
    "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
    "\n",
    "Finally once you implement the feedforward, you can go ahead and implement the entire block using: \n",
    "\n",
    "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the tl.LayerNorm(), causal attention block, tl.dropout. \n",
    "\n",
    "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the feedforward block you will implement. \n",
    "\n",
    "<a name='ex03'></a>\n",
    "### Exercise 03\n",
    "**Instructions:** Implement the transformer decoder block. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:04:28.618957Z",
     "start_time": "2021-08-16T02:04:28.612053Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gKOxnRbp1K5U"
   },
   "outputs": [],
   "source": [
    "# UNQ_C6\n",
    "# GRADED FUNCTION: DecoderBlock\n",
    "def DecoderBlock(d_model, d_ff, n_heads,\n",
    "                 dropout, mode, ff_activation):\n",
    "    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
    "\n",
    "    The input is an activation tensor.\n",
    "\n",
    "    Args:\n",
    "        d_model (int):  depth of embedding.\n",
    "        d_ff (int): depth of feed-forward layer.\n",
    "        n_heads (int): number of attention heads.\n",
    "        dropout (float): dropout rate (how much to drop out).\n",
    "        mode (str): 'train' or 'eval'.\n",
    "        ff_activation (function): the non-linearity in feed-forward layer.\n",
    "\n",
    "    Returns:\n",
    "        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Create masked multi-head attention block using CausalAttention function\n",
    "    causal_attention = CausalAttention( \n",
    "                        d_model,\n",
    "                        n_heads=n_heads,\n",
    "                        mode=mode\n",
    "                        )\n",
    "\n",
    "    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
    "    feed_forward = [ \n",
    "        # Normalize layer inputs\n",
    "        tl.LayerNorm(),\n",
    "        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
    "        tl.Dense(d_ff),\n",
    "        # Add activation function passed in as a parameter (you need to call it!)\n",
    "        ff_activation(), # Generally ReLU\n",
    "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
    "        tl.Dense(d_model),\n",
    "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
    "        tl.Dropout(rate=dropout, mode=mode) \n",
    "    ]\n",
    "\n",
    "    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
    "    return [\n",
    "      tl.Residual(\n",
    "          # Normalize layer input\n",
    "          tl.LayerNorm(),\n",
    "          # Add causal attention block previously defined (without parentheses)\n",
    "          causal_attention,\n",
    "          # Add dropout with rate and mode specified\n",
    "          tl.Dropout(rate=dropout, mode=mode) \n",
    "        ),\n",
    "      tl.Residual(\n",
    "          # Add feed forward block (without parentheses)\n",
    "          feed_forward\n",
    "        ),\n",
    "      ]\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:04:30.738186Z",
     "start_time": "2021-08-16T02:04:30.731495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Serial[\n",
      "        Branch_out3[\n",
      "          [Dense_512, AttnHeads]\n",
      "          [Dense_512, AttnHeads]\n",
      "          [Dense_512, AttnHeads]\n",
      "        ]\n",
      "        DotProductAttn_in3\n",
      "        AttnOutput\n",
      "        Dense_512\n",
      "      ]\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "], Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Dense_2048\n",
      "      Serial[\n",
      "        Relu\n",
      "      ]\n",
      "      Dropout\n",
      "      Dense_512\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the decoder block\n",
    "print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "[Serial[\n",
    "  Branch_out2[\n",
    "    None\n",
    "    Serial[\n",
    "      LayerNorm\n",
    "      Serial[\n",
    "        Branch_out3[\n",
    "          [Dense_512, AttnHeads]\n",
    "          [Dense_512, AttnHeads]\n",
    "          [Dense_512, AttnHeads]\n",
    "        ]\n",
    "        DotProductAttn_in3\n",
    "        AttnOutput\n",
    "        Dense_512\n",
    "      ]\n",
    "      Dropout\n",
    "    ]\n",
    "  ]\n",
    "  Add_in2\n",
    "], Serial[\n",
    "  Branch_out2[\n",
    "    None\n",
    "    Serial[\n",
    "      LayerNorm\n",
    "      Dense_2048\n",
    "      Relu\n",
    "      Dropout\n",
    "      Dense_512\n",
    "      Dropout\n",
    "    ]\n",
    "  ]\n",
    "  Add_in2\n",
    "]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoFv-nfLRWRN",
    "lines_to_next_cell": 0
   },
   "source": [
    "<a name='2.4'></a>\n",
    "## 2.4 Transformer Language Model\n",
    "\n",
    "You will now bring it all together. In this part you will use all the subcomponents you previously built to make the final model. Concretely, here is the image you will be implementing. \n",
    "<img src = \"transformer_decoder.png\" style = \"height:400px\">\n",
    "\n",
    "    \n",
    "<a name='ex04'></a>\n",
    "### Exercise 04\n",
    "**Instructions:** Previously you coded the decoder block. Now you will code the transformer language model. Here is what you will need. \n",
    "\n",
    "- <span style=\"color:blue\"> positional_enconder </span>- a list containing the following layers:\n",
    "    - <span style=\"color:blue\"> [tl.Embedding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding)\n",
    "    - <span style=\"color:blue\"> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout)\n",
    "    - <span style=\"color:blue\"> [tl.PositionalEncoding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PositionalEncoding)\n",
    "\n",
    "- A list of `n_layers` <span style=\"color:blue\"> decoder blocks</span>.\n",
    "- <span style=\"color:blue\"> [tl.Serial](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial): </span> takes in the following layers or lists of layers:\n",
    "    - <span style=\"color:blue\"> [tl.ShiftRight](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight): </span>: shift the tensor to the right by padding on axis 1.\n",
    "    - <span style=\"color:blue\"> positional_encoder </span>: encodes the text positions.\n",
    "    - <span style=\"color:blue\"> decoder_blocks </span>: the ones you created.\n",
    "    - <span style=\"color:blue\"> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: a layer norm.\n",
    "    - <span style=\"color:blue\"> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: takes in the vocab_size.\n",
    "    - <span style=\"color:blue\"> [tl.LogSoftmax](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) </span>: to predict.\n",
    "    \n",
    "Go go go!! You can do it :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:05:30.213958Z",
     "start_time": "2021-08-16T02:05:30.206064Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0yi4LJO1RWRS"
   },
   "outputs": [],
   "source": [
    "# UNQ_C7\n",
    "# GRADED FUNCTION: TransformerLM\n",
    "def TransformerLM(vocab_size=33300,\n",
    "                  d_model=512,\n",
    "                  d_ff=2048,\n",
    "                  n_layers=6,\n",
    "                  n_heads=8,\n",
    "                  dropout=0.1,\n",
    "                  max_len=4096,\n",
    "                  mode='train',\n",
    "                  ff_activation=tl.Relu):\n",
    "    \"\"\"Returns a Transformer language model.\n",
    "\n",
    "    The input to the model is a tensor of tokens. (This model uses only the\n",
    "    decoder part of the overall Transformer.)\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): vocab size.\n",
    "        d_model (int):  depth of embedding.\n",
    "        d_ff (int): depth of feed-forward layer.\n",
    "        n_layers (int): number of decoder layers.\n",
    "        n_heads (int): number of attention heads.\n",
    "        dropout (float): dropout rate (how much to drop out).\n",
    "        max_len (int): maximum symbol length for positional encoding.\n",
    "        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.\n",
    "        ff_activation (function): the non-linearity in feed-forward layer.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n",
    "        to activations over a vocab set.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Embedding inputs and positional encoder\n",
    "    positional_encoder = [ \n",
    "        # Add embedding layer of dimension (vocab_size, d_model)\n",
    "        tl.Embedding(vocab_size, d_model),\n",
    "        # Use dropout with rate and mode specified\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        # Add positional encoding layer with maximum input length and mode specified\n",
    "        tl.PositionalEncoding(max_len=max_len, mode=mode) ]\n",
    "\n",
    "    # Create stack (list) of decoder blocks with n_layers with necessary parameters\n",
    "    decoder_blocks = [ \n",
    "        DecoderBlock(d_model, d_ff, n_heads, dropout, mode, ff_activation) for _ in range(n_layers)]\n",
    "\n",
    "    # Create the complete model as written in the figure\n",
    "    return tl.Serial(\n",
    "        # Use teacher forcing (feed output of previous step to current step)\n",
    "        tl.ShiftRight(mode=mode), # Specify the mode!\n",
    "        # Add positional encoder\n",
    "        positional_encoder,\n",
    "        # Add decoder blocks\n",
    "        decoder_blocks,\n",
    "        # Normalize layer\n",
    "        tl.LayerNorm(),\n",
    "\n",
    "        # Add dense layer of vocab_size (since need to select a word to translate to)\n",
    "        # (a.k.a., logits layer. Note: activation already set by ff_activation)\n",
    "        tl.Dense(vocab_size),\n",
    "        # Get probabilities with Logsoftmax\n",
    "        tl.LogSoftmax()\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:05:37.326824Z",
     "start_time": "2021-08-16T02:05:37.319251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Serial[\n",
      "    ShiftRight(1)\n",
      "  ]\n",
      "  Embedding_33300_512\n",
      "  Dropout\n",
      "  PositionalEncoding\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Serial[\n",
      "          Branch_out3[\n",
      "            [Dense_512, AttnHeads]\n",
      "            [Dense_512, AttnHeads]\n",
      "            [Dense_512, AttnHeads]\n",
      "          ]\n",
      "          DotProductAttn_in3\n",
      "          AttnOutput\n",
      "          Dense_512\n",
      "        ]\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Dense_2048\n",
      "        Serial[\n",
      "          Relu\n",
      "        ]\n",
      "        Dropout\n",
      "        Dense_512\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  LayerNorm\n",
      "  Dense_33300\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the Transformer\n",
    "print(TransformerLM(n_layers=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Serial[\n",
    "  ShiftRight(1)\n",
    "  Embedding_33300_512\n",
    "  Dropout\n",
    "  PositionalEncoding\n",
    "  Serial[\n",
    "    Branch_out2[\n",
    "      None\n",
    "      Serial[\n",
    "        LayerNorm\n",
    "        Serial[\n",
    "          Branch_out3[\n",
    "            [Dense_512, AttnHeads]\n",
    "            [Dense_512, AttnHeads]\n",
    "            [Dense_512, AttnHeads]\n",
    "          ]\n",
    "          DotProductAttn_in3\n",
    "          AttnOutput\n",
    "          Dense_512\n",
    "        ]\n",
    "        Dropout\n",
    "      ]\n",
    "    ]\n",
    "    Add_in2\n",
    "  ]\n",
    "  Serial[\n",
    "    Branch_out2[\n",
    "      None\n",
    "      Serial[\n",
    "        LayerNorm\n",
    "        Dense_2048\n",
    "        Relu\n",
    "        Dropout\n",
    "        Dense_512\n",
    "        Dropout\n",
    "      ]\n",
    "    ]\n",
    "    Add_in2\n",
    "  ]\n",
    "  LayerNorm\n",
    "  Dense_33300\n",
    "  LogSoftmax\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRRKnoAdvmJ7"
   },
   "source": [
    "<a name='3'></a>\n",
    "# Part 3: Training\n",
    "\n",
    "Now you are going to train your model. As usual, you have to define the cost function, the optimizer, and decide whether you will be training it on a `gpu` or `cpu`. In this case, you will train your model on a cpu for a few steps and we will load in a pre-trained model that you can use to predict with your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1lkVebQRWRV"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 Training the model\n",
    "\n",
    "You will now write a function that takes in your model and trains it. To train your model you have to decide how many times you want to iterate over the entire data set. Each iteration is defined as an `epoch`. For each epoch, you have to go over all the data, using your training iterator.\n",
    "\n",
    "<a name='ex05'></a>\n",
    "### Exercise 05\n",
    "**Instructions:** Implement the `train_model` program below to train the neural network above. Here is a list of things you should do:\n",
    "\n",
    "- Create the train task by calling [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) and pass in the following: \n",
    "    - <span style='color:blue'> labeled_data </span> = train_gen\n",
    "    - <span style='color:blue'> loss_fn </span> = [tl.CrossEntropyLoss()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss)\n",
    "    - <span style='color:blue'> optimizer </span> = [trax.optimizers.Adam(0.01)](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam)\n",
    "    - <span style='color:blue'> lr_schedule </span> = [lr_schedule](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.lr_schedules.warmup_and_rsqrt_decay)\n",
    "\n",
    "\n",
    "- Create the eval task by calling [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) and pass in the following: \n",
    "    - <span style='color:blue'> labeled_data </span> = eval_gen\n",
    "    - <span style='color:blue'> metrics </span> = tl.CrossEntropyLoss() and [tl.Accuracy()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy)\n",
    "    \n",
    "    \n",
    "- Create the training loop by calling [`trax.supervised.Training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) and pass in the following: \n",
    "    - <span style='color:blue'> TransformerLM </span> \n",
    "    - <span style='color:blue'> train_task </span> \n",
    "    - <span style='color:blue'> eval_task </span> = [eval_task]\n",
    "    - <span style='color:blue'> output_dir</span> = output_dir\n",
    "    \n",
    "You will be using a cross entropy loss, with Adam optimizer. Please read the [Trax](https://trax-ml.readthedocs.io/en/latest/index.html) documentation to get a full understanding. \n",
    "\n",
    "The training loop that this function returns can be runned using the `run()` method by passing in the desired number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:05:40.069862Z",
     "start_time": "2021-08-16T02:05:40.062142Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gM2gpu4xvjtX"
   },
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "# UNQ_C8\n",
    "# GRADED FUNCTION: train_model\n",
    "def training_loop(TransformerLM, train_gen, eval_gen, output_dir = \"~/model\"):\n",
    "    '''\n",
    "    Input:\n",
    "        TransformerLM (trax.layers.combinators.Serial): The model you are building.\n",
    "        train_gen (generator): Training stream of data.\n",
    "        eval_gen (generator): Evaluation stream of data.\n",
    "        output_dir (str): folder to save your file.\n",
    "        \n",
    "    Returns:\n",
    "        trax.supervised.training.Loop: Training loop.\n",
    "    '''\n",
    "    output_dir = os.path.expanduser(output_dir)  # trainer is an object\n",
    "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.01)\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    train_task = training.TrainTask( \n",
    "      labeled_data=train_gen, # The training generator\n",
    "      loss_layer=tl.CrossEntropyLoss(), # Loss function \n",
    "      optimizer=trax.optimizers.Adam(0.01), # Optimizer (Don't forget to set LR to 0.01)\n",
    "      lr_schedule=lr_schedule,\n",
    "      n_steps_per_checkpoint=10\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask( \n",
    "      labeled_data=eval_gen, # The evaluation generator\n",
    "      metrics=[tl.CrossEntropyLoss(), tl.Accuracy()] # CrossEntropyLoss and Accuracy\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    loop = training.Loop(TransformerLM(d_model=4,\n",
    "                                       d_ff=16,\n",
    "                                       n_layers=1,\n",
    "                                       n_heads=2,\n",
    "                                       mode='train'),\n",
    "                         train_task,\n",
    "                         eval_tasks=[eval_task],\n",
    "                         output_dir=output_dir)\n",
    "    \n",
    "    return loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model will be trained for only 10 steps. \n",
    "\n",
    "Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:07:04.636778Z",
     "start_time": "2021-08-16T02:05:42.124962Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "BFRBTwSqRWRZ",
    "outputId": "aff859e5-8f4a-4d3b-f1d3-98e137581a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[2,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (2, 1217, 1217)\n",
      "Traced<ShapedArray(float32[2,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (2, 1217, 1217)\n",
      "Traced<ShapedArray(float32[2,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (2, 1217, 1217)\n",
      "Traced<ShapedArray(float32[2,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (2, 1217, 1217)\n",
      "Traced<ShapedArray(float32[2,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (2, 1217, 1217)\n",
      "Traced<ShapedArray(float32[2,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (2, 1217, 1217)\n",
      "Traced<ShapedArray(float32[4,1024,1024])>with<DynamicJaxprTrace(level=1/0)> (4, 1024, 1024)\n",
      "Traced<ShapedArray(float32[4,1024,1024])>with<JVPTrace(level=2/1)>\n",
      "  with primal = Traced<ShapedArray(float32[4,1024,1024])>with<DynamicJaxprTrace(level=0/1)>\n",
      "       tangent = Traced<ShapedArray(float32[4,1024,1024]):JaxprTrace(level=1/1)> (4, 1024, 1024)\n",
      "\n",
      "Step      1: Total number of trainable weights: 316336\n",
      "Step      1: Ran 1 train steps in 10.70 secs\n",
      "Step      1: train CrossEntropyLoss |  10.41411781\n",
      "Traced<ShapedArray(float32[4,1024,1024])>with<DynamicJaxprTrace(level=0/1)> (4, 1024, 1024)\n",
      "Step      1: eval  CrossEntropyLoss |  10.41093445\n",
      "Step      1: eval          Accuracy |  0.00000000\n",
      "Traced<ShapedArray(float32[2,1443,1443])>with<JVPTrace(level=2/1)>\n",
      "  with primal = Traced<ShapedArray(float32[2,1443,1443])>with<DynamicJaxprTrace(level=0/1)>\n",
      "       tangent = Traced<ShapedArray(float32[2,1443,1443]):JaxprTrace(level=1/1)> (2, 1443, 1443)\n",
      "Traced<ShapedArray(float32[2,1188,1188])>with<JVPTrace(level=2/1)>\n",
      "  with primal = Traced<ShapedArray(float32[2,1188,1188])>with<DynamicJaxprTrace(level=0/1)>\n",
      "       tangent = Traced<ShapedArray(float32[2,1188,1188]):JaxprTrace(level=1/1)> (2, 1188, 1188)\n",
      "Traced<ShapedArray(float32[2,1724,1724])>with<JVPTrace(level=2/1)>\n",
      "  with primal = Traced<ShapedArray(float32[2,1724,1724])>with<DynamicJaxprTrace(level=0/1)>\n",
      "       tangent = Traced<ShapedArray(float32[2,1724,1724]):JaxprTrace(level=1/1)> (2, 1724, 1724)\n",
      "Traced<ShapedArray(float32[2,1413,1413])>with<JVPTrace(level=2/1)>\n",
      "  with primal = Traced<ShapedArray(float32[2,1413,1413])>with<DynamicJaxprTrace(level=0/1)>\n",
      "       tangent = Traced<ShapedArray(float32[2,1413,1413]):JaxprTrace(level=1/1)> (2, 1413, 1413)\n",
      "Traced<ShapedArray(float32[2,1275,1275])>with<JVPTrace(level=2/1)>\n",
      "  with primal = Traced<ShapedArray(float32[2,1275,1275])>with<DynamicJaxprTrace(level=0/1)>\n",
      "       tangent = Traced<ShapedArray(float32[2,1275,1275]):JaxprTrace(level=1/1)> (2, 1275, 1275)\n",
      "\n",
      "Step     10: Ran 9 train steps in 57.41 secs\n",
      "Step     10: train CrossEntropyLoss |  10.41297531\n",
      "Traced<ShapedArray(float32[2,1436,1436])>with<DynamicJaxprTrace(level=0/1)> (2, 1436, 1436)\n",
      "Step     10: eval  CrossEntropyLoss |  10.40823174\n",
      "Step     10: eval          Accuracy |  0.00000000\n"
     ]
    }
   ],
   "source": [
    "# Should take around 1.5 minutes\n",
    "!rm -f ~/model/model.pkl.gz\n",
    "loop = training_loop(TransformerLM, train_batch_stream, eval_batch_stream)\n",
    "loop.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKrEBjmskeWa"
   },
   "source": [
    " <a name='4'></a>\n",
    " # Part 4:  Evaluation  \n",
    "\n",
    "<a name='4.1'></a>\n",
    "### 4.1 Loading in a trained model\n",
    "\n",
    "In this part you will evaluate by loading in an almost exact version of the model you coded, but we trained it for you to save you time. Please run the cell below to load in the model.\n",
    "\n",
    "As you may have already noticed the model that you trained and the pretrained model share the same overall architecture but they have different values for some of the parameters:\n",
    "\n",
    "    \n",
    "   `Original (pretrained) model: `                                 \n",
    "                                       \n",
    "    TransformerLM(vocab_size=33300, d_model=512, d_ff=2048, n_layers=6, n_heads=8, \n",
    "                   dropout=0.1, max_len=4096, ff_activation=tl.Relu)\n",
    "                   \n",
    "   `Your model:`\n",
    "   \n",
    "    TransformerLM(d_model=4, d_ff=16, n_layers=1, n_heads=2)\n",
    "   \n",
    "   **Only the parameters shown for your model were changed. The others stayed the same.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:07:05.583156Z",
     "start_time": "2021-08-16T02:07:04.639223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2252\r\n",
      "-rw-r--r--. 1 root root    2744 Aug 16 02:05 config.gin\r\n",
      "-rw-r--r--. 1 root root       6 Aug 16 02:06 data_counters0.pkl\r\n",
      "drwxr-xr-x. 2 root root     261 Aug 16 02:06 eval\r\n",
      "-rw-r--r--. 1 root root 1143897 Aug 16 02:07 model.opt_slots0.npy.gz\r\n",
      "-rw-r--r--. 1 root root     637 Aug 16 02:07 model.pkl.gz\r\n",
      "-rw-r--r--. 1 root root 1144656 Aug 16 02:07 model.weights.npy.gz\r\n",
      "drwxr-xr-x. 2 root root     261 Aug 16 02:05 train\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {os.path.expanduser('~/model')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T02:07:15.282210Z",
     "start_time": "2021-08-16T02:07:05.586496Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zWoSzR5tkoAx",
    "outputId": "2b9f1cca-4778-4509-bd9e-bd1738625a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=1/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n",
      "Traced<ShapedArray(float32[8,1217,1217])>with<DynamicJaxprTrace(level=2/0)> (8, 1217, 1217)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-675824437297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the pre-trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/layers/base.py\u001b[0m in \u001b[0;36minit_from_file\u001b[0;34m(self, file_name, weights_only, input_signature)\u001b[0m\n\u001b[1;32m    351\u001b[0m     weights, state = unflatten_weights_and_state(\n\u001b[1;32m    352\u001b[0m         \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flat_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flat_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         weights_and_state_sig, weights_only=weights_only)\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/layers/base.py\u001b[0m in \u001b[0;36munflatten_weights_and_state\u001b[0;34m(flat_weights, flat_state, weights_and_state_signature, weights_only)\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0mweights_to_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEMPTY_WEIGHTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGET_WEIGHTS_FROM_CACHE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m   weights, _ = fastmath.tree_unflatten(flat_weights, weights_tree,\n\u001b[0;32m--> 837\u001b[0;31m                                        copy_from_tree=weights_to_copy)\n\u001b[0m\u001b[1;32m    838\u001b[0m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       \u001b[0mnew_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_from_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(flat, tree, copy_from_tree)\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0mnew_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get the model architecture\n",
    "model = TransformerLM(mode='eval')\n",
    "\n",
    "# Load the pre-trained weights\n",
    "model.init_from_file(os.path.expanduser('~/model') + '/model.pkl.gz', weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilM9C8P3RWRf"
   },
   "source": [
    "<a name='5'></a>\n",
    "# Part 5: Testing with your own input\n",
    "\n",
    "You will now test your input. You are going to implement greedy decoding. This consists of two functions. The first one allows you to identify the next symbol. It gets the argmax of the output of your model and then returns that index. \n",
    "\n",
    "<a name='ex06'></a>\n",
    "### Exercise 06\n",
    "**Instructions:** Implement the next symbol function that takes in the cur_output_tokens and the trained model to return the index of the next word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:10:09.593Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rD_bXRCpRWRg"
   },
   "outputs": [],
   "source": [
    "# UNQ_C9\n",
    "def next_symbol(cur_output_tokens, model):\n",
    "    \"\"\"Returns the next symbol for a given sentence.\n",
    "\n",
    "    Args:\n",
    "        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.\n",
    "        model (trax.layers.combinators.Serial): The transformer model.\n",
    "\n",
    "    Returns:\n",
    "        int: tokenized symbol.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # current output tokens length\n",
    "    token_length = len(cur_output_tokens)\n",
    "    # calculate the minimum power of 2 big enough to store token_length\n",
    "    # HINT: use np.ceil() and np.log2()\n",
    "    # add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0\n",
    "    padded_length = 2**int(np.ceil(np.log2(token_length + 1)))\n",
    "\n",
    "    # Fill cur_output_tokens with 0's until it reaches padded_length\n",
    "    padded = cur_output_tokens + [0] * (padded_length - token_length)\n",
    "    padded_with_batch = np.array(padded)[None, :] # Don't replace this 'None'! This is a way of setting the batch dim\n",
    "\n",
    "    # model expects a tuple containing two padded tensors (with batch)\n",
    "    output, _ = model((padded_with_batch, padded_with_batch)) \n",
    "    # HINT: output has shape (1, padded_length, vocab_size)\n",
    "    # To get log_probs you need to index output with 0 in the first dim\n",
    "    # token_length in the second dim and all of the entries for the last dim.\n",
    "    log_probs = output[0, token_length, :]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return int(np.argmax(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:10:10.173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test it out!\n",
    "sentence_test_nxt_symbl = \"I want to fly in the sky.\"\n",
    "detokenize([next_symbol(tokenize(sentence_test_nxt_symbl)+[0], model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "'The'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AwrQFglRWRj"
   },
   "source": [
    "<a name='5.1'></a>\n",
    "### 5.1 Greedy decoding\n",
    "\n",
    "Now you will implement the greedy_decode algorithm that will call the `next_symbol` function. It takes in the input_sentence, the trained model and returns the decoded sentence. \n",
    "\n",
    "<a name='ex07'></a>\n",
    "### Exercise 07\n",
    "\n",
    "**Instructions**: Implement the greedy_decode algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:10:12.153Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6HwIdimiN0k2"
   },
   "outputs": [],
   "source": [
    "# UNQ_C10\n",
    "# Decoding functions.\n",
    "def greedy_decode(input_sentence, model):\n",
    "    \"\"\"Greedy decode function.\n",
    "\n",
    "    Args:\n",
    "        input_sentence (string): a sentence or article.\n",
    "        model (trax.layers.combinators.Serial): Transformer model.\n",
    "\n",
    "    Returns:\n",
    "        string: summary of the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # Use tokenize()\n",
    "    cur_output_tokens = tokenize(input_sentence)  + [0]\n",
    "    generated_output = [] \n",
    "    cur_output = 0 \n",
    "    EOS = 1 \n",
    "    \n",
    "    while cur_output != EOS:\n",
    "        # Get next symbol\n",
    "        cur_output = next_symbol(cur_output_tokens, model)\n",
    "        # Append next symbol to original sentence\n",
    "        cur_output_tokens.append(cur_output)\n",
    "        # Append next symbol to generated sentence\n",
    "        generated_output.append(cur_output)\n",
    "        print(detokenize(generated_output))\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return detokenize(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:10:13.132Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "9kHuIDGW1sOr",
    "outputId": "2525ca2c-4625-47c0-8456-f75598581993"
   },
   "outputs": [],
   "source": [
    "# Test it out on a sentence!\n",
    "test_sentence = \"It was a sunny day when I went to the market to buy some flowers. But I only found roses, not tulips.\"\n",
    "print(wrapper.fill(test_sentence), '\\n')\n",
    "print(greedy_decode(test_sentence, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA-279WI2D3G"
   },
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    ":\n",
    ": I\n",
    ": I just\n",
    ": I just found\n",
    ": I just found ros\n",
    ": I just found roses\n",
    ": I just found roses,\n",
    ": I just found roses, not\n",
    ": I just found roses, not tu\n",
    ": I just found roses, not tulips\n",
    ": I just found roses, not tulips\n",
    ": I just found roses, not tulips.\n",
    ": I just found roses, not tulips.<EOS>\n",
    ": I just found roses, not tulips.<EOS>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-16T02:10:15.013Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DYgX-mzjyUia",
    "outputId": "b901e164-48b3-4124-d21a-fe7443d15b79"
   },
   "outputs": [],
   "source": [
    "# Test it out with a whole article!\n",
    "article = \"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\n",
    "print(wrapper.fill(article), '\\n')\n",
    "print(greedy_decode(article, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Jordan\n",
    "Jordan Ful\n",
    "Jordan Fulcol\n",
    "Jordan Fulcoly\n",
    "Jordan Fulcoly,\n",
    "Jordan Fulcoly, Wayne\n",
    "Jordan Fulcoly, Wayne Dre\n",
    "Jordan Fulcoly, Wayne Drexe\n",
    "Jordan Fulcoly, Wayne Drexel\n",
    "Jordan Fulcoly, Wayne Drexel,\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "Final summary:\n",
    "\n",
    "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
    "suspended for one day. Four students were suspended for one day\n",
    "because they allegedly did not heed to warnings that the 'Tebowing'\n",
    "craze was blocking the hallway and presenting a safety hazard to\n",
    "students.<EOS>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!** You did a lot of work and now you should have a better understanding of the encoder part of Transformers and how Transformers can be used for text summarization.\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC4-2"
   ]
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "\n",
    "base_path = '/notebooks/eipi10/arsenal'\n",
    "sys.path.append(base_path)\n",
    "current_path = '.'\n",
    "current_data_path = current_path + \"/data\"\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "logging.root.setLevel(level=logging.INFO)\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from eipi10.ml2.utils import *\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "os.environ[\"https_proxy\"] = \"http://web-proxy.rose.hp.com:8080\"\n",
    "os.environ[\"http_proxy\"] = \"http://web-proxy.rose.hp.com:8080\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 代码自动重新加载\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# #当module有新的方法的时候，需要运行下面方法。\n",
    "# %reload_ext autoreload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.20 HMM（隐形马尔可夫，Hidden Markov Model） \n",
    "\n",
    "**history**\n",
    "- [2018-07-19]\n",
    "- [2018-07-23] 编写自己的viterbi算法。\n",
    "- [2018-08-08] 更新概率图模型的一些介绍\n",
    "- [2018-09-17] 前向算法和后向算法的一些总结\n",
    "\n",
    "![hmm](../../image/hmm.png)\n",
    "\n",
    "**reference**  \n",
    "- [如何用简单易懂的例子解释隐马尔可夫模型？](https://www.zhihu.com/question/20962240)   \n",
    "- [【中文分词】最大熵马尔可夫模型MEMM](https://www.cnblogs.com/en-heng/p/6201893.html)\n",
    "- [ZH奶酪：隐马尔可夫模型学习小记——forward算法+viterbi算法+forward-backward算法（Baum-welch算法）](http://www.aizhuanji.com/a/GV8KDQ3w.html) 里面总结了HMM的资料，同时附有代码（包括前向，后向，Baum-Welch算法），还是不错的。\n",
    "- [隐马尔科夫模型python实现简单拼音输入法](http://www.aizhuanji.com/a/PGV8rnxv.html) 里面的这个例子，有机会一定要实现一下。\n",
    "\n",
    "#### 1.20.1 基本概念和实践\n",
    "\n",
    "\n",
    "在概率图模型中，HMM属于生成模型的有向图PGM，通过联合概率建模：\n",
    "\n",
    "$$P(S,O) = \\prod_{t=1}^{n}P(s_t|s_{t-1})P(o_t|s_t)$$\n",
    "\n",
    "其中，$S$、$O$分别表示状态序列与观测序列。HMM的解码问题为$ \\arg \\mathop{max}\\limits_{S} P(S|O)$；定义在时刻$t$状态为s的所有单个路径$s_1^t$中的概率最大值为\n",
    "\n",
    "$$\\delta_t(s) = \\max P(s_1^{t-1}, o_1^{t}, s_t=s)$$\n",
    "\n",
    "则有\n",
    "$$\\begin{aligned}\n",
    "\\delta_{t+1}(s)  & = \\max P(s_1^{t}, o_1^{t+1}, s_{t+1}=s) \\\\\n",
    "& = \\max_{s'} P(s_1^{t-1}, o_1^{t}, s_t=s') P(s_{t+1}|s_t) P(o_{t+1}|s_{t+1}) \\\\\n",
    "& = \\max_{s'} [\\delta_t(s') P(s|s')] P(o_{t+1}|s)\n",
    "\\end{aligned}$$\n",
    "\n",
    "$s'$, $s$分别代表$s_{t}$,$s_{t+1}$。上述式子即为（用于解决HMM的解码问题的）Viterbi算法的递推式；可以看出HMM是通过联合概率来求解标注问题的。\n",
    "\n",
    "不得不感叹，隐形马尔科夫的这种假设，真是简单粗暴，但实际效果似乎不错。jieba中使用了HMM的功能，它是如果假设的呢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sunny  rainy\n",
      "initial    0.4    0.6\n",
      "       sunny  rainy\n",
      "sunny    0.6    0.4\n",
      "rainy    0.3    0.7\n",
      "       walk  shop  clean\n",
      "sunny   0.6   0.3    0.1\n",
      "rainy   0.1   0.4    0.5\n",
      "--------------------------------------------------\n",
      "0.033611999999999996\n",
      "0: [[0.24 0.06]]\n",
      "1: [[0.0486 0.0552]]\n",
      "2: [[0.004572 0.02904 ]]\n",
      "p(walk, shop, clean) = 0.033612\n",
      "p(walk, shop, clean, walk) = 0.0090888\n",
      "==================================================\n",
      "[[0.24 0.06]]\n",
      "[[0.0432 0.0384]\n",
      " [0.0054 0.0168]]\n",
      "[[[0.002592 0.00864 ]\n",
      "  [0.001152 0.01344 ]]\n",
      "\n",
      " [[0.000324 0.00108 ]\n",
      "  [0.000504 0.00588 ]]]\n",
      "0.033611999999999996\n",
      "==================================================\n",
      "0: [[0.24 0.06]]\n",
      "--------------------1,(2, 2)--------------------\n",
      "[[0.0432 0.0384]\n",
      " [0.0054 0.0168]]\n",
      "(walk, shop): 0.1038 - ['sunny', 'sunny'] - 0.043199999999999995\n",
      "==================================================\n",
      "0: [[0.24 0.06]]\n",
      "--------------------1,(2, 2)--------------------\n",
      "[[0.0432 0.0384]\n",
      " [0.0054 0.0168]]\n",
      "--------------------2,(2, 2, 2)--------------------\n",
      "[[[0.002592 0.00864 ]\n",
      "  [0.001152 0.01344 ]]\n",
      "\n",
      " [[0.000324 0.00108 ]\n",
      "  [0.000504 0.00588 ]]]\n",
      "(walk, shop, clean): 0.033611999999999996 - ['sunny', 'rainy', 'rainy'] - 0.01344\n",
      "==================================================\n",
      "p(walk, shop, clean, walk) = 0.0090888\n",
      "(walk, shop, clean, walk): 0.0090888 - ['sunny', 'rainy', 'rainy', 'sunny'] - 0.0024192\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "[[0.24 0.06]] [['sunny'], ['rainy']]\n",
      "--------------------------------------------------\n",
      "[0.0432 0.0384] [0 0] [['sunny', 'sunny'], ['sunny', 'rainy']]\n",
      "--------------------------------------------------\n",
      "[0.002592 0.01344 ] [0 1] [['sunny', 'sunny', 'sunny'], ['sunny', 'rainy', 'rainy']]\n",
      "(0.01344, ['sunny', 'rainy', 'rainy'])\n",
      "==================================================\n",
      "(0.0024192, ['sunny', 'rainy', 'rainy', 'sunny'])\n"
     ]
    }
   ],
   "source": [
    "#  天气模型 参考自https://www.zhihu.com/question/20962240/answer/64187492\n",
    "#  三种天气sunny, rainy\n",
    "#  三种行动散步，购物，收拾\n",
    "\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "df_pi = pd.DataFrame([[0.4, 0.6]], index=['initial'], columns=['sunny', 'rainy'])\n",
    "pi = df_pi.values\n",
    "#状态转移概率矩阵   \n",
    "df_A = pd.DataFrame([[0.6, 0.4], [0.3, 0.7]], index=['sunny',  'rainy'], columns=['sunny',  'rainy'])  \n",
    "A = df_A.values\n",
    "#观测概率矩阵\n",
    "df_B = pd.DataFrame([[0.6, 0.3, 0.1], [0.1, 0.4, 0.5]], index=['sunny',  'rainy'], columns=['walk', 'shop', 'clean'])\n",
    "B = df_B.values\n",
    "print(df_pi)\n",
    "print(df_A)\n",
    "print(df_B)\n",
    "\n",
    "# 第一个问题： 观察序列是 walk, shop, clean, 请问这个的概率有多大 \n",
    "print('-'*50)\n",
    "p_manual = 0.6*0.1*0.7*0.4*0.7*0.5 + 0.6*0.1*0.7*0.4*0.3*0.1 + \\\n",
    "            0.6*0.1*0.3*0.3*0.4*0.5 + 0.6*0.1*0.3*0.3*0.6*0.1 +  \\\n",
    "            0.4*0.6*0.4*0.4*0.7*0.5 + 0.4*0.6*0.4*0.4*0.3*0.1 +  \\\n",
    "            0.4*0.6*0.6*0.3*0.4*0.5 + 0.4*0.6*0.6*0.3*0.6*0.1\n",
    "print(p_manual)  #手工计算的结果\n",
    "\n",
    "def sequence_probability(sequnece=['walk', 'shop', 'clean'], verbose=False):\n",
    "    names = list(df_B.columns)\n",
    "    indexs = [names.index(b) for b in sequnece]\n",
    "    \n",
    "    prob = pi\n",
    "    for i, index in enumerate(indexs):\n",
    "        p = prob * B[:, index]\n",
    "        prob = p.dot(A)\n",
    "        if verbose: print('{}: {}'.format(i, p))\n",
    "    return np.sum(p)\n",
    "sequnece=['walk', 'shop', 'clean']\n",
    "p = sequence_probability(sequnece, verbose='True')\n",
    "print('p({}) = {}'.format(', '.join(sequnece), p))\n",
    "assert(math.isclose(p, p_manual))\n",
    "\n",
    "#如果观察序列是 walk, shop, clean, walk, 概率多大\n",
    "sequnece=['walk', 'shop', 'clean', 'walk']\n",
    "p = sequence_probability(sequnece4)\n",
    "print('p({}) = {}'.format(', '.join(sequnece), p))\n",
    "\n",
    "# 第二个问题： 观察序列是 walk, shop, clean, 请问这种情况下，这三天的天气最有可能是？ \n",
    "print('='*50)\n",
    "day1 = pi * B[:,0]\n",
    "day2 = day1.reshape(2,1) * A * B[:,1] \n",
    "day3 = np.array([row.reshape(2,1) * A * B[:,2] for row in day2 ])\n",
    "\n",
    "print(day1)\n",
    "print(day2)\n",
    "print(day3)\n",
    "print(np.sum(day3))\n",
    "assert(math.isclose(np.sum(day3), p_manual))\n",
    "\n",
    "\n",
    "\n",
    "def hide_probability(sequnece=['walk', 'shop', 'clean'], verbose=False):\n",
    "    '''\n",
    "    实现了HMM的第二类问题。主要是思路是，把A的不同状态的组合变换成一个无限的多维数组。\n",
    "    比如： B_sequnece=['walk', 'shop', 'clean'], A_sequence是一个shape为（2，2，2）的数组\n",
    "    这个数组的最后一个维度，代表了最后一个时间点的，A的状态概率。\n",
    "    在计算的时候，由于多维数组不方便递归，所以先把多维数组变成二维数组【prob.reshape(-1, A.shape[0])】\n",
    "    '''\n",
    "    names = list(df_B.columns)\n",
    "    indexs = np.array([names.index(b) for b in sequnece])\n",
    "    \n",
    "    prob = pi * B[:,indexs[0]]\n",
    "    new_shape = (A.shape[0],)\n",
    "    if verbose: print('{}: {}'.format(0, prob))\n",
    "    for i, index in enumerate(indexs[1:]):\n",
    "        new_shape = (A.shape[0],) + new_shape\n",
    "        prob = prob.reshape(-1, A.shape[0])\n",
    "        prob = np.array([row.reshape(2,1) * A * B[:,index] for row in prob ]).reshape(new_shape)        \n",
    "        if verbose: print('--------------------{},{}--------------------'.format(i+1, prob.shape))\n",
    "        if verbose: print('{}'.format(prob))\n",
    "    hide_sequence =  [ df_A.columns[index] for index in np.unravel_index(np.argmax(prob, axis=None), prob.shape)]\n",
    "    return prob, hide_sequence, np.max(prob, axis=None)\n",
    "\n",
    "print('='*50)\n",
    "sequence=['walk', 'shop']\n",
    "prob_matrix, hide_sequence, prob = hide_probability(sequence, True)\n",
    "print('({}): {} - {} - {}'.format(', '.join(sequence), np.sum(prob_matrix), hide_sequence, prob ))\n",
    "\n",
    "print('='*50)\n",
    "sequence=['walk', 'shop', 'clean']\n",
    "prob_matrix, hide_sequence, prob  = hide_probability(sequence, True)\n",
    "print('({}): {} - {} - {}'.format(', '.join(sequence), np.sum(prob_matrix), hide_sequence, prob ))\n",
    "assert(math.isclose(np.sum(prob_matrix), p_manual))\n",
    "\n",
    "# 进一步检查是否正确\n",
    "print('='*50)\n",
    "sequence=['walk', 'shop', 'clean', 'walk']\n",
    "p_sequence= sequence_probability(sequnece4)\n",
    "print('p({}) = {}'.format(', '.join(sequence), p_sequence))\n",
    "\n",
    "p = hide_probability(sequnece)\n",
    "prob_matrix, hide_sequence, prob  = hide_probability(sequence)\n",
    "print('({}): {} - {} - {}'.format(', '.join(sequence), np.sum(prob_matrix), hide_sequence, prob ))\n",
    "assert(math.isclose(np.sum(prob_matrix), p_sequence))\n",
    "\n",
    "\n",
    "def viterbi(output, df_pi, df_A, df_B, verbose=False):       \n",
    "    '''\n",
    "    下面是根据 viterbi的概念，自己实现的算法。和下面来自wiki的不同，自己的这个版本，采用了矩阵计算的方法，更加的简洁\n",
    "    '''\n",
    "    hidden_states = list(df_A.columns)\n",
    "    output_states = list(df_B.columns)\n",
    "    pi = df_pi.values \n",
    "    A = df_A.values\n",
    "    B = df_B.values    \n",
    "    \n",
    "    indexs = np.array([output_states.index(b) for b in output])\n",
    "    \n",
    "    probs = (pi * B[:,indexs[0]])\n",
    "    paths = [[state]  for state in hidden_states]\n",
    " \n",
    "    if verbose: print('-'*50)\n",
    "    if verbose: print(probs, paths)  \n",
    "    for index in indexs[1:]:\n",
    "        probs = probs.reshape(2, 1)*A*B[:, index]\n",
    "        probs_max_index = np.argmax(probs, axis=0)\n",
    "        probs = np.max(probs, axis=0)     \n",
    "\n",
    "        # 09-15 今天又看了一遍自己写的算法，看起来还挺巧妙地。\n",
    "        paths = [paths[prob_max_index] + [hidden_states[i]] for i, prob_max_index in enumerate(probs_max_index)]\n",
    "        if verbose: print('-'*50)\n",
    "        if verbose: print(probs, probs_max_index, paths)   \n",
    "          \n",
    "    prob = np.max(probs)\n",
    "    return prob, paths[np.argmax(probs)]\n",
    "\n",
    "print('='*50)\n",
    "print(viterbi(['walk', 'shop', 'clean'], df_pi, df_A, df_B, verbose=True))\n",
    "print('='*50)\n",
    "print(viterbi(['walk', 'shop', 'clean', 'walk'], df_pi, df_A, df_B) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面用于求解第二类问题的算法复杂度时是$O(n^m)$, n是隐含状态的个数，m是观察序列的长度。下面是[Viterbi算法](https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95)，它的算法复杂度是$O(m*n^2)$，具体说来，就在1，2，3 ...,t的每个时刻，都要计算一个n*n的矩阵。仔细阅读了一下vitberbi的算法，发现其巧妙之处是，假设我们知道第t-1时刻，各个隐含状态的概率值，那么在计算t的时候，只要根据这个概率值计算t时刻的各个隐含状态的概率就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1      2\n",
      "Fever: 0.04000 0.02700 0.01512 \n",
      "Healt: 0.30000 0.08400 0.00588 \n",
      "(0.01512, ['Healthy', 'Healthy', 'Fever'])\n",
      "==================================================\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}]\n",
      "path={'sunny': ['sunny'], 'rainy': ['rainy']}\n",
      "-----------------1---------------\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}, {'sunny': 0.043199999999999995, 'rainy': 0.038400000000000004}]\n",
      "path={'sunny': ['sunny', 'sunny'], 'rainy': ['sunny', 'rainy']}\n",
      "-----------------2---------------\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}, {'sunny': 0.043199999999999995, 'rainy': 0.038400000000000004}, {'sunny': 0.0025919999999999997, 'rainy': 0.01344}]\n",
      "path={'sunny': ['sunny', 'sunny', 'sunny'], 'rainy': ['sunny', 'rainy', 'rainy']}\n",
      "          0      1      2\n",
      "sunny: 0.24000 0.04320 0.00259 \n",
      "rainy: 0.06000 0.03840 0.01344 \n",
      "(0.01344, ['sunny', 'rainy', 'rainy'])\n",
      "==================================================\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}]\n",
      "path={'sunny': ['sunny'], 'rainy': ['rainy']}\n",
      "-----------------1---------------\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}, {'sunny': 0.043199999999999995, 'rainy': 0.038400000000000004}]\n",
      "path={'sunny': ['sunny', 'sunny'], 'rainy': ['sunny', 'rainy']}\n",
      "-----------------2---------------\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}, {'sunny': 0.043199999999999995, 'rainy': 0.038400000000000004}, {'sunny': 0.0025919999999999997, 'rainy': 0.01344}]\n",
      "path={'sunny': ['sunny', 'sunny', 'sunny'], 'rainy': ['sunny', 'rainy', 'rainy']}\n",
      "-----------------3---------------\n",
      "V=[{'sunny': 0.24, 'rainy': 0.06}, {'sunny': 0.043199999999999995, 'rainy': 0.038400000000000004}, {'sunny': 0.0025919999999999997, 'rainy': 0.01344}, {'sunny': 0.0024192, 'rainy': 0.0009408}]\n",
      "path={'sunny': ['sunny', 'rainy', 'rainy', 'sunny'], 'rainy': ['sunny', 'rainy', 'rainy', 'rainy']}\n",
      "          0      1      2      3\n",
      "sunny: 0.24000 0.04320 0.00259 0.00241 \n",
      "rainy: 0.06000 0.03840 0.01344 0.00094 \n",
      "(0.0024192, ['sunny', 'rainy', 'rainy', 'sunny'])\n"
     ]
    }
   ],
   "source": [
    "# Helps visualize the steps of Viterbi.\n",
    "def print_dptable(V):\n",
    "    print(\"    \",end='')\n",
    "    for i in range(len(V)): print(\"%7d\" % i,end='')\n",
    "    print(\"\")\n",
    "\n",
    "    for y in V[0].keys():\n",
    "        print(\"%.5s: \" % y,end='')\n",
    "        for t in range(len(V)):\n",
    "            print(\"%.7s\" % (\"%f\" % V[t][y]),end=' ')\n",
    "        print(\"\")\n",
    "\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p,verbose=False):\n",
    "    V = [{}]  #保存1，2，3 ...,t ，生成相应观察矩阵，每个隐含状态的最大概率\n",
    "    path = {}\n",
    "\n",
    "    # Initialize base cases (t == 0)\n",
    "    for y in states:\n",
    "        V[0][y] = start_p[y] * emit_p[y][obs[0]]\n",
    "        path[y] = [y]\n",
    "    if verbose : print(\"V={}\\npath={}\".format(V, path))\n",
    "\n",
    "    # Run Viterbi for t > 0\n",
    "    for t in range(1,len(obs)):\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    "\n",
    "        # 下面算法，应该是从wiki上抓下来的，从形式上，不如我写的简洁啊。\n",
    "        for y in states:\n",
    "            (prob, state) = max([(V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states])\n",
    "            V[t][y] = prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "        \n",
    "        if verbose : print(\"-----------------{}---------------\".format(t))\n",
    "        if verbose : print(\"V={}\\npath={}\".format(V, newpath))\n",
    "        # Don't need to remember the old paths\n",
    "        path = newpath\n",
    "\n",
    "    print_dptable(V)\n",
    "    (prob, state) = max([(V[len(obs) - 1][y], y) for y in states])\n",
    "    return (prob, path[state])\n",
    "\n",
    "def example():\n",
    "    states = ('Healthy', 'Fever')\n",
    "\n",
    "    observations = ('normal', 'cold', 'dizzy')\n",
    "\n",
    "    start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "\n",
    "    transition_probability = {\n",
    "       'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "       'Fever' : {'Healthy': 0.4, 'Fever': 0.6},\n",
    "       }\n",
    "\n",
    "    emission_probability = {\n",
    "       'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "       'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "       }\n",
    "        \n",
    "    \n",
    "    return viterbi(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability)\n",
    "\n",
    "def example1():\n",
    "    states = ('sunny', 'rainy')\n",
    "\n",
    "    observations = ('walk', 'shop', 'clean')\n",
    "\n",
    "    start_probability = {'sunny': 0.4, 'rainy': 0.6}\n",
    "\n",
    "    transition_probability = {\n",
    "       'sunny' : {'sunny': 0.6, 'rainy': 0.4},\n",
    "       'rainy' : {'sunny': 0.3, 'rainy': 0.7},\n",
    "       }\n",
    "\n",
    "    emission_probability = {\n",
    "       'sunny' : {'walk': 0.6, 'shop': 0.3, 'clean': 0.1},\n",
    "       'rainy' : {'walk': 0.1, 'shop': 0.4, 'clean': 0.5},\n",
    "       }\n",
    "    \n",
    "    return viterbi(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability, verbose=True)\n",
    "\n",
    "def example2():\n",
    "    states = ('sunny', 'rainy')\n",
    "\n",
    "    observations = ('walk', 'shop', 'clean', 'walk')\n",
    "\n",
    "    start_probability = {'sunny': 0.4, 'rainy': 0.6}\n",
    "\n",
    "    transition_probability = {\n",
    "       'sunny' : {'sunny': 0.6, 'rainy': 0.4},\n",
    "       'rainy' : {'sunny': 0.3, 'rainy': 0.7},\n",
    "       }\n",
    "\n",
    "    emission_probability = {\n",
    "       'sunny' : {'walk': 0.6, 'shop': 0.3, 'clean': 0.1},\n",
    "       'rainy' : {'walk': 0.1, 'shop': 0.4, 'clean': 0.5},\n",
    "       }\n",
    "    \n",
    "    return viterbi(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability, verbose=True)\n",
    "\n",
    "\n",
    "print(example())\n",
    "print('='*50)\n",
    "print(example1())\n",
    "print('='*50)\n",
    "print(example2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.20.2 前向后向算法\n",
    "\n",
    "主要的内容来自李航老师的统计学习方法第10章。前向后向算法是viterbi和Baum-Welch等算法的基础。下面做一些总结。\n",
    "\n",
    "HMM模型：\n",
    "\n",
    "$Q = (q_1, q_2, ... , q_N)$  \n",
    "$V = (v_1, v_2, ... , v_N)$  \n",
    "$\\lambda = (A, B, \\pi)$    \n",
    "$O = (o_1, o_2, ... , o_T)$  \n",
    "$H = (h_1, h_2, ... , h_T)$   $\\ \\ \\ \\ $书中公式为$I = (i_1, i_2, ... , i_T)$，因为感觉这个$i$在公式中两个地方用到，容易有歧义，所以做这个修改。 \n",
    "\n",
    "$Q$是所有可能的状态集合， $V$是所有的可能的观测的集合，$\\pi$是初始状态概率向量。 $A$是状态转移概率矩阵，$B$是观测概率矩阵。$O$是实际的观测序列，$H$是对应的状态序列。\n",
    "\n",
    "**三个问题**\n",
    "\n",
    "- 概率计算问题：已知模型$\\lambda = (A, B, \\pi)$ 和观测序列$O$，  计算$O$出现的概率$P(O \\lvert \\lambda)$。一般使用前向或后向算法。\n",
    "- 预测问题。已知模型$\\lambda = (A, B, \\pi)$ 和观测序列$O$，求最有可能的状态序列$H$。一般使用viterbi算法。\n",
    "- 学习问题。已知观测序列$O$，估计模型$\\lambda = (A, B, \\pi)$ 参数，使得在该模型下，$P(O \\lvert \\lambda)$最大。\n",
    "\n",
    "**前向算法**\n",
    "\n",
    "前向概率$\\alpha_t(q_i)$：时刻$t$，部分观察序列为$o_1, o_2, ... , o_t$,且状态为$q_i$的概率。\n",
    "\n",
    "$\\alpha_t(q_i) = P(o_1, o_2, ... , o_t，h_t = q_i \\lvert \\lambda) $\n",
    "\n",
    "可以得出 $\\alpha_t = [\\alpha_t(q_1), \\alpha_t(q_2),  ... , \\alpha_t(q_N)] $，也是一个向量。\n",
    "\n",
    "对于第一个问题，公式为：\n",
    "$\\alpha_{t+1} = SUM( \\alpha_{t} * A * B[:, o_{t+1}], axis=0)^{'}  $\n",
    "$\\alpha_1 = \\pi * B[:, o_{1}]^{'} $\n",
    "\n",
    "对于第二个问题，公式为：\n",
    "$\\alpha_{t+1} = MAX( \\alpha_{t} * A * B[:, o_{t+1}], axis=0)^{'}  $\n",
    "\n",
    "其实viterbi算法就是上述公式。\n",
    "\n",
    "\n",
    "$P(O \\lvert \\lambda) = \\sum \\alpha_{T}  $ \n",
    "\n",
    "$公式中{'}$表示转置。其中$\\alpha_{t} * A * B[:, o_{t+1}]$, 可以表示为下图：\n",
    "\n",
    "![hmm_forward](../../image/hmm_forward.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**后向算法**\n",
    "\n",
    "前向概率$\\beta_t(q_i)$：时刻$t$状态为$q_i$，从$t+1$到$T$的部分观察序列为$o_{t+1}, o_{t+2}, ... , o_{T}$的概率。\n",
    "\n",
    "$\\beta_t(q_i) = P(o_{t+1}, o_{t+2}, ... , o_{T}\\lvert h_t = q_i, \\lambda) $\n",
    "\n",
    "可以得出 $\\beta_t= [\\beta_t(q_1), \\beta_t(q_2),  ... , \\beta_t(q_N)] $，也是一个向量。\n",
    "\n",
    "$\\beta_T= [1, 1, ..., 1]^{'} $\n",
    "\n",
    "对于第一个问题，公式为：\n",
    "$\\beta_{t} = SUM(A * B[:, o_{t+1}] *  \\beta_{t+1}^{'} , axis=1)   $  \n",
    "$P(O \\lvert \\lambda) = \\sum  \\pi * B[:, o_{1}]^{'} * \\beta_{1}  $ \n",
    "\n",
    "对于第二个问题，公式为：\n",
    "$\\beta_{t} = MAX(A * B[:, o_{t+1}] *  \\beta_{t+1}^{'} , axis=1)  $\n",
    "\n",
    "\n",
    "\n",
    "$公式中{'}$表示转置。其中$A * B[:, o_{t+1}] *  \\beta_{t+1}$, 可以表示为下图：\n",
    "\n",
    "![hmm_backward](../../image/hmm_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结向前向后算法，我们可以得到。\n",
    "\n",
    "对于第一个问题，公式为\n",
    "\n",
    "$ P(O \\lvert \\lambda) = \\sum  \\alpha_{t} * A * B[:, o_{t+1}] *  \\beta_{t+1}^{'} $\n",
    "\n",
    "![hmm_backward](../../image/hmm_forward_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baum-Welch算法**\n",
    "\n",
    "本质上是EM算法。参考《统计学习方法》181-183页，其中Baum-Welch算法证明了一下公式的数学严谨性。平时我们直接使用下面公式计算便可。\n",
    "\n",
    "感觉计算起来还是有些复杂，以后找时间再做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baum_welch(output, df_pi, df_A, df_B, verbose=False): \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.19 sklearn.MultiLabelBinarizer\n",
    "\n",
    "多标签二元转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1]\n",
      " [0 0 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 0 0]]\n",
      "[[0. 0. 1. 1. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[2,3,4],[2],[0,1,3],[0,1,2,3,4],[0,1,2]]\n",
    "\n",
    "#以下两个公式等价\n",
    "print(MultiLabelBinarizer().fit_transform(y))\n",
    "print(np.vstack([ np.sum(np.eye(5)[labels], axis=0)  for labels in y]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.18 Accuracy, F1 score, Confusion Matrix, ROC,    Precision-Recall, Average Precision (AP) \n",
    "\n",
    "[Precision-Recall](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)  \n",
    "[sklearn.metrics.f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)  \n",
    "[sklearn.metrics.roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)  \n",
    "[模型评估：评价指标-附sklearn API](https://blog.csdn.net/shine19930820/article/details/78335550)  \n",
    "[sklearn中的模型评估](http://d0evi1.com/sklearn/model_evaluation/)\n",
    "\n",
    " \n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3, 1]\n",
    "y_true = [0, 1, 2, 3, 0]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score\n",
    "$P = \\frac{T_p}{T_p+F_p} \\ \\ $     $R = \\frac{T_p}{T_p + F_n}\\ \\ $  $F1 = 2\\frac{P \\times R}{P+R}\\ \\ $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666666\n",
      "0.5\n",
      "0.4666666666666666\n",
      "[1.  0.4 0. ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 1, 1]\n",
    "\n",
    "print(f1_score(y_true, y_pred, average='macro'))  \n",
    "print(f1_score(y_true, y_pred, average='micro'))  \n",
    "print(f1_score(y_true, y_pred, average='weighted'))  \n",
    "print(f1_score(y_true, y_pred, average=None))\n",
    "\n",
    "# print(np.eye(3)[y_true])\n",
    "# print(np.eye(3)[y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix(混淆矩阵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "\n",
    "ROC Curve = Receiver Operating Characteristic Curve  \n",
    "ROC AUC = ROC Area Under roc Curve \n",
    "\n",
    "ROC AUC: 计算ROC曲线的面积。实际中是计算一个又一个小的梯形面积，然后累加。\n",
    "\n",
    "下面还有自己实现的评估曲线对比(由于自己的计算结果和sklearn有一些小误差，所以改调用sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4,)\n",
      "[0 1]\n",
      "binary\n",
      "continuous\n",
      "sklearn auc:  0.75\n",
      "手工计算 auc:  0.75\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sklearn auc:  0.6001602564102564\n",
      "手工计算 auc:  0.6001602564102564\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from eipi10.ml2.predictor import *\n",
    "\n",
    "\n",
    "y_true = np.array([0, 0, 1, 1])\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_scores.shape)\n",
    "\n",
    "print(np.unique(y_true))\n",
    "print(type_of_target(y_true))\n",
    "print(type_of_target(y_scores))\n",
    "\n",
    "\n",
    "print('sklearn auc: ', roc_auc_score(y_true, y_scores))\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "print('手工计算 auc: ',np.trapz(tpr, fpr)) #手工计算auc\n",
    "\n",
    "print('-'*100)\n",
    "y_true = np.random.choice(2,  100)\n",
    "y_scores = [0.2 + random.random() if p==1 else random.random() - 0.2  for p in y_true]\n",
    "y_scores = np.array([random.random() if p>1 else (random.random() if p<0 else p)  for p in y_scores])\n",
    "print('sklearn auc: ', roc_auc_score(y_true, y_scores))\n",
    "# print('sklearn auc: ', auc(y_true, y_scores))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "print('手工计算 auc: ',np.trapz(tpr, fpr)) #手工计算auc\n",
    "\n",
    "\n",
    "\n",
    "curve = EvaluateCurve(y_true, y_scores)                    \n",
    "curve.plot_roc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XucTfX++PHXu5kiJQkpuYxxiTHdpxy5p1xC6aKjJDqDI4WfThfdRAe5lZDboIgiKSd9072klDQJuSRyD7nEoCQz3r8/1pppN83M3sNee83seT8fj/2w916fvT/vNTP2e6/PZ63PW1QVY4wxBuAUvwMwxhhTcFhSMMYYk8WSgjHGmCyWFIwxxmSxpGCMMSaLJQVjjDFZLCkYY4zJYknBmBCIyDQR+UNENvsdS2Hm/hyPiMh2v2MxObOkYIISkc3uf+TDIrLL/Y99ZrY2V4vIxyJySETSROQtEUnI1uYsEXlORLa67/Wj+7hsLv2KiPQWkVUi8quIbBeR10TkIi/3Nw/DVTUu+5PuzyNdRM7P4flB2Z6LExEVkdiA5+4QkVT3Z7JTRN4RkQb5DU5E+rq/n4Mi8oKIFMujbQkRGS8ie93f16KAbQNE5JgbT+YtPmB7W/d3clhEvgj8Pbu/s0Ei8pP7vgtFpE7mdlXtArTK776ZyLGkYELVVlXPBC4FLgMeydwgIvWA94E3gQpAVWAFsDjzw0RETgM+AuoALYGzgHrAPuCqXPocDfQBegPnADWB/wGt8xt84IdwOInIGcAtQBpw5wm8/n7gOWAIUB6oDIwHbszn+7QA+gHNgCpAPDAwj5ek4PxMa7v/9s22/VVVPTPgttHtpwbwMtADOBt4C5gf8PNtD/wLaOi+75fAjPzsi/GZqtrNbnnegM3AtQGPhwNvBzz+DBifw+veAV5y73cFfgbODLHPGkAGcFUebRYCXQMedwE+D3iswL3AemATMAEYme093gTud+9XAF4H9rjtewe0mwYMyiGGu4BtOMlrVbZtf3sNEOfGFQuUAg4D7cPwO3oFGBLwuBmwK5e2tYCDwFm5bB8AzMxl233ZfvenAEeAZu7jh4E5AdvrAL9ne48mwHa//67tlvPNjhRMvohIRZzD/w3u4xLA1cBrOTSfA1zn3r8WeFdVD4fYVTOcD46lJxcx7YC6QAIwC/iniAiAiJQGmgOzReQUnG+9K4AL3P7/n/sNPC+d3fedDdQSkSvyEVs9oDgwL7cG7tDSgTxuld2mddzYM60AyotImRze9ipgCzDQHT76TkRuydamrYj8IiKrReSe7GFluy9Aovt4NlBNRGqKyKk4P593c/8RmILGkoIJ1f9E5BDOt+LdwJPu8+fg/B3tzOE1O4HM+YIyubTJTX7b5+ZpVf1FVY/gHNEoztAGwK3Al6q6A7gSKKeqT6nqH+oMl0wGOuT2xu4HclPgFVX9GWd47K58xFYG2Kuq6bk1UNVXVPXsPG5b3aZn4gxhZcq8XzKHt62I8yGehnN0dB8wXURqu9vn4AwrlQO6Af1F5HZ324dAYxFp4g4JPgqcBpRwt+8EPgfW4RxBtOfvQ1OmALOkYELVTlVL4hz61+LPD/v9wHHg/Bxecz6w172/L5c2uclv+9xsy7yjztjFbCDzA+4OnPFxcMbhKwR+C8f5wCufx3t3Ataq6nL38cvAHe43ZIB04NRsrzkV5+d1HGcfy4ZpvuMwzjxNpsz7h3JoewQ4hjO09Yeqfgp8gnPUhKquUdUdqpqhql/gzO3c6m77Hufb//P8mfTXAJlnE/XHSbCVcI6CBgIfu0eUphCwpGDyxf0AmQaMdB//ijOZ2D6H5rfhfHsG5xtmC3diNhQfARVFJCmPNr/y5zdUgPNyCjnb41nArSJSBWdY6XX3+W3Apmzfwkuq6vV59H8XEO+e8bMLeBbnQzLzNVtx5hACVQW2qepxnJ/bUZwhrhyJSMdsZwFlv2UOH60GLgl46SXAz6q6L4e3XZnDc3mtoa8EDBmp6lxVTVTVMjhHjHHA1+7mS3EmqberarqqTgNK4wzfmcLA70kNuxX8G3+faC6H84F8ifu4gfu4N85wRWlgEHAAqOG2KYbzwfEuzpHGKTjDJ48C1+fS71icSeImOEMUxXGGc/q52wfjTDaXAKq7bbNPNFfP4X3XAh8A8wKeiwGW4UyUnu4+TgSudLdPI2DSGGc+IB24CCcZZd5eBl5329TB+Qbf3H2/CsAiYGjA+/wHZwK+nbsfp+LM2QzP5++oJbAL58P3bODjwH6ytT0VZ07oCZwJ7/o4RxS13O03ur9DwZl/+AnoHPD6K9z9KYcz1PRKwLYncYaPyru/407u38bZAW2aYBPNBfbmewB2K/i37EnBfW5C5oef+7iB+wF9GOfMlreBxGyvKYVz+uU2t92PON+uy+TSr+Cc1bMa+M39cHoVqONuL4tzKuwhYDHOWTOhJIUn3G3tsz1fAedIYhfOsNiSzP3OISlMDNz/gOevwvn2f477uC3wDc74/RZgBHB6ttd0BFLdD89d7s/u6hP4Pd3vJpiDwItAsYBtq4GOAY/r4Byp/Ioz/HNTwLZZOENbh4HvCTgLy93+ufsz/wWYBJwRsK04MA5naOkgTqJtme31lhQK8E3cX5IxJg8iMhlnLuJnVa3mdzyFlYhMxRlq3K2q1f2Ox/ydJQVjjDFZbKLZGGNMFksKxhhjsniyHoyXypYtq3FxcX6HYYwxhco333yzV1XLBWtX6JJCXFwcqampfodhjDGFiohsCaWdDR8ZY4zJYknBGGNMFksKxhhjslhSMMYYk8WSgjHGmCyeJQW3RuxuEVmVy3YRkTEiskFEVorI5V7FYowxJjReHilMw1m5MTetcEou1gC64yywZowxxkeeJQVVXYSzimJubsSp36uqugQ4W0TCUVTFGGOiyq+//srmzZsj0pefF69dQEBVLJzKTReQQwlGEemOczRB5cqVs282xhRRlwx8n7Qjx/wOw1NHtqzgl3fHckqxMziv8yi2DGvraX+F4opmVU0BUgCSkpJsWVdjDABpR46xeWhrv8PwxIEDB3jwwQeZMnsK1atXZ8qUKTRu3Njzfv1MCj/h1HHNVNF9zhhjirSMjAyuvvpq1q1bx0MPPcSAAQM4/fTTI9K3n0lhPnCfiMzGqZWbpqp/GzoyxpiiYt++fZxzzjnExMQwePBgKlWqRFJSXmXKw8+zpCAis3DK7pUVke04tVtPBVDVicACnALnG3BKLd7tVSzGmPArCOP5pU4/1df+w0VVefnll+nTpw9Dhw6lW7du3HTTTb7E4llSUNXbg2xX4F6v+jfGeCuax/Mjadu2bfTo0YMFCxbwj3/8g/r16/saj13RbIwxPpk1axZ16tRh4cKFPPfcc3z++eckJCT4GlOhOPvIGGOiUenSpalbty4pKSlUrVrV73AASwrGmDzkNW8QLeP5kZSens6oUaP4448/eOyxx2jZsiUtWrRARPwOLYslBWNMrmzeIHxWrFhBcnIy33zzDbfddhuqiogUqIQANqdgjDGeOnr0KE888QRJSUls27aN1157jdmzZxe4ZJDJkoIxxnho/fr1DBs2jDvuuIM1a9Zw6623FtiEADZ8ZIwxYXf48GHefPNNOnbsSGJiIt9//z3x8fF+hxUSO1Iwxpgw+uCDD7jooovo1KkTa9euBSg0CQEsKRhjTFjs37+f5ORkmjdvzmmnncann35K7dq1/Q4r32z4yBhjTlJGRgb169fnhx9+4JFHHqF///4UL17c77BOiCUFY4w5QXv37s1awG7IkCFUrlyZyy8v3JWFPR0+EpGWIrLOrcPcL4ftVUTkI7dG80IRqehlPMYYEw6qyksvvUTNmjWZMmUKAO3atSv0CQE8TAoiEgOMw6nFnADcLiLZF/UYiVOS82LgKeBpr+Ixxphw2LJlC61ataJz587Url2bRo0a+R1SWHl5pHAVsEFVN6rqH8BsnLrMgRKAj937n+Sw3RhjCoyZM2eSmJjI559/ztixY/nss8+oVauW32GFlZdJIbcazIFWADe7928CSopImexvJCLdRSRVRFL37NnjSbDGGBNMuXLlqF+/PqtXr+a+++7jlFOi7wROv/foAaCxiHwLNMYpx5mRvZGqpqhqkqomlStXLtIxGmOKqGPHjjF06FD++9//AtCiRQveeecdqlSp4nNk3vHy7KOgNZhVdQfukYKInAncoqoHPIzJGGNC8u2335KcnMy3335Lhw4dCuwCduHm5ZHC10ANEakqIqcBHXDqMmcRkbIikhnDI8ALHsZjjDFB/f777zz66KNceeWV7Nixg9dff51Zs2ZFfTLI5FlSUNV04D7gPWAtMEdVV4vIUyJyg9usCbBORH4AygODvYrHGGNCsWHDBkaOHMldd93F2rVrufnmm4O/KIp4evGaqi4AFmR7rn/A/bnAXC9jMMaYYA4fPsy8efPo1KkTiYmJrFu3rsBUQos0vyeajTHGV++99x516tShc+fOWQvYFdWEAJYUjDFF1L59++jcuTMtW7akRIkSfPbZZ4VyAbtws7WPjDFFTuYCdhs2bOCxxx7j8ccfL7QL2IWbJQVjTJGxZ88eypQpQ0xMDMOGDaNKlSpceumlfodVoNjwkTEm6qkqL774IjVr1mTy5MkA3HjjjZYQcmBJwRgT1TZv3kyLFi3417/+xUUXXUTTpk39DqlAs6RgjIlaM2bMIDExkS+//JLx48ezcOFCatas6XdYBZrNKRhjolb58uVp1KgREydOpHLlyn6HUyhYUjDGRI1jx44xfPhwMjIy6N+/P82bN6d58+Z+h1Wo2PCRMSYqLFu2jCuvvJLHH3+cdevWoap+h1QoWVIwxhRqR44coV+/flx11VX8/PPPzJs3j5dffrnILGAXbp4OH4lIS2A0EANMUdWh2bZXBqYDZ7tt+rnrJRljIuiSge+TduTY354vdfqpPkSTPxs3buTZZ5+lS5cujBgxgtKlS/sdUqHmWVIIqNF8HU7Vta9FZL6qrglo9jjO6qkT3PrNC4A4r2IyxuQs7cgxNg9t7XcYITt48CBvvPEGXbp0oU6dOqxfvz6qC99Ekt81mhU4y71fCtjhYTzGmCiwYMECEhMTSU5OzlrAzhJC+Phdo3kAcKeIbMc5SuiV0xtZjWZjzN69e+nUqROtW7emZMmSLF682Baw84Dfp6TeDkxT1WdEpB4wQ0QSVfV4YCNVTQFSAJKSkuyUAmNOQG7zBlDw5w4yF7DbuHEj/fv359FHH6VYsWJ+hxWVfK3RDCQDLQFU9UsRKQ6UBXZ7GJcxRVJhmzcA+PnnnylXrhwxMTGMHDmSKlWqcPHFF/sdVlTztUYzsBVoBiAitYHigI0PGVPEqSpTp07lwgsvJCUlBYC2bdtaQogAz44UVDVdRDJrNMcAL2TWaAZSVXU+8B9gsoj0xZl07qJ2xYkxJ6Uwn14Kzimm3bp14+OPP6Zx48Zce+21fodUpPhdo3kNUN/LGIwpagrjMFGm6dOn07NnT2JiYpg4cSLdunXjlFPsGttI8nui2RhjslSoUIFrrrmGCRMmULFiRb/DKZIsKRhjfPPHH38wdOhQjh8/zoABA7juuuu47rrr/A6rSLOkYEwBldcppHkpLHMHX3/9Nf/6179YtWoVnTp1QlVtvaICwJKCMQVUYZ4byMtvv/1G//79GTVqFOeffz7z58+nbdu2fodlXDaDY4yJqE2bNjF27Fi6devG6tWrLSEUMHakYEwEnMhQUGEZBgpFWloab7zxBnfffTd16tRhw4YNVKpUKfgLTcRZUjAmAqJ1KCgUb7/9Nv/+97/ZuXMn9erVo1atWpYQCjAbPjLGeGLPnj107NiRNm3aULp0ab788ktq1arld1gmCDtSMMaEXUZGBg0aNGDTpk0MHDiQfv36cdppp/kdlgmBJQVjTNjs2rWLc889l5iYGJ555hni4uJITEz0OyyTD54OH4lISxFZJyIbRKRfDttHichy9/aDiBzwMh5jjDeOHz/OpEmTqFmzJpMmTQKgTZs2lhAKIV/Lcapq34D2vYDLvIrHGOONDRs20K1bNxYuXMg111xDixYt/A7JnAS/y3EGuh2Y5WE8xpgwe/HFF7noootYtmwZkydP5sMPPyQ+Pt7vsMxJ8HJOIadynHVzaigiVYCqwMcexmPM35zoUhL5FU3XHASqXLkyLVq0YNy4cVxwQfZqu6YwKigTzR2AuaqakdNGEekOdAfnj9CYcCnK1w+ciKNHj/L0009z/PhxnnrqKZo1a0azZs38DsuEkZfDR6GU48zUgTyGjlQ1RVWTVDWpXLlyYQzRGBOqr776iiuuuIKBAweydetWrB5WdPK7HCciUgsoDXzpYSzGmBP066+/cv/991OvXj3S0tL4v//7P6ZNm2YrmkapoElBROqJyDgRWSkie0Rkq4gsEJF7RaRUbq9T1XQgsxznWmBOZjlOEbkhoGkHYLaV4TSmYNqyZQvjx4+nR48erF69mtatbbgtmuU5pyAi7wA7gDeBwcBuoDhQE2gKvCkiz7r1lv8mWDlO9/GAEw3eGOONAwcOMHfuXLp27UpCQgIbNmywSmhFRLCJ5k6qujfbc4eBZe7tGREp60lkxhhfvPnmm9xzzz3s3r2bBg0aUKtWLUsIRUiew0c5JAQAROQUEemYVxtjTOGye/duOnToQLt27ShXrhxLliyxBeyKoDyTgoicJSKPiMjzItJcHL2AjcBtkQnRGOO1jIwM6tevz7x58xg0aBCpqakkJSX5HZbxQbDhoxnAfpwzg7oCjwICtFPV5R7HZozx2I4dOzjvvPOIiYlh9OjRxMXFkZCQ4HdYxkfBzj6KV9UuqjoJZxmKBKCFJQRjCrfjx48zYcIEatWqxcSJEwG4/vrrLSGYoEkh6/p/92rj7ar6u7chGWO89MMPP9C0aVN69uxJ3bp1adWqld8hmQIk2PDRJSJyEGfICOD0gMeqqmd5Gp0xJqymTp3KfffdR/HixXnhhRfo0qWLXYRm/iLPpKCqMZEKxBjjvbi4OFq1asW4ceM4//zz/Q7HFEDBLl4rDvQAqgMrgRfcK5WNMYXA0aNH+e9//wvAoEGDbAE7E1SwOYXpQBLwHXA98IznERljwuKLL77g0ksvZfDgwezcudMWsDMhCZYUElT1Tvfso1uBhhGIyRhzEg4fPkyfPn1o0KABv/32G++++y5Tp061uQMTkvycfZTvYaNgNZrdNreJyBoRWS0ir+S3D2PMX23dupVJkyZx7733smrVKiuPafIl1LOPwDnjKOSzj0Kp0SwiNYBHgPqqul9Ezj2JfTGmyNq/fz+vvfYa3bt3JyEhgY0bN1KhQgW/wzKFULAjheKqepZ7K6mqsQH3g52OGkqN5m7AOFXdD6Cqu09oL4wpwubNm0dCQgI9e/Zk3bp1AJYQzAkLlhS+Oon3zqlGc/YirjWBmiKyWESWiEjLnN5IRLqLSKqIpO7Zs+ckQjImeuzatYv27dtz8803c95557F06VIuvPBCv8MyhVyw4SOvZ6ZigRpAE5xynYtE5CJVPRDYSFVTgBSApKQkO4XCFHkZGRk0bNiQbdu2MWTIEB544AFOPfVUv8MyUSBYUignIvfntlFVn83jtaHUaN4OfKWqx4BNIvIDTpL4OkhcxhRJ27dvp0KFCsTExDBmzBiqVq1qy1ubsAo2fBQDnAmUzOWWl1BqNP8P5ygBt1hPTZxluY0xAY4fP87YsWOpVasWEyZMAKBVq1aWEEzYBTtS2KmqT53IG6tquohk1miOwbkaerWIPAWkuiU83wOai8gaIAN4UFX3nUh/xkSr77//nq5du7J48WJatGhBmzZt/A7JRDFP5xSC1WhW5xLL+92bMUFdMvB90o4cC94wRKVOL9jj8FOmTOG+++6jRIkSTJ8+nU6dOtlFaMZTwZLCDcHeQETOVNXDYYrHmDylHTnG5qGt/Q4jYqpVq0bbtm15/vnnKV++vN/hmCIgWFKYJiLLgTeBb1T1VwARiQea4pTknAzM9TRKY4qI33//naeeckZshwwZQtOmTWnatKnPUZmiJM+JZlVtBnwE/BtYLSJpIrIPmAmcB3RWVUsIxoTB4sWLufTSS3n66afZs2ePLWBnfBHsSCHHeQFjvJTXvEFBnwM4EYcOHeLRRx9l3LhxVKlShffee4/mzZv7HZYpooImBQAReR2YCryrqse9DckUdUVt3mD79u1MmTKFXr16MXjwYM4880y/QzJFWLDrFDJNADoC60VkqIjYtfTGnIR9+/ZlXW9Qu3ZtNm7cyOjRoy0hGN+FlBRU9UNV7QhcDmwGPhSRL0TkbhGJvuN5YzyiqsydO5eEhAR69+6dtYCdlcY0BUWoRwqISBmgC9AV+BYYjZMkPvAkMmOizM6dO7nlllto3749lSpVIjU11RawMwVOqHMK84ALgRlAW1Xd6W56VURSvQrOmGiRuYDdTz/9xPDhw+nbty+xsSH99zMmokL9q5zsnoWURUSKqepRVU3yIC5josK2bdu44IILiImJYdy4cVStWpWaNWv6HZYxuQp1+GhQDs99Gc5AjIkmGRkZjBkz5i8L2LVo0cISginw8kwKInKeiFyBU4bzMhG53L01AUoEe/NgNZpFpIuI7BGR5e6t6wnviTEFxNq1a2nYsCF9+vShcePGtG3b1u+QjAlZsOGjFjiTyxWBwNoJh4BH83phKDWaXa+q6n35CdqYgiolJYVevXpRsmRJZsyYQceOHW0BO1Oo5JkUVHU6MF1EblHV1/P53lk1mgFEJLNGc/akYEzUqFGjBjfddBNjxozh3HPP9TscY/Itz6QgIneq6kwgLqcKbEEqr+VUo7luDu1uEZFGwA9AX1Xdlr2BiHQHugNUrlw5r5CNiagjR44wYMAARIShQ4faAnam0As20XyG+29u1ddO1ltAnKpejHO9w/ScGqlqiqomqWpSuXLlwtCtMSdv0aJFXHLJJQwfPpy0tDRbwM5EhWDDR5Pcu+NVdU8+3ztojeZsVdamAMPz2YcxEXfw4EH69evHhAkTiI+P56OPPuKaa67xOyxjwiLUU1IXi8j7IpIsIqVDfE3QGs0iEnht/w3A2hDf2xjf7Nixg2nTpnH//fezcuVKSwgmqoR08Zqq1hSRq3A+2B9zayrPducbcntNKDWae4vIDUA68AvOmU6miMhtieyCuDz23r17mTNnDj179qRWrVps2rTJKqGZqCT5HQcVkbI4p6d2VNUYT6LKQ1JSkqam2soa0SCu39sFfolsVWXOnDn06tWLAwcOsGrVKrsAzRRKIvJNKCtQhDR8JCJniUhnEXkH+ALYiXPKqTFRa8eOHbRr144OHTpQpUoVvvnmG0sIJuqFuvbRCuB/wFOqastbmKiXkZFBo0aN+Omnnxg5ciR9+vSxBexMkRDqX3m82vl2pgjYsmULFStWJCYmhvHjxxMfH0/16tX9DsuYiAm29tFz7t35IvK3WwTiMyYiMjIyePbZZ6ldu3bWAnbNmze3hGCKnGBHCjPcf0d6HYgxflm1ahXJycksXbqUNm3a0K5dO79DMsY3wS5e+8a9e6mqjg7cJiJ9gE+9CsxEh9xOO4WCcerpxIkT6d27N6VKleKVV16hQ4cOtoCdKdJCnVPojFN+M1CXHJ4z5i/SjhwrkKedqioiQu3atWnfvj3PPfcctoSKMcEXxLsduAOomm0OoSTOxWbGFCq//fYb/fv3JyYmhmHDhtG4cWMaN27sd1jGFBjBjhQyr0koCzwT8PwhYKVXQRnjhYULF9K1a1d+/PFHevbsmXW0YIz5U7A5hS3AFqBeZMIxJvzS0tJ46KGHSElJoVq1anz88ce2vLUxuQh2Surn7r+HRORgwO2QiByMTIjGnJydO3cyc+ZMHnjgAVauXGkJwZg85JkUVLWB+29JVT0r4FZSVc8K9ubBajQHtLtFRFREgq7LYUwo9uzZw9ixYwGoVasWmzdvZsSIEZQoEbS0uDFFWkhnH4lINWC7qh4VkSbAxcBLqnogj9eEVKNZREoCfYCvTmwXjN8K0mmnqsqsWbPo3bs3Bw8epEWLFtSsWdPOLDImRKGekvo6kCQi1YEU4E3gFeD6PF4Tao3m/wLDgAfzEbcpQArKaafbtm3jnnvu4e2336Zu3bpMnTrVFrAzJp9CLbJzXFXTgZuAsar6IHB+kNfkVKP5gsAGInI5UElV387rjUSku4ikikjqnj35LQBnioL09HSaNGnCJ598wqhRo1i8eDF16tTxOyxjCp1QjxSOudcsdAbaus+d1LiAiJyCU5ehS7C2qpqCc4RCUlKSLcxnsmzevJlKlSoRGxvLpEmTiI+PJz4+3u+wjCm0Qj1SuBvntNTBqrpJRKry57pIuQlWo7kkkAgsFJHNwD9wFt6zyWYTVHp6OiNHjqR27dqMHz8egGuvvdYSgjEnKdRynGuA3gGPN+HMA+Qlq0YzTjLogHN1dOZ7pOFcFAeAiCwEHlBVK6tm8rRy5UqSk5NJTU3lxhtv5JZbbvE7JGOiRqiV1+qLyAci8oOIbBSRTSKyMa/XuHMQmTWa1wJzMms0u3WZjcm38ePHc8UVV7BlyxZeffVV5s2bR4UKFfwOy5ioEeqcwlSgL/ANkBHqm6vqAmBBtuf659K2Sajva4qezCUpEhMT6dChA6NGjaJs2bLBX2iMyZdQk0Kaqr7jaSSmwMvtegQvr0X49ddfefzxx4mNjWXEiBE0atSIRo0aedafMUVdqEnhExEZAbwBHM18UlWXeRKVKZAifT3CRx99RLdu3di0aRO9evWyBeyMiYBQk0Jd99/AM4MUuCa84RgDBw4c4IEHHmDq1KnUqFGDRYsW0bBhQ7/DMqZICPXsI1tBrIgoCEtW/Pzzz8yePZuHH36YJ598ktNPPz0i/RpjQl/7qDwwBKigqq1EJAGop6pTPY3ORJxfS1ZkJoI+ffpw4YUXsnnzZptINsYHoV68Ng3n1NLMc/9+AP6fFwGZokVVmTlzJgkJCTz00EOsX78ewBKCMT4JNSmUVdU5wHHIugYh5FNTjcnJ1q1bad26NZ06deLCCy9k+fLl1KhRw++wjCnSQp1o/lVEyuBMLiMi/wCQU7LUAAAT1UlEQVTSPIvKeKogzBtkLmC3e/duxowZQ8+ePYmJiYlI38aY3IWaFO4H5gPVRGQxUA641bOojKf8XOp648aNVKlShdjYWCZPnky1atWIi4vzJRZjzN8FK8d5pYic516P0Bh4FOc6hfdxlsI2JiTp6ekMGzaMhIQExo0bB0CzZs0sIRhTwASbU5gE/OHevxp4DKea2n7cpazzEqwcp4j0EJHvRGS5iHzuntVkoszy5cupW7cu/fr14/rrr6d9+/Z+h2SMyUWw4aMYVf3Fvf9PIEVVXwdeF5Hleb0wxHKcr6jqRLf9DTj1FVqewH6YHPixLEV2zz//PH379qVMmTLMnTvXVjQ1poALmhREJNY926gZ0D0frw1ajlNVDwa0PwN3ItuEh59zB5lLUlx88cV07NiRZ599lnPOOceXWIwxoQv2wT4L+FRE9gJHgM8A3FrNwc4+yqkcZ93sjUTkXpyJ7NOwZTMKvcOHD/PYY49x6qmnMnLkSFvAzphCJs85BVUdDPwH5+K1Bqqa+U3+FKBXOAJQ1XGqWg14GHg8pzZWo7lweP/990lMTGTs2LEcO3aMP/9cjDGFRdCL11R1iarOU9VfA577IYQVUoOV48xuNtAulxhSVDVJVZPKlSsXLGQTYfv37+fuu++mRYsWFC9enEWLFjF69Ghb0dSYQijUK5pPRFY5ThE5Dacc5/zABiISePlqa2C9h/EYj+zevZu5c+fyyCOPsHz5cho0aOB3SMaYExTqxWv5pqrpIpJZjjMGeCGzHCeQqqrzgftE5FrgGM5prp29iseE165du5g1axZ9+/bNWsCuTJkyfodljDlJniUFCF6OU1X7eNm/CT9V5aWXXqJv37789ttvtGnThho1alhCMCZKeDl8ZKLM5s2badmyJV26dCEhIcEWsDMmCnl6pGCiR3p6Ok2bNmXv3r2MGzeOHj16cMop9p3CmGhjScHkacOGDVStWpXY2FheeOEF4uPjqVKlit9hGWM8YkkhBHktNV2QncxyFseOHWPEiBEMHDiQESNG0Lt3b5o2taqsxkQ7Swoh8HO5CD8sW7aM5ORkli9fTvv27fnnP//pd0jGmAixQWHzF2PGjOGqq65i165dvPHGG8yZM4fy5cv7HZYxJkKK1JHCiQ4DRXJVUb9kLmB32WWXcdddd/HMM89QunRpv8MyxkRYkUoKRW0YKBSHDh3ikUceoVixYjzzzDM0bNiQhg0b+h2WMcYnNnxUhL377rskJiYyfvx4VNUWsDPGWFIoivbt20fnzp1p1aoVZ5xxBosXL+bZZ5+1BeyMMZYUiqJ9+/Yxb948nnjiCb799lvq1avnd0jGmALC06QQQo3m+0VkjYisFJGPRMSuivLIzp07GTlyJKpKzZo12bJlC0899RTFihXzOzRjTAHiWVIIqNHcCkgAbheRhGzNvgWSVPViYC4w3Kt4iipV5YUXXqB27do88cQTbNiwAcDOLDLG5MjLI4WsGs2q+gdOEZ0bAxuo6ieq+pv7cAlOIR4TJps2baJ58+YkJydzySWXsGLFClvAzhiTJy9PSQ2pRnOAZOCdnDaISHegO0DlypXDFV9US09P55prrmHfvn1MmDCB7t272wJ2xpigCsR1CiJyJ5AENM5pu6qmACkASUlJdt5kHtavX098fDyxsbG8+OKLVKtWjUqVKgV/oTHG4O3wUUg1mt3Ka48BN6jqUQ/jiWrHjh1j0KBBJCYm8vzzzwPQpEkTSwjGmHzx8kghq0YzTjLoANwR2EBELgMmAS1VdbeHsUS11NRUkpOTWblyJR06dOD222/3OyRjTCHl2ZGCqqYDmTWa1wJzMms0i8gNbrMRwJnAayKyXETmexVPtBo9ejR169Zl7969vPnmm8yaNYtzzz3X77CMMYWU3zWar/Wy/2iWuYBdUlISycnJDB8+nLPPPtvvsIwxhVyBmGg2oTt48CAPP/wwxYsXZ9SoUdSvX5/69ev7HZYxJkrYOYqFyIIFC6hTpw4pKSnExsbaAnbGmLCzpFAI7N27lzvvvJPWrVtTqlQpvvjiC0aMGGEL2Bljws6SQiGwf/9+3nrrLZ588kmWLVtG3bp5XQNojDEnzuYUCqiffvqJl19+mQcffJAaNWqwZcsWm0g2xnjOjhQKGFVl8uTJJCQkMGDAAH788UcASwjGmIiwpFCA/PjjjzRr1ozu3btz+eWXs3LlSqpXr+53WMaYIsSGjwqI9PR0mjVrxi+//MKkSZPo2rWrLWBnjIk4Swo+W7duHdWqVSM2Npbp06dTrVo1Kla0FcSNMf6wr6I++eOPPxg4cCAXXXQR48aNA6Bx48aWEIwxvrIjBR8sXbqU5ORkVq1axR133EHHjh39DskYYwD/azQ3EpFlIpIuIrd6GUtB8dxzz1GvXr2saw9efvllypYt63dYxhgD+F+jeSvQBXjFqzgKiswlKa666iq6devG6tWradOmjc9RGWPMX3k5fJRVoxlARDJrNK/JbKCqm91txz2Mw1dpaWk89NBDnH766Tz33HNcffXVXH311X6HZYwxOfJy+CinGs0XnMgbiUh3EUkVkdQ9e/aEJbhIeOutt0hISGDKlCkUK1bMFrAzxhR4heLsI1VNUdUkVU0qV66c3+EEtWfPHu644w5uuOEGypQpw5IlSxg2bJgtYGeMKfB8r9EcjdLS0liwYAEDBw4kNTWVK6+80u+QjDEmJL7WaI4m27ZtY+bMmfTr14/q1auzZcsWSpUq5XdYxhiTL77WaBaRK0VkO9AemCQiq72KxyvHjx9n4sSJ1KlTh0GDBmUtYGcJwRhTGPldo/lrnGGlQmn9+vV069aNTz/9lGbNmpGSkkJ8fLzfYRljzAmzK5pPUHp6Otdddx0HDhxg6tSp3H333TaRbIwp9Cwp5NPatWupUaMGsbGxzJgxg2rVqlGhQgW/wzLGmLAoFKekFgRHjx7lySef5OKLL+b5558HoGHDhpYQjDFRxY4UQrBkyRKSk5NZs2YNnTp1olOnTn6HZIwxnrAjhSCeeeYZrr76ag4dOsSCBQt46aWXKFOmjN9hGWOMJywp5OL4cWc5pnr16tGjRw9WrVpFq1atfI7KGGO8ZcNH2Rw4cID//Oc/lChRgrFjx9oCdsaYIsWOFAL873//IyEhgenTp1OyZElbwM4YU+RYUgB2797Nbbfdxk033UT58uVZunQpQ4YMsesOjDFFjiUF4ODBg3zwwQcMHjyYpUuXcvnll/sdkjHG+KLIzils3bqVGTNm8Oijj1K9enW2bt1KyZIl/Q7LGGN85XeN5mIi8qq7/SsRifMyns1DW3P8+HHGjx9PnTp1GDJkSNYCdpYQjDHG/xrNycB+Va0OjAKGeRUPwLp162jSpAn33nsv9erVY/Xq1VSvXt3LLo0xplDx8kghq0azqv4BZNZoDnQjMN29PxdoJh7N7qanp9OiRQu+++47XnzxRd577z3i4uK86MoYYwotL+cUcqrRXDe3NqqaLiJpQBlgb2AjEekOdAeoXLnyCQUTGxvLzJkzqVatGueff/4JvYcxxkS7QnH2UbhqNDdo0MASgjHG5MHvGs1ZbUQkFigF7PMwJmOMMXnwMilk1WgWkdNwajTPz9ZmPtDZvX8r8LHaZcTGGOMbz+YU3DmCzBrNMcALmTWagVRVnQ9MBWaIyAbgF5zEYYwxxid+12j+HWjvZQzGGGNCVygmmo0xxkSGJQVjjDFZLCkYY4zJYknBGGNMFilsZ4CKyB5gywm+vCzZrpaOIL/6tn2O/n797Nv2ufD0XUVVg179W+iSwskQkVRVTSpKfds+R3+/fvZt+xx9fdvwkTHGmCyWFIwxxmQpakkhpQj2bfsc/f362bftc5T1XaTmFIwxxuStqB0pGGOMyYMlBWOMMVmiMimISEsRWSciG0SkXw7bi4nIq+72r0QkLkL9NhKRZSKSLiK3hqPPfPR9v4isEZGVIvKRiFSJUL89ROQ7EVkuIp/nUKfbs74D2t0iIioiYTmVL4R97iIie9x9Xi4iXcPRbyh9u21uc3/Xq0XklUj0KyKjAvb3BxE5EI5+Q+y7soh8IiLfun/f10eo3yru/6WVIrJQRCqGqd8XRGS3iKzKZbuIyBg3rpUicnk4+s2iqlF1w1mm+0cgHjgNWAEkZGvTE5jo3u8AvBqhfuOAi4GXgFsjvM9NgRLu/XsiuM9nBdy/AXg3UvvstisJLAKWAEkR2ucuwPM+/W3XAL4FSruPz43UzzqgfS+cpfIjtc8pwD3u/QRgc4T6fQ3o7N6/BpgRpn1uBFwOrMpl+/XAO4AA/wC+CuffWTQeKVwFbFDVjar6BzAbuDFbmxuB6e79uUAzERGv+1XVzaq6Ejh+kn2dSN+fqOpv7sMlOJXwItHvwYCHZwDhOrMhlN8zwH+BYcDvEe7XC6H03Q0Yp6r7AVR1d4T6DXQ7MCsM/YbatwJnufdLATsi1G8C8LF7/5Mctp8QVV2EU18mNzcCL6ljCXC2iIStznA0JoULgG0Bj7e7z+XYRlXTgTSgTAT69Up++07G+aYRkX5F5F4R+REYDvQOQ78h9e0eVldS1bfD1GdI/bpucQ/t54pIpRy2e9V3TaCmiCwWkSUi0jJC/QLOkApQlT8/LCPR9wDgThHZjlO/pVeE+l0B3OzevwkoKSIn+zkSrthOWDQmBZMHEbkTSAJGRKpPVR2nqtWAh4HHI9GniJwCPAv8JxL9ZfMWEKeqFwMf8OdRaSTE4gwhNcH5xj5ZRM6OYP8dgLmqmhHBPm8HpqlqRZyhlRnu799rDwCNReRboDFOzflI7rcnojEp/AQEfjOr6D6XYxsRicU55NwXgX69ElLfInIt8Bhwg6oejVS/AWYD7cLQbyh9lwQSgYUishln7HV+GCabg+6zqu4L+PlOAa44yT5D7hvnW+N8VT2mqpuAH3CShNf9ZupA+IaOQu07GZgDoKpfAsVxFo7ztF9V3aGqN6vqZTj/r1DVsE2wn0xsJyWcExQF4YbzTWkjziFs5gRRnWxt7uWvE81zItFvQNtphHeiOZR9vgxn4qxGhPutEXC/LU597oj0na39QsIz0RzKPp8fcP8mYEkEf94tgenu/bI4wwxlIvGzBmoBm3Evio3gPr8DdHHv18aZUzipGELstyxwint/MPBUGPc7jtwnmlvz14nmpeHqV1WjLym4P7Trcb4h/Qg85j73FM43ZHC+SbwGbACWAvER6vdKnG9yv+IcmayO4D5/CPwMLHdv8yPU72hgtdvnJzl9mHjVd7a2CwlDUghxn59293mFu8+1Ivh7FpxhszXAd0CHSP2sccb2h4ZrX/OxzwnAYvfnvRxoHqF+bwXWu22mAMXC1O8sYCdwzP28SAZ6AD0Cfsfj3Li+C9ffdebNlrkwxhiTJRrnFIwxxpwgSwrGGGOyWFIwxhiTxZKCMcaYLJYUjDHGZLGkYAq8YKtGum0ec1cFXemu1Fk3zDEsyLwyWER6i8haEXlZRG7Ia4VWt/0X7r9xInJHiP21E5H+7v0BIvJTwCqkQ93nF7qreK5wl7W4MIfnvxaRSwPe90MRKX1iPwVTFNgpqabAE5FGwGGcRcASc9heD+fc/CaqelREygKnqWo4FkbLKZ7vgWtVdXs+X9cEeEBV24TQ9guc8+H3isgA4LCqjszWZqH7fqki0h1oo6o3ZHv+buAOVb3OfU1noKKqDs5P7KbosCMFU+Bp8FUjzwf2qru0hKruzUwIIrJZRIaLU9NhqYhUd58vJyKvu9+kvxaR+u7zZ4rIi277lSJyS8D7lBWRiTjLKb8jIn3FqZ3wvNumvIjMc7+hrxCRq93nD7txDgUaut/2+4rIomzf4j8XkUtEpCZwVFX35uPHtAionsPzX/LXxdLm46wVZEyOLCmYaPA+UEmc4i7jRaRxtu1pqnoR8DzwnPvcaGCUql4J3IJzRSrAE5nt1VnQ7i+rfapqD5xlFJqq6qhs/YwBPlXVS3DWw1+dbXs/4DNVvdR97VSc2gu4iaC4qq4A6gPLsr22b8DwUYscfgZtca5uza4l8L+A+PcDxSK0mqcphGL9DsCYk6Wqh0XkCqAhTjGhV0Wkn6pOc5vMCvg384P8WiAhoIzGWSJypvt8h4D33p+PUK4B7nJfl4GzJHteXgOeEJEHgX/hrIkFzpHPnmxtR2UfPnK9LCJHcNYc6pXt+dOAM4FLs71mN1CBk18E0kQhSwqm0HHrE7zlPpyoqhPdD+GFOKuifgd05s8P2cCJs8z7pwD/UNW/FN85+VpLoVPV30TkA5yiKbfx52qqR3BW7g1FR1VNzel54BucJdLH8ue6/+Cs/XXkhII2Uc+Gj0yho6rb3CGYS1V1oohcKCKBy0NfCmwJePzPgH+/dO+/T8A364Cx/Q9wVtHNfD4/Z+p8hFPqFBGJEZHsH+yHcJb0DjQFZ9jp64CjkrXkPD+QL+qcRfIE8A8RqeXGJcB5OEcWxvyNJQVT4InILJwP8wtFZLuIJGdrciYwXZxi9StxVs0cELC9tPt8H6Cv+1xvIMmdTF6DswolwCC3/SoRWYEzHBWqPkBT90jlGzeOQCuBDHcSui+Aqn4DHAReDGi3CLhMwnDYoqpHgGeAB92nrsBZyjv9ZN/bRCc7JdVENXEK7CTl80yeiBGRCjjDXrVU9XjA86OBt1T1wzD3Nxpn2fSPwvm+JnrYkYIxPhGRu4CvcNbqP55t8xCghAfdrrKEYPJiRwrGGGOy2JGCMcaYLJYUjDHGZLGkYIwxJoslBWOMMVksKRhjjMny/wHCN9FALrJ+GgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "%matplotlib inline\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "roc_auc = auc(fpr, tpr)   #计算auc\n",
    "#画图，只需要plt.plot(fpr,tpr),变量roc_auc只是记录auc的值，通过auc()函数能计算出来  \n",
    "plt.plot(fpr, tpr, lw=1, label='ROC(area = %0.2f)' % (roc_auc))\n",
    "plt.xlabel(\"FPR (False Positive Rate)\")\n",
    "plt.ylabel(\"TPR (True Positive Rate)\")\n",
    "plt.title(\"Receiver Operating Characteristic, ROC(AUC = %0.4f)\"% (roc_auc))\n",
    "plt.show()\n",
    "\n",
    "curve = EvaluateCurve(y_true, y_scores)                    \n",
    "curve.plot_roc()\n",
    "\n",
    "print(len(y_scores))\n",
    "print(len(fpr))\n",
    "print(len(thresholds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test = np.random.choice(2,  20)\n",
    "y_score = [0.25 + random.random() if p==1 else random.random() - 0.25  for p in y_test]\n",
    "y_score = np.array([random.random() if p>1 else (random.random() if p<0 else p)  for p in y_score])\n",
    "\n",
    "print(y_score.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.show() \n",
    "\n",
    "curve = EvaluateCurve(y_test, y_score)                    \n",
    "curve.plot_pr()\n",
    "\n",
    "print(len(thresholds))\n",
    "print(len(pr_thresholds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Precision (AP) \n",
    "$\\text{AP} = \\sum_n (R_n - R_{n-1}) P_n$  \n",
    "where $P_n$ and $R_n$ are the precision and recall at the nth threshold. \n",
    "\n",
    "AP：其实也相当于上面曲线的面积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.56\n",
      "0.5298443568051411\n",
      "0.5589357628573315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "precision, recall = precision[::-1], recall[::-1]\n",
    "\n",
    "print(np.trapz(precision, recall)) #手工计算auc\n",
    "\n",
    "l = len(precision)\n",
    "print(np.sum((recall[i+1]-recall[i])*precision[i+1] for i in range(l-1)))#手工计算auc 上面梯形计算面积的方法有些偏小，但大致的方向是一致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**自己实现的评估曲线**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.17 BM25\n",
    "\n",
    "Okapi BM25 是搜索引擎用来对匹配文档进行排序的函数，依据是每个文档与搜索词的相关度。BM 是 Best Matching (最佳匹配) 的缩写。这个方法是上世纪七八十年代在概率搜索的框架下被提出的。Okapi 是第一个使用这种方法的信息获取系统的名称。\n",
    "\n",
    "BM25 是基于词频的方法；也就是说，它不考虑多个搜索词在文档里是不是靠近，只考虑它们各自的出现次数。BM25 不是单个函数：许多函数都可以叫 BM25，彼此之间有些形式和参数个数的差异。最常用的形式之一是\n",
    "\n",
    "$\\text{score}(D,Q) = \\sum_{i=1}^n\\text{IDF}(q_i)\\cdot\\left[\\frac{f(q_i,D)\\cdot\\left(k_1+1\\right)}{f(q_i,D) + k_1\\cdot\\left(1-b+b\\cdot\\frac{|D|}{\\text{avgdl}}\\right)}\\right],$\n",
    "\n",
    "其中各符号含义如下：\n",
    "\n",
    "D: 文档  \n",
    "Q: 搜索词 (多个)  \n",
    "f(qi,D): qi 这个词在文档 D 中的出现次数  \n",
    "|D|: D 的单词数  \n",
    "avgdl: 整个文档库中文档的平均长度  \n",
    "k1, b: 自由参数，一般取值范围是 k1∈[1.2,2.0], b=0.75  \n",
    "IDF(qi): inverse document frequency，通常由下述公式计算  \n",
    "\n",
    "$\\text{IDF}(q_i) = \\log\\left(\\frac{N-n(q_i)+0.5}{n(q_i) + 0.5}\\right),$\n",
    "\n",
    "这里 N 是文档库里总的文档数，n(qi) 是包含单词 qi 的文档个数。一个单词的 IDF 大，意味着这个单词只在较少文档中出现，也就意味着这个单词比较独特。\n",
    "这里 IDF 的定义有个问题，那就是，如果一个词在超过半数的文档里出现，则其 IDF 是负数，于是这个词对 BM25 分数的贡献是负的。一般不希望这样的特性，所以当 IDF 为负数时可强行改为 0，或者一个比较小的正数，或者改用一种平滑过渡到 0 的函数形式。\n",
    "\n",
    "[Okapi BM25, TF-IDF, 以及 ElasticSearch/Lucene 搜索结果的分数](http://fjdu.github.io/coding/2017/03/16/bm25-elasticsearch-lucene.html)  \n",
    "[文本相似度-bm25算法原理及实现](https://www.jianshu.com/p/1e498888f505): 里面有代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.16 限定GPU内存的使用\n",
    "\n",
    "####  Tensorflow\n",
    "\n",
    "默认情况下，一个session会分配所有的GPU内存\n",
    "\n",
    "**自动增加**  \n",
    "```python\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "session = tf.Session(config=config)  \n",
    "```\n",
    "\n",
    "**固定分配**  \n",
    "```\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4  \n",
    "session = tf.Session(config=config) \n",
    "```\n",
    "\n",
    "如果是使用keras, 以下脚本。\n",
    "```\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "```\n",
    "---------------------\n",
    "\n",
    "本文来自 悟乙己 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/sinat_26917383/article/details/75633754?utm_source=copy \n",
    "\n",
    "#### PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.15 NLP平滑方法 \n",
    "**历史**  \n",
    "- 2018-06-17 Additive smoothing  \n",
    "- 2018-07-17 Good-Turing estimate\n",
    "- 2018-07-18 Kneser-Ney smoothing 总体看懂了，但细节之处，的确复杂。\n",
    "\n",
    "总体上采用深度学习的方法比平滑方法的效果好的多。但这项技术还是必须要有所了解。\n",
    "\n",
    "为了处理NLP建模过程中的稀疏性（Sparsity）问题，需要进行平滑化。而平滑方法可以分为三个大类：\n",
    "    \n",
    "- Add-One Smoothing（Laplacian Smoothing）\n",
    "- Additive smoothing\n",
    "- Good-Turing estimate（图灵平滑）\n",
    "- Jelinek-Mercer smoothing (interpolation)\n",
    "- Katz smoothing (backoff)\n",
    "- Witten-Bell smoothing\n",
    "- Absolute discounting\n",
    "- Kneser-Ney smoothing(Strong Baseline Method基准方法)\n",
    "    \n",
    "    \n",
    "**参考 **\n",
    "- [自然语言处理中N-Gram模型的Smoothing算法](https://blog.csdn.net/baimafujinji/article/details/51297802): 高手的blog，对Kneser-Ney Smoothing等做了详细描述\n",
    "- [Language Modeling with Smoothing](https://cocoxu.github.io/courses/5525_slides_spring17/10_advanced_smoothing.pdf): 这篇文章中比较了各个平滑方法（非常好），作者的观点如下。\n",
    "    - Add-1 estimation is a blunt instrument \n",
    "        - So add-1 isn’t used for N-grams:\n",
    "            -We’ll see better methods\n",
    "        - But add-1 is used to smooth other NLP models\n",
    "            - For text classification\n",
    "            - In domains where the number of zeros isn’t so huge.    \n",
    "    - Backoff:\n",
    "        - use trigram if you have good evidence,\n",
    "        - otherwise bigram, otherwise unigram\n",
    "    - Interpolation:\n",
    "        - mix unigram, bigram, trigram\n",
    "        - Interpolation works better\n",
    "        \n",
    "- [NLP Lunch Tutorial: Smoothing](https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf)  \n",
    "- NLP 笔记 - 平滑方法(Smoothing)小结  http://www.shuang0420.com/2017/03/24/NLP%20%E7%AC%94%E8%AE%B0%20-%20%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95(Smoothing)%E5%B0%8F%E7%BB%93/\n",
    "\n",
    "**Add-One Smoothing ** \n",
    "\n",
    "比较简单，但总效果比较差的方法。\n",
    "\n",
    "下面以bigram model为例说明\n",
    "\n",
    "**  MLE **  \n",
    "\n",
    "$ \\begin{align} \n",
    "P_{MLE}\\ (w_i|w_{i-1}) = \\frac {c(w_{i-1} w_i)} {c(w_{i-1})}\n",
    "\\end{align}$\n",
    "\n",
    "** Add-1 MLE **  \n",
    "\n",
    "$ \\begin{align} \n",
    "P_{MLE}\\ (w_i|w_{i-1}) = \\frac {c(w_{i-1} w_i) + 1} {c(w_{i-1}) + V}  \\end{align} \\\\ \n",
    "V = \\{w:c(w)>0\\} \\cup \\{UNK\\}   \n",
    "$\n",
    "\n",
    "V其实就是training中所有unique unigram的个数+1( V is the number of unique unigrams in the train corpus plus 1)\n",
    "\n",
    "\n",
    "举个例子，假设语料库为下面三个句子\n",
    "\n",
    "```\n",
    "JOHN READ MOBY DICK\n",
    "MARY READ A DIFFERENT BOOK\n",
    "SHE READ A BOOK BY CHER\n",
    "```\n",
    "\n",
    "那么 JOHN READ A BOOK 这个句子的概率是：\n",
    "![](http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95%28Smoothing%29%E5%B0%8F%E7%BB%93/1.jpg)\n",
    "\n",
    "而 CHEN READ A BOOK 这个句子出现的概率是：\n",
    "![](http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95%28Smoothing%29%E5%B0%8F%E7%BB%93/2.jpg)\n",
    "\n",
    "如果使用加1平滑，那么概率就变成了：\n",
    "![](http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95%28Smoothing%29%E5%B0%8F%E7%BB%93/3.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "2.9802322387695312e-08 11.887954313095586 [0.125, 0.125, 0.125, 0.0625, 0.125, 0.125, 0.125, 0.125]\n"
     ]
    }
   ],
   "source": [
    "#  以下任务来自 https://www.coursera.org/learn/language-processing/supplement/fdxeI/perplexity-computation \n",
    "# 手工实现add one smooth\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk import FreqDist\n",
    "import math\n",
    "\n",
    "def get_grams(sentences, n=2):\n",
    "    n_grams = []\n",
    "    n_1_grams = []\n",
    "    unigram = []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.lower().split(' ') \n",
    "        for i in range(n-1):\n",
    "            tokens = ['<s>'] + tokens            \n",
    "        tokens = tokens + [\"<e>\"]    \n",
    "\n",
    "        n_grams = n_grams + list(ngrams(tokens, n=n, pad_left=False, pad_right=False))\n",
    "        n_1_grams = n_1_grams + list(ngrams(tokens, n=n-1, pad_left=False, pad_right=False))\n",
    "        unigram = unigram + list(ngrams(tokens, n=1, pad_left=False, pad_right=False)) \n",
    "    return n_grams, n_1_grams, unigram\n",
    "\n",
    "def show_most_common(dist, m=30):\n",
    "    print('-'*50)\n",
    "    for item in dist.most_common(m):\n",
    "        print(item)\n",
    "\n",
    "        \n",
    "def likehood_estimate(train_sentences, test_sentence, n=2, verbose=False):    \n",
    "    train_n_grams, train_n_1_grams, _ = get_grams(train_sentences, n=n)\n",
    "    train_n_dist, train_n_1_dist = FreqDist(train_n_grams), FreqDist(train_n_1_grams)\n",
    "    if verbose: show_most_common(train_n_dist)\n",
    "    if verbose: show_most_common(train_n_1_dist)\n",
    "    \n",
    "    probs = []\n",
    "    test_grams, _, _ = get_grams([test_sentence], n=n)\n",
    "    prob = 1\n",
    "    \n",
    "    print('-'*50)\n",
    "    for gram in test_grams:\n",
    "        p = train_n_dist[gram]/train_n_1_dist[gram[0:-1]]\n",
    "        if verbose: print(gram, train_n_dist[gram], gram[0:-1], train_n_1_dist[gram[0:-1]])\n",
    "        prob = p*prob\n",
    "        probs.append(p)\n",
    "    perplexity = math.pow(prob, -1/(len(test_grams)-1))    \n",
    "    return prob, perplexity, probs    \n",
    "\n",
    "def add_one_smooth(train_sentences, test_sentence, n=2, verbose=False):\n",
    "    train_n_grams, train_n_1_grams, train_unigram = get_grams(train_sentences, n=n)\n",
    "    train_n_dist, train_n_1_dist, train_1_dist = FreqDist(train_n_grams), FreqDist(train_n_1_grams), FreqDist(train_unigram)\n",
    "    if verbose: show_most_common(train_n_dist)\n",
    "    if verbose: show_most_common(train_n_1_dist)\n",
    "    if verbose: show_most_common(train_1_dist)\n",
    "    v =  len(train_1_dist) - 1\n",
    "    \n",
    "    probs = []\n",
    "    test_grams, _, _ = get_grams([test_sentence], n=n)\n",
    "    prob = 1\n",
    "    False\n",
    "    print('-'*50)\n",
    "    for gram in test_grams:\n",
    "        p = (train_n_dist[gram]+1)/(train_n_1_dist[gram[0:-1]]+v)\n",
    "        if verbose: print(gram, train_n_dist[gram], gram[0:-1], train_n_1_dist[gram[0:-1]])\n",
    "        prob = p*prob\n",
    "        probs.append(p)\n",
    "    perplexity = math.pow(prob, -1/(len(test_grams)-1))    \n",
    "    if verbose: print(len(test_grams)-1, v)\n",
    "    return prob, perplexity, probs\n",
    "    \n",
    "train_sentences = [\"This is the cat that killed the rat that ate the malt that lay in the house that Jack built\"]\n",
    "test_sentence  = \"This is the house that Jack built\"\n",
    "prob, perplexity, probs = add_one_smooth(train_sentences, test_sentence, 3)\n",
    "print(prob, perplexity, probs)\n",
    "assert(perplexity==11.887954313095586)  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "0.0005668934240362811 1.9730415660093537 [1.0, 1.0, 1.0, 0.14285714285714285, 1.0, 0.16666666666666666, 1.0, 0.14285714285714285, 1.0, 0.16666666666666666, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "0.1111111111111111 1.3687381066422017 [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 1.0]\n",
      "--------------------------------------------------\n",
      "1.3281030862990755e-07 9.602746388257104 [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.125, 0.14285714285714285, 0.125, 0.14285714285714285, 0.14285714285714285]\n",
      "--------------------------------------------------\n",
      "8.673326277871513e-08 10.205413747033983 [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.07142857142857142, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "train_sentences = [\"This is the cow with the crumpled horn that tossed the dog that worried the cat that killed the rat that ate the malt that lay in the house that Jack built\"]\n",
    "test_sentence  = \"This is the rat that worried the dog that Jack built\"\n",
    "prob, perplexity, probs = likehood_estimate(train_sentences, test_sentence, 2, verbose=False)\n",
    "print(prob, perplexity, probs)\n",
    "assert(math.isclose(prob, 1/6/7/6/7))\n",
    "\n",
    "train_sentences = [\"This is the rat that ate the malt that lay in the house that Jack built\"]\n",
    "test_sentence  = \"This is the house that Jack built\"\n",
    "prob, perplexity, probs = likehood_estimate(train_sentences, test_sentence, 2, verbose=False)\n",
    "print(prob, perplexity, probs)\n",
    "assert(math.isclose(perplexity, math.pow(1/3*1/3, -1/7)))\n",
    "prob, perplexity, probs = add_one_smooth(train_sentences, test_sentence, 2)\n",
    "print(prob, perplexity, probs)\n",
    "\n",
    "train_sentences = [\"This is the cat that killed the rat that ate the malt that lay in the house that Jack built\"]\n",
    "test_sentence  = \"This is the house that Jack built\"\n",
    "# prob, perplexity, probs = likehood_estimate(train_sentences, test_sentence, 3, verbose=False)  #\n",
    "# print(prob, perplexity, probs)\n",
    "\n",
    "train_sentences = [\"This is the rat that ate the malt that lay in the house that Jack built\"]\n",
    "test_sentence  = \"This is the house that Jack built\"\n",
    "prob, perplexity, probs = add_one_smooth(train_sentences, test_sentence, 3, verbose=False)\n",
    "print(prob, perplexity, probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "0.0005668934240362811 1.9730415660093537 [1.0, 1.0, 1.0, 0.14285714285714285, 1.0, 0.16666666666666666, 1.0, 0.14285714285714285, 1.0, 0.16666666666666666, 1.0, 1.0] 0.0005668934240362812\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "train_sentences = [\"This is the cow with the crumpled horn that tossed the dog that worried the cat that killed the rat that ate the malt that lay in the house that Jack built\"]\n",
    "test_sentence  = \"This is the rat that worried the dog that Jack built\"\n",
    "prob, perplexity, probs = likehood_estimate(train_sentences, test_sentence, 2)\n",
    "print(prob, perplexity, probs, 1/6/7/6/7)\n",
    "assert(math.isclose(prob, 1/6/7/6/7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good-Turing estimate（古德-图灵估计）**\n",
    "\n",
    "摘自[Good-Turing估计](https://heshenghuan.github.io/2016/05/13/Good-Turing%E4%BC%B0%E8%AE%A1/)\n",
    "\n",
    "\n",
    "古德-图灵（Good-Turing）估计法是很多平滑技术的核心，于1953年有古德（I.J.Good）引用图灵（Turing）的方法而提出来的。其基本思想是：对于没有看见的事件，我们不能认为它发生的概率就是零，因此我们从概率的总量（Probability Mass）中，分配一个很小的比例给这些没有看见的事件（如下图）。这样一来看的见概率总和就要小于1了，因此，需要将所有看见的事件概率调小一点。至于小多少，要根据“越是不可信的统计折扣越多”的方法进行。\n",
    "\n",
    "![未看见](../../image/good-turing-event.png)\n",
    "\n",
    "以统计词典中的每个词的概率为例，假设语料库中出现$r$次的词有$N_r$个，特别地，未出现的词数量为$N_0$。语料库的大小为$N$。那么很显然：\n",
    "\n",
    "$$N = \\sum_{r=1}^{\\infty}{rN_r}$$\n",
    "\n",
    "\n",
    "出现r次的词在整个语料库上的相对频度（Relative Frequency）则是$r/N$，如果不做任何处理，就以这个相对频度作为这些词的概率估计。\n",
    "\n",
    "现在假设当$r$比较小时，它的估计可能不可靠，因此在计算出现r次的词的概率时，要使用一个更小的系数$d_r$（而不是直接使用$r$），古德图灵估计按照下面的公式计算$d_r$:\n",
    "\n",
    "$$d_r = (r+1) \\frac{N_{r+1}}{N_r}$$\n",
    "\n",
    "显然有，\n",
    "\n",
    "$$\\sum_r d_r N_r = N$$\n",
    "\n",
    "一般来说，出现一次的词的数量比出现两次的多，出现两次的比三次的多。这种规律称为Zipf定律（Zipf’s Law）。下图是一个小语料上出现r次的词的数量$N_r$和$r$的关系。\n",
    "\n",
    "![Zipf's Law](../../image/zipfs_law.png)\n",
    "\n",
    "可以看出$r$越大，词的数量$N_r$越小，即$N_{r+1}<N_r$。因此，一般情况下$d_r$<r，而$d_0>0$。这样就给未出现的词赋予了一个很小的非零值，从而解决了零概率的问题。同时下调了出现概率很低的词的概率。\n",
    "\n",
    "当然，在实际的自然语言处理中，一般会设置一个阈值$k$，仅对出现次数小于$k$的词做上述调整。并且，因为实际语料的统计情况使得$N_{r+1}<N_r$不一定成立，$N_r=0$情况也可能出现，所以需要使用曲线拟合的方式替换掉原有的$N_r$，并使用如下Kartz退避公式计算$d_r$:\n",
    "\n",
    "$$d_r = \\frac{(r+1)\\frac{N_{r+1}}{N_r}-r\\frac{(k+1)N_{k+1}}{N_1}}{1-\\frac{(k+1)N_{k+1}}{N_1}}, 1 \\le r \\le k$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举例：\n",
    "\n",
    "训练集合：T= {<s\\>what is it what is small?}， |T|=8   \n",
    "验证集合：V={what is it small ? <s\\> flying birds are a bird.}， |V|=12   \n",
    "在训练集合上，我们得到：  \n",
    "$p(<s>)=p(it)=p(small)=p(?)=0.125$    \n",
    "$p(what)=p(is)=0.25, 其他为0   $\n",
    "  \n",
    "\n",
    "如果不经过平滑处理，则验证集上两句子的概率分别为：  \n",
    "$p(what\\ is\\ it?)=0.25*0.25*0.125*0.125≈0.001   $     \n",
    "$p(it\\ is\\ flying.)=0.125*0.25*0*0=0  $\n",
    "    \n",
    "用古德-图灵算法进行平滑处理:\n",
    "\n",
    "- 首先计算，各发生r次N元组类别的数目   \n",
    "$N(0)=6,N(1)=4,N(2)=2 \\\\ \n",
    "N(i)=0,i>2:$  \n",
    "\n",
    "\n",
    "- 其次，重新估计各概率值。   \n",
    "    对于发生0次的事件概率：  \n",
    "    $p(.)=p(flying)=p(birds)=p(are)=p(bird)=p(a)= (0+1)*N(0+1)/(8*N(0))=1*4/(8*6)≈0.083$\n",
    "\n",
    "    对于发生1次的时间概率：  \n",
    "    $p(it)=p(<s>)=p(small)=p(?)=(1+1)*N(1+1)/(8*N(1))=2*2 /(8*4)=0.125  $\n",
    "\n",
    "    对于发生两次的时间概率：  \n",
    "    $p(what)=Pr(is)=(2+1)*N(2+1)/(8*N(2))=3*0/(8*2)=0,  保持原值0.25 $\n",
    "    \n",
    "\n",
    "- 归一化处理:  \n",
    "\n",
    "    $6*P0+4*P1+2*P2=1.5$  \n",
    "  \n",
    "    $p'(it)=p'(<s>)=p'(small)=p'(?)= 0.125/1.5 ≈0.08 \\\\\n",
    "    p'(what)=p'(is)= 0.25/1.5 ≈0.17 \\\\ \n",
    "    p'(.)=p(flying)=p'(birds)=p'(are)=p'(bird)=p'(a) = 0.083/1.5  ≈0.06 $\n",
    "\n",
    "    因此：  \n",
    "    $p'(what\\ is\\ it?)=0.17*0.17*0.08*0.08≈0.0002  \\\\  p'(it\\ is\\ flying.) ≈ 0.08*0.17*0.06*0.06≈0.00004$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kneser-Ney Smoothing**\n",
    "\n",
    "摘自[自然语言处理中N-Gram模型的Smoothing算法](https://blog.csdn.net/baimafujinji/article/details/51297802)\n",
    "\n",
    "这种算法目前是一种标准的，而且是非常先进的平滑算法，它其实相当于是前面讲过的几种算法的综合。由于这个算法比较复杂，我们从一个直观上的例子来开始。假设我们使用 bigram 和 unigram 的插值模型来预测下面这个句子中空缺的一个词该填什么\n",
    "\n",
    "I used to eat Chinese food with ______ instead of knife and fork.\n",
    "\n",
    "直觉上你一定能猜到这个地方应该填 chopsticks（筷子）。但是有一种情况是训练语料库中，Zealand 这个词出现的频率非常高，因为 New Zealand 是语料库中高频词。如果你采用标准的 unigram 模型，那么显然 Zealand 会比 chopsticks 具有更高的权重，所以最终计算机会选择Zealand这个词（而非chopsticks）填入上面的空格，尽管这个结果看起来相当不合理。这其实就暗示我们应该调整一下策略，最好仅当前一个词是 New 时，我们才给 Zealand 赋一个较高的权值，否则尽管在语料库中 Zealand 也是高频词，但我们并不打算单独使用它。\n",
    "\n",
    "如果说 $P(w)$ 衡量了$ w $这个词出现的可能性，那么我们现在想创造一个新的 unigram 模型，叫做 $P_{continuation}$ ，它的意思是将 $w$ 这个词作为一个新的接续的可能性。注意这其实暗示我们要考虑前面一个词（即历史）的影响。或者说，为了评估 $P_{continuation}$ （注意这是一个 unigram 模型），我们其实需要考察使用了 $w $这个词来生成的不同 bigram 的数量。注意这里说使用了$ w$ 这个词来生成的不同类型 bigram 的数量，是指当前词为$ w$ ，而前面一个词不同时，就产生了不同的类型。例如：w = “food”, 那么不同的 bigram 类型就可能包括 “chinese food”，“english food”，“japanese food”等。每一个 bigram 类型，当我们第一次遇到时，就视为一个新的接续（novel continuation）。\n",
    "\n",
    "也就是说 $P_{continuation}$ 应该同所有新的接续（novel continuation）构成的集合之势（cardinality）成比例。所以，可知 \n",
    "\n",
    "$$P_{continuation}(w_i)\\propto \\lvert {w_{i-1}:C(w_{i-1}w_i)>0}\\rvert$$\n",
    "\n",
    "如果你对此尚有困惑，我再来解释一下上面这个公式的意思。当前词是 $w_i$，例如“food”，由此构成的不同类型的 bigram 即为 $w_{i−1}w_i$，其中 $w_{i−1}$ 表示前一个词（preceding word）。显然，所有由 $w_{i−1}w_i$构成的集合的势，其实就取决于出现在$w_i$之前的不同的$w_{i−1}$ 的数量。\n",
    "然后，为了把上面这个数变成一个概率，我们需要将其除以一个值，这个值就是所有 bigram 类型的数量，即$\\lvert\\{(w_{j−1},w_j):C(w_{j−1}w_j)>0\\}\\rvert $，这里大于0的意思就是“出现过”。于是有 \n",
    "\n",
    "$$P_{continuation}(w_i)=\\frac{\\lvert \\{w_{i-1}:C(w_{i-1}w_i)>0\\}\\rvert}{\\lvert\\{(w_{j-1},w_j):c(w_{j-1}w_j)>0\\}\\rvert}$$\n",
    "\n",
    "当然，我们还可以采用下面这种等价的形式 \n",
    "\n",
    "$$P_{continuation}(w_i)=\\frac{\\lvert \\{ w_{i-1}:C(w_{i-1}w_i)>0\\}\\rvert}\n",
    "{\\sum_{w'_i} \\lvert\\{w'_{i-1}:C(w'_{i-1}w'_i)>0\\}\\rvert}$$\n",
    "\n",
    "即所有不同的 bigram 的数量就等于出现在单词 $w'_i$ 前面的所有不同的词$w'_{i-1}$ 的数量。\n",
    "如此一来，一个仅出现在 New 后面的高频词 Zealand 只能获得一个较低的接续概率（continuation probability）。由此，再结合前面给出的Absolute Discounting 的概率计算公式，就可以得出插值的 Kneser-Ney Smoothing 的公式，即 \n",
    "\n",
    "$$P_{KN}(w_i|w_{i-1})=\\frac{max(C(w_{i-1}w_i)-d,0)}{C(w_{i-1})}\n",
    "+\\lambda(w_{i-1})P_{continuation}(w_i)$$\n",
    "\n",
    "其中，$max(C(w_{i-1}w_i)-d,0)$ 的意思是要保证最后的计数在减去一个 $d$ 之后不会变成一个负数。其次，我们将原来的 $P(w_i) $替换成了 $P_{continuation}(w_i)$。此外，$\\lambda$ 是一个正则化常量，用于分配之前discount的概率值（也就是从高频词中减去的准备分给那些未出现的低频词的概率值）： \n",
    "\n",
    "$$\\lambda(w_{i-1})=\\frac{d}{C(w_{i-1})}\\cdot \\lvert \\{w:C(w_{i-1},w)>0\\}\\rvert$$\n",
    "\n",
    "如果用递归的方式重写出一个更加普适的泛化公式则有：\n",
    "\n",
    "$$P_{KN}(w_i|w_{i-n+1}\\cdots w_{i-1})=\\frac{max(0,C_{KN}(w_{i-n+1} \\cdots w_i) - d)}{C_{KN}(w_{i-n+1}\\cdots w_{i-1})}\n",
    "+\\lambda(w_{i-n+1}\\cdots w_{i-1})\\cdot P_{KN}(w_i|w_{i-n+2}\\cdots w_{i-1})$$\n",
    "\n",
    "其中， \n",
    "$$\\lambda(w_{i-n+1}\\cdots w_{i-1})=\\frac{d}{C_{KN}(w_{i-n+1}\\cdots w_{i-1})}\\cdot \\lvert \\{w:C_{KN}(w_{i-n+1} \\cdots w_{i-1}w)>0\\}\\rvert$$\n",
    "\n",
    "由于采用了上述这种递归的写法，我们需要定义一个计数函数 $C_{KN}$，它取决于在插值组合中的各阶 N-Gram 处于哪个层级。例如，假设我们现在所使用的插值模型是trigram，bigram 和 unigram 的组合，那么对于最高阶的 trigram 在计数时并不需要使用接续计数（采用普通计数即可），而其他低阶，即 bigram 和 unigram 则需要使用接续计数。这是因为在 unigram 中，我们遇到了一个 Zealand，我们可以参考它的 bigram，同理在 bigram，我还可以再参考它的 trigram，但是如果我们的插值组合中最高阶就是 trigram，那么现在没有 4-gram来给我们做接续计数。用公式表示即为： \n",
    "\n",
    "$$C_{KN}(\\cdot)=\\begin{cases}count(\\cdot) &,for\\quad the\\quad highest\\quad order\\\\\n",
    "continuationcount(\\cdot) &,for\\quad all\\quad other\\quad lower\\quad orders\n",
    "\\end{cases}$$\n",
    "\n",
    "我们前面提到Kneser-Ney Smoothing 是当前一个标准的、广泛采用的、先进的平滑算法。这里我们所说的先进的平滑算法，其实是包含了其他以 Kneser-Ney 为基础改进、衍生而来的算法。其中，效果最好的Kneser-Ney Smoothing 算法是由Chen & Goodman（1998）提出的modified Kneser-Ney Smoothing 算法。很多NLP的开发包和算法库中提供有原始的Kneser-Ney Smoothing（也就是我们前面介绍的），以及modified Kneser-Ney Smoothing 算法的实现。有兴趣的读者可以查阅相关资料以了解更多。\n",
    "\n",
    "推荐阅读和参考文献：  \n",
    "[1] Speech and Language Processing. Daniel Jurafsky & James H. Martin, 3rd. Chapter 4  \n",
    "[2] 本文中的一些例子和描述来自 北京大学 常宝宝 以及 The University of Melbourne “Web Search and Text Analysis” 课程的幻灯片素材    \n",
    "[3] [A Kneser-Ney mini-example](http://idiom.ucsd.edu/~rlevy/lign256/winter2008/kneser_ney_mini_example.pdf) ： 这里有一个计算的例子，不清楚的时候可以看看。总体Kneser-Ney的确是一个复杂的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.14 TF-IDF\n",
    "\n",
    "处理tf-idf要非常注意，转化后的数据是否正确。比如： TfidfVectorizer类中token_pattern默认是r\"(?u)\\b\\w\\w+\\b\"，它只会匹配长度两个以上的字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 19)\n",
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (0, 16)\t0.4424621378947393\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 5)\t0.3574550433419527\n",
      "[[0.         0.         0.         0.34884223 0.44246214 0.        ]\n",
      " [0.         0.         0.4533864  0.35745504 0.         0.35745504]\n",
      " [0.5        0.5        0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.28113163]]\n",
      "['and', 'apple', 'car', 'china', 'come', 'in', 'is', 'love', 'papers', 'polupar', 'science', 'some', 'tea', 'the', 'this', 'to', 'travel', 'work', 'write']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "corpus=[\"I come to China to travel \", \n",
    "    \"This is a car polupar in China \",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science \"] \n",
    "\n",
    "\n",
    "tfidf2 = TfidfVectorizer()\n",
    "re = tfidf2.fit_transform(corpus)\n",
    "print(re.shape)\n",
    "print(re[0:2])\n",
    "print(re.toarray()[:, 0:6])\n",
    "print( tfidf2.get_feature_names())\n",
    "\n",
    "print('-'*100)\n",
    "# corpus= [dict(Counter(line.split(' ')))  for line in corpus]\n",
    "# print(corpus)\n",
    "\n",
    "# tfidf2 = TfidfVectorizer()\n",
    "# re = tfidf2.fit_transform(corpus)\n",
    "# print(re.shape)\n",
    "# print(re[0:2])\n",
    "# print(re.toarray()[:, 0:6])\n",
    "# print( tfidf2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-24 06:05:22,134: INFO: collecting document frequencies\n",
      "2019-02-24 06:05:22,136: INFO: PROGRESS: processing document #0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('to', 2),\n",
      "  ('china', 1),\n",
      "  ('i', 1),\n",
      "  ('travel', 1),\n",
      "  ('come', 1),\n",
      "  ('hello', 0.2)],\n",
      " [('this', 1),\n",
      "  ('car', 1),\n",
      "  ('a', 1),\n",
      "  ('in', 1),\n",
      "  ('china', 1),\n",
      "  ('polupar', 1),\n",
      "  ('is', 1),\n",
      "  ('hello', 0.4)],\n",
      " [('love', 1),\n",
      "  ('and', 1),\n",
      "  ('i', 1),\n",
      "  ('tea', 1),\n",
      "  ('apple', 1),\n",
      "  ('hello', 0.6000000000000001)],\n",
      " [('some', 1),\n",
      "  ('the', 1),\n",
      "  ('work', 1),\n",
      "  ('to', 1),\n",
      "  ('in', 1),\n",
      "  ('science', 1),\n",
      "  ('is', 1),\n",
      "  ('write', 1),\n",
      "  ('papers', 1),\n",
      "  ('hello', 0.8)]]\n",
      "TfidfModel(num_docs=4, num_nnz=30)\n",
      "[('to', 0.5345224838248488), ('china', 0.2672612419124244), ('i', 0.2672612419124244), ('travel', 0.5345224838248488), ('come', 0.5345224838248488)]\n",
      "[('this', 0.4588314677411235), ('car', 0.4588314677411235), ('a', 0.4588314677411235), ('in', 0.22941573387056174), ('china', 0.22941573387056174), ('polupar', 0.4588314677411235), ('is', 0.22941573387056174)]\n",
      "[('love', 0.48507125007266594), ('and', 0.48507125007266594), ('i', 0.24253562503633297), ('tea', 0.48507125007266594), ('apple', 0.48507125007266594)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %i format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-204ce1b9ef81>\", line 19, in <module>\n",
      "    tfidf = models.TfidfModel(new_corpus)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/gensim/models/tfidfmodel.py\", line 343, in __init__\n",
      "    self.initialize(corpus)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/gensim/models/tfidfmodel.py\", line 396, in initialize\n",
      "    self.num_docs, n_features, self.num_nnz\n",
      "Message: 'calculating IDF weights for %i documents and %i features (%i matrix non-zeros)'\n",
      "Arguments: (4, 'write', 30)\n"
     ]
    }
   ],
   "source": [
    "# gensim也有tfidf, 和上面比较一下\n",
    "from gensim import models\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "texts = [[word for word in document.lower().split()]\n",
    "         for document in corpus]\n",
    "\n",
    "# frequency = defaultdict(int)\n",
    "# for text in corpus:\n",
    "#     for token in text.split():\n",
    "#         frequency[token] += 1\n",
    "# print(frequency)\n",
    "        \n",
    "new_corpus = [  Counter(sentence).most_common()+ [('hello', 0.2*i+0.2)]  for i, sentence in enumerate(texts) ]      \n",
    "pprint(new_corpus)\n",
    "tfidf = models.TfidfModel(new_corpus)\n",
    "print(tfidf)\n",
    "print(tfidf[new_corpus[0]])   #看起来, tfidf的计算值和sklearn中的不同，原因何在？\n",
    "print(tfidf[new_corpus[1]])   \n",
    "print(tfidf[new_corpus[2]])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'come', 'to', 'china', 'to', 'travel'], ['this', 'is', 'a', 'car', 'polupar', 'in', 'china'], ['i', 'love', 'tea', 'and', 'apple'], ['the', 'work', 'is', 'to', 'write', 'some', 'papers', 'in', 'science']]\n",
      "[[('to', 2), ('come', 1), ('travel', 1), ('china', 1), ('i', 1)], [('a', 1), ('is', 1), ('this', 1), ('in', 1), ('car', 1), ('polupar', 1), ('china', 1)], [('love', 1), ('tea', 1), ('and', 1), ('i', 1), ('apple', 1)], [('papers', 1), ('in', 1), ('to', 1), ('work', 1), ('is', 1), ('write', 1), ('the', 1), ('science', 1), ('some', 1)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('to', 0.5345224838248488),\n",
       " ('come', 0.5345224838248488),\n",
       " ('travel', 0.5345224838248488),\n",
       " ('china', 0.2672612419124244),\n",
       " ('i', 0.2672612419124244)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1=[\"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n",
    "texts = [[word for word in document.lower().split()]\n",
    "         for document in corpus1]     \n",
    "print(texts)\n",
    "new_corpus = [  Counter(sentence).most_common()  for sentence in texts ]     \n",
    "print(new_corpus)\n",
    "\n",
    "tfidf_model = models.TfidfModel(new_corpus)\n",
    "tfidf_model[new_corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我喜欢踢足球\n",
      "为甚恶魔     爱中国  已经崛起  \n",
      "['我 来到 北京 清华大学', '他 来到 了 网易 杭研 大厦', '小明 硕士 毕业 于 中国科学院', '我 爱 北京 天安门', '中国 已经 崛起', '每 一个 中国 人 都 爱 中国', '我 喜欢 踢足球 \\n 为 甚 恶魔           爱 中国     已经 崛起    ']\n",
      "(7, 18)\n",
      "----Document 0----\n",
      "北京 0.5382813427107301\n",
      "来到 0.5382813427107301\n",
      "清华大学 0.6484646421965249\n",
      "----Document 1----\n",
      "大厦 0.5206467559864713\n",
      "来到 0.43218152024617124\n",
      "杭研 0.5206467559864713\n",
      "网易 0.5206467559864713\n",
      "----Document 2----\n",
      "中国科学院 0.5\n",
      "小明 0.5\n",
      "毕业 0.5\n",
      "硕士 0.5\n",
      "----Document 3----\n",
      "北京 0.6387085483562188\n",
      "天安门 0.7694487573949885\n",
      "----Document 4----\n",
      "中国 0.5172690941469574\n",
      "崛起 0.60515811332262\n",
      "已经 0.60515811332262\n",
      "----Document 5----\n",
      "一个 0.5760335528744375\n",
      "中国 0.8174260492318878\n",
      "----Document 6----\n",
      "中国 0.32113915333960336\n",
      "喜欢 0.4526083494381602\n",
      "崛起 0.3757037997205483\n",
      "已经 0.3757037997205483\n",
      "恶魔 0.4526083494381602\n",
      "踢足球 0.4526083494381602\n",
      "----Document 0----\n",
      "中国 0.649749587643745\n",
      "北京 0.7601483232611799\n"
     ]
    }
   ],
   "source": [
    "# 中文: jieba + tfidf \n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "raw_corpus = [\"我来到北京清华大学\",\n",
    "          \"他来到了网易杭研大厦\",\n",
    "          \"小明硕士毕业于中国科学院\",\n",
    "          \"我爱北京天安门\",\n",
    "          \"中国已经崛起\",\n",
    "          \"每一个中国人都爱中国\",\n",
    "           '我喜欢踢足球\\n为甚恶魔     爱中国  已经崛起  '\n",
    "         ]\n",
    "\n",
    "print(raw_corpus[6])\n",
    "\n",
    "corpus = [\" \".join(jieba.cut(line, cut_all=False)) for line in raw_corpus]\n",
    "print(corpus)\n",
    "                   \n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "print(tfidf.shape)\n",
    "\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "def show_document(corpus, tfidf):\n",
    "    for i in range(len(corpus)):\n",
    "        print('----Document %d----' % (i))\n",
    "        for j in range(len(words)):\n",
    "            if tfidf[i,j] > 1e-5:\n",
    "                  print(words[j], tfidf[i,j])\n",
    "\n",
    "show_document(corpus, tfidf)\n",
    "       \n",
    "corpus1 = ['中国 首都 是 北京']  \n",
    "tfidf1 = vectorizer.transform(corpus1)\n",
    "show_document(corpus1, tfidf1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13 jieba常用函数\n",
    "https://github.com/fxsjy/jieba\n",
    "\n",
    "词性表： http://www.niumou.com.cn/183 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n",
      "我, 来到, 北京, 清华, 华大, 大学, 清华大学\n",
      "|, [, 2, ], :,  , 我, 想, 给, 我, 的, 机器, 15, -, AK030TX, 加个, 内存条, ，, 你, 能, 给, 我查, 下, 是, 什么, 规格, 的, 吗, ？\n"
     ]
    }
   ],
   "source": [
    "#三种模式：全模式，精确模式， # 搜索引擎模式\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"我来到北京清华大学\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\n",
      "例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\n",
      "「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\n",
      "|[2]: 我想给我的机器15-AK030TX加个内存条，你能给我查下是什么规格的吗？\n",
      "您可以尝试卸载一下无线网的驱动  然后在尝试链接一下无线尝试一下\n",
      "已经发送啦,稍后看看邮件的垃圾箱还有收件箱两个地方哈\n",
      "\n",
      "========================================\n",
      "李小福/是/创新办/主任/也/是/云计算/方面/的/专家/;/ /什么/是/八一双鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉赏鉴/”/的/标题/，/在/自定义/词库/中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。/\n",
      "/|/[/2/]/:/ /我/想/给/我/的/机器/15/-/AK030TX/加个/内存条/，/你/能/给/我查/下/是/什么/规格/的/吗/？/\n",
      "/您/可以/尝试/卸载/一下/无线网/的/驱动/ / /然后/在/尝试/链接/一下/无线/尝试/一下/\n",
      "/已经/发送/啦/,/稍后/看看/邮件/的/垃圾箱/还有/收件箱/两个/地方/哈/\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "#用户词典\n",
    "#encoding=utf-8\n",
    "from __future__ import print_function, unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import jieba\n",
    "jieba.load_userdict(\"userdict.txt\")\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\\n\"\n",
    "\"|[2]: 我想给我的机器15-AK030TX加个内存条，你能给我查下是什么规格的吗？\\n\"\n",
    "\"您可以尝试卸载一下无线网的驱动  然后在尝试链接一下无线尝试一下\\n\"\n",
    "\"已经发送啦,稍后看看邮件的垃圾箱还有收件箱两个地方哈\\n\"\n",
    ")\n",
    "print(test_sent)\n",
    "print(\"=\"*40)\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))\n",
    "\n",
    "print(\"=\"*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pseg.cut(test_sent)\n",
    "\n",
    "for w in result:\n",
    "    print(w.word, \"/\", w.flag, \", \", end=' ')\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "\n",
    "terms = jieba.cut('easy_install is great')\n",
    "print('/'.join(terms))\n",
    "terms = jieba.cut('python 的正则表达式是好用的')\n",
    "print('/'.join(terms))\n",
    "\n",
    "print(\"=\"*40)\n",
    "# test frequency tune: 如果有些词在一定场景存在变化，这种用户词典，可能更加的科学。\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]\n",
    "\n",
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    # suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    print(\"-\"*40)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "\n",
    "jieba.suggest_freq(('中', '将'), False)\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "jieba.suggest_freq('台中', False)\n",
    "\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "\n",
    "words =jieba.cut(\"我们中出了一个叛徒\",HMM=False)\n",
    "print('/'.join(words))\n",
    "jieba.suggest_freq(('中出'),True)\n",
    "words =jieba.cut(\"我们中出了一个叛徒\",HMM=False)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12 BLEU分数 \n",
    "\n",
    "BLEU，全称为Bilingual Evaluation Understudy（双语评估替换），是一个比较候选文本翻译与其他一个或多个参考翻译的评价分数。\n",
    "尽管BLEU一开始是为翻译工作而开发，但它也可以被用于评估文本的质量，这种文本是为一套自然语言处理任务而生成的。\n",
    "\n",
    "**惩罚因子**\n",
    "\n",
    "$ BP = \\begin{equation}  \n",
    "\\left\\{  \n",
    "\\begin{array}{lcl}  \n",
    " 1        & &  if\\ c>r \\\\  \n",
    " e^{(1-r/c)} & &  if\\ c<=r  \n",
    "\\end{array}  \n",
    "\\right.  \n",
    "\\end{equation}   $  \n",
    "\n",
    "这里的c是机器译文的词数，r是参考译文的词数\n",
    "\n",
    "$\n",
    "BLEU = BP \\cdot exp \\left( \\sum\\limits_{n=1}^N w_n \\log p_n \\right)\n",
    "$  \n",
    "[浅谈用Python计算文本BLEU分数](https://cloud.tencent.com/developer/article/1042161)  \n",
    "[机器翻译自动评估-BLEU算法详解](https://blog.csdn.net/qq_31584157/article/details/77709454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArgSpec(args=['references', 'hypothesis', 'weights', 'smoothing_function', 'auto_reweigh'], varargs=None, keywords=None, defaults=((0.25, 0.25, 0.25, 0.25), None, False))\n",
      "--------------------------------------------------------------------------\n",
      "gram_scores: [0.88888889 0.75       0.71428571 0.66666667]\n",
      "weights: (0.25, 0.25, 0.25, 0.25) - score: 0.750624 - manual score: 0.750624  - manual score(no bp): 0.750624  \n",
      "--------------------------------------------------------------------------\n",
      "gram_scores: [0.77777778 0.5        0.42857143 0.33333333]\n",
      "weights: (0.25, 0.25, 0.25, 0.25) - score: 0.485492 - manual score: 0.485492  - manual score(no bp): 0.485492  \n",
      "--------------------------------------------------------------------------\n",
      "gram_scores: [0.75147729 0.75147729 0.75147729 0.75147729]\n",
      "weights: (0.25, 0.25, 0.25, 0.25) - score: 0.751477 - manual score: 0.564718  - manual score(no bp): 0.751477  \n",
      "--------------------------------------------------------------------------\n",
      "gram_scores: [0.81818182 0.8        0.77777778 0.75      ]\n",
      "weights: (0.25, 0.25, 0.25, 0.25) - score: 0.786075 - manual score: 0.786075  - manual score(no bp): 0.786075  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import inspect\n",
    "print(inspect.getargspec(sentence_bleu))\n",
    "\n",
    "def manual_bleu(gram_scores, weights):    \n",
    "    return np.exp(np.sum((np.log(gram_scores) * np.array(weights))))\n",
    "    \n",
    "def bleu(reference, candidate, all_weights=[(1, 0, 0, 0), (0.5, 0.5, 0, 0), (0.33, 0.33, 0.33, 0), (0.25, 0.25, 0.25, 0.25)]):   \n",
    "    print(\"--------------------------------------------------------------------------\")    \n",
    "    gram1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    gram2 = sentence_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "    gram3 = sentence_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "    gram4 = sentence_bleu(reference, candidate, weights=(0, 0, 0, 1))\n",
    "\n",
    "    gram_scores = np.array([gram1, gram2, gram3, gram4])\n",
    "    print('gram_scores: %s' % gram_scores)\n",
    "    \n",
    "    bp = 1 if len(reference[0]) < len(candidate) else  math.exp(1-len(reference[0])/len(candidate))\n",
    "    for weights in all_weights:            \n",
    "        score = sentence_bleu(reference, candidate, weights=weights)   \n",
    "        manual_score_no_bp = manual_bleu(gram_scores, weights)\n",
    "        manual_score = bp *  manual_score_no_bp\n",
    "        print(\"weights: %s - score: %f - manual score: %f  - manual score(no bp): %f  \" % (weights, score, manual_score, manual_score_no_bp) )\n",
    "\n",
    "\n",
    "# reference = [['this', 'is', 'a', 'test']]\n",
    "# candidate = ['this', 'is', 'a', 'test']\n",
    "# bleu(reference, candidate)\n",
    "\n",
    "# reference = [['this', 'is', 'small', 'test']]\n",
    "# candidate = ['this', 'is', 'a', 'test']\n",
    "# bleu(reference, candidate)\n",
    "\n",
    "# one word different\n",
    "reference = [['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']]\n",
    "candidate = ['the', 'fast', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "bleu(reference, candidate, all_weights=[(0.25, 0.25, 0.25, 0.25)])\n",
    "\n",
    "# two words different\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']]\n",
    "candidate = ['the', 'fast', 'brown', 'fox', 'jumped', 'over', 'the', 'sleepy', 'dog']\n",
    "bleu(reference, candidate, all_weights=[(0.25, 0.25, 0.25, 0.25)])\n",
    "\n",
    "# shorter candidate\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']]\n",
    "candidate = ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the']\n",
    "bleu(reference, candidate, all_weights=[(0.25, 0.25, 0.25, 0.25)])\n",
    "#这里有个问题，\n",
    "#weights: (0.25, 0.25, 0.25, 0.25) - score: 0.751477 - manual score: 0.564718 \n",
    "# 手工计算的结果和library中的结果有差异，经过检查发现manual score如果不乘于bp，则结果能匹配上。难道是library里有bug.\n",
    "            \n",
    "# longer candidate\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']]\n",
    "candidate = ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', 'from', 'space']\n",
    "bleu(reference, candidate, all_weights=[(0.25, 0.25, 0.25, 0.25)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Five Types of RNN(RNN的几种类型)\n",
    "\n",
    "![five rnn](../../image/five_rnn.png)\n",
    "\n",
    " 1. Element-wise sequence classification\n",
    " 2. Unconditional sequence generation\n",
    " 3. Sequence classification\n",
    " 4. Conditional sequence generation\n",
    " 5. Sequence translation(sequence to sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 word2vec\n",
    "\n",
    "\n",
    "\n",
    "**Bengio2003的论文《A Neural Probabilistic Language Model》**\n",
    "![Bengio NPLM](../../image/bengio_nnlm.png)\n",
    "\n",
    "**如何找到一种简单有效的词向量学习方法**\n",
    "\n",
    "首先根据具体任务，选一个领域相似的语料，在这个条件下，语料越大越好。然后下载一个 word2vec 的新版（14年9月更新），语料小（小于一亿词，约 500MB 的文本文件）的时候用 Skip-gram 模型，语料大的时候用 CBOW 模型。最后记得设置迭代次数为三五十次，维度至少选 50，就可以了。\n",
    "\n",
    "语料对词向量的影响比模型的影响要重要得多得多得多。语料方面，很多论文都提到语料越大越好，我们发现，语料的领域更重要。领域选好了，可能只要 1/10 甚至 1/100 的语料，就能达到一个大规模泛领域语料的效果。有时候语料选的不对，甚至会导致负面效果（比随机词向量效果还差）。文章还做了实验，当只有小规模的领域内语料，而有大规模的领域外语料时，到底是语料越纯越好，还是越大越好。在我们的实验中，是越纯越好。这一部分实验数据比较丰富，原文相对清楚一些。\n",
    "\n",
    "\n",
    "**相关**\n",
    "- [[NLP] 秒懂词向量Word2vec的本质](https://zhuanlan.zhihu.com/p/26306795)\n",
    "- [Deep Learning in NLP （一）词向量和语言模型](http://licstar.net/archives/328)\n",
    "- [word2vec 中的数学原理详解](https://blog.csdn.net/itplus/article/details/37969519)  说实话，还是把这个看完后，感觉到一些安心\n",
    "- [Deep Learning实战之word2vec](http://techblog.youdao.com/?p=915#LinkTarget_699)\n",
    "- [基于神经网络的词和文档语义向量表示方法研究](../../paper/Word_and_Document Embeddings_based_on_Neural_Network_Approaches.pdf)  可以作为更深入全面的扩展阅读，这里不仅仅有 word2vec，而是把词嵌入的所有主流方法通通梳理了一遍\n",
    "- [《How to Generate a Good Word Embedding?》导读](http://licstar.net/archives/620#comment-1542) \n",
    "- [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738)  理论完备由浅入深非常好懂，且直击要害，既有 high-level 的 intuition 的解释，也有细节的推导过程\n",
    "- [Word and Document Embeddings based on Neural Network Approaches](https://arxiv.org/pdf/1611.05962)\n",
    "- [基于神经网络的词和文档语义向量表示方法研究](https://arxiv.org/ftp/arxiv/papers/1611/1611.05962.pdf) 对于初学者，的确是文本向量化的集大成之文。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 什么是avoidable bias ？\n",
    "\n",
    "\n",
    "<img src=\"../../image/reduce_bias_variance.png\">\n",
    "\n",
    "如果human-level的error不同，比如：\n",
    "\n",
    "top one expert: 0.1%\n",
    "expert1 : 0.2%\n",
    "expert2 : 0.3%\n",
    "normal human: 1%\n",
    "选择最小的error作为human-level的error。这是因为这代表了人类的最高水平，理论上非常接近Bayes Possible Error。\n",
    "\n",
    "Human-level error is a proxy for Bayes error. 机器学习的准确度 Accuracy 提升有两道坎, 一道是 human-level, 人类非常擅长一些工作, 比如判断是猫与否, 因此将其设为第一道坎, 表达了对人类的尊重; 另一道坎是 贝叶斯可能误差 Bayes Possible Error, 这是学习任务的理论最优值, 可以说是, 看得到摸不着的天花板."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 why is gradients sometimes vanishing or exploding? \n",
    "![a](../../image/vanish_explode_gradient.png)\n",
    "\n",
    "上面的这个解释非常形象，但$W$取了一个对角矩阵，还不够普遍，下面进一步解释一下。\n",
    "\n",
    "设$W = P\\lambda P^\\mathrm{T}$，则$W^{l-1}=P\\lambda^{l-1}P^\\mathrm{T}$， $\\hat{y} = W^{l}P\\lambda^{l-1}P^\\mathrm{T}X $\n",
    "\n",
    "这个时候的导数，还是取决于特征值，如果特征值大于1，则导数就非常大，如果特征值小于1，则导数趋近于0。\n",
    "所以好的weight initialization策略非常重要\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 应对梯度爆炸的方法**\n",
    "\n",
    "- Gradient Clipping\n",
    "![a](../../image/gradient_clipping.png)\n",
    "![a](../../image/gradient_clipping_threshold.png)\n",
    "\n",
    "- Truncated BPTT：避免梯度爆炸。当反向传播时，仅仅只反向传播一定步骤。\n",
    "![a](../../image/full_bptt.png)\n",
    "![a](../../image/truncated_bptt.png)\n",
    "\n",
    "carry hidden states forward in time forever, but only backpropagate for some smaller number of steps. \n",
    "\n",
    "** 应对梯度消失的方法**\n",
    "- LSTM， GRU\n",
    "- Relu\n",
    "![resistant](../../image/relu_resistant.png)\n",
    "![derivative](../../image/derivative.png)\n",
    "- Initialization\n",
    "![orthogonal](../../image/w_orthogonal.png)\n",
    "![w value](../../image/w_value.png)\n",
    "- Skip Connnections(Resnet)\n",
    "![skip_connection](../../image/skip_connection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 why does deep learning break bias variance trade-off（both low bias and low varance）\n",
    "\n",
    "![bias_variance_tradeoff](../../image/bias_variance_tradeoff.png)\n",
    "\n",
    "在深度学习里，可以打破bias variance trade-off。\n",
    "\n",
    "1 消除High Bias。采用更大更深的网络，更长的train时间（更好的优化方法），更加适合的神经网络架构。  \n",
    "2 消除High Variance。采用更多的数据，更大正则化系数，更加适合的神经网络架构。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Big Data大数据中Train，Dev和Test Sets的比例发生了变化\n",
    "\n",
    "![train_dev_test](../../image/train_dev_test.png)\n",
    "\n",
    "对于Big Data（$>1000,000$），三者比例变成98：1：1，甚至99.5：0.25：0.25。尽可能的利用数据，来训练出一个更好的模型。另外需要注意的一点就是Train sets与Dev Sets, Test Sets的数据分布可以不同, 但要保证 Dev Set和 Test Set 这两个集合来自同一数据分布，以确保我们能够通过在 Dev Set上的评估能正确反映在 Test Set 的性能。\n",
    "\n",
    "## 1.5 为什么Regularization会抑制overfitting?\n",
    "\n",
    "![prevent_overfitting](../../image/prevent_overfitting.png)\n",
    "\n",
    "正则项中$\\lambda$越大，则$W$更加趋近于0，则$Z$会变得更小，则$Z$的取值范围在图中圆圈范围。而$tanh, sigmoid$在该范围趋近于线性，这样整个模型显得更加简单，从而减少过拟合。\n",
    "\n",
    "## 1.4 $\\textbf{为什么正则项中，往往没有b}$?\n",
    "\n",
    "因为$W$里面已经包含了大量的参数，$b$就可以忽略。这个解释似乎有些牵强。在PRML中说： “通常系数w0从正则化项中省略，因为包含w0会使得结果依赖于⽬标变量原点的选择。w0也可以被包含在正则化项中，但是必须有⾃⼰的正则化系数”。 还是迷糊。\n",
    "\n",
    "在线性分类器中，w如果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Huffman编码 \n",
    "\n",
    "霍夫曼编码（英语：Huffman Coding），是一种用于无损数据压缩的熵编码（权编码）算法。由大卫·霍夫曼在1952年发明。\n",
    "\n",
    "![构建Huffman树](../../image/huffman_tree_build.gif)\n",
    "\n",
    "在电文传输中，需要将电文中出现的每个字符进行二进制编码。采用霍夫曼编码可以使得发送的二进值编码尽可能短。\n",
    "\n",
    "**相关**\n",
    "- [霍夫曼树和霍夫曼编码原理](https://blog.csdn.net/sddxqlrjxr/article/details/51114809)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 CNN发展史  2018-05-03\n",
    "\n",
    "希望能够通读下面的网络的相关论文，并同时做实验重现论文，\n",
    "\n",
    "![cnn发展](../../image/cnn-progress.png)\n",
    "\n",
    "- [【卷积神经网络-进化史】从LeNet到AlexNet](https://blog.csdn.net/cyh_24/article/details/51440344) 上图来自于这篇blog\n",
    "- [CNN的近期进展与实用技巧（上）](https://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&mid=2650324619&idx=1&sn=ca1aed9e42d8f020d0971e62148e13be&scene=1&srcid=0503De6zpYN01gagUvn0Ht8D#wechat_redirect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Deep Learning is a language 深度学习是一门语言   2018-05-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正在学习了国立高等经济大学（后面简称高经大学）的系列深度学习课程，感觉真的不错，真的不得不佩服俄罗斯人。和NG的课程比较，高经大学的课程内容更加丰富，简明，干货满满，作业量甚至是NG的3倍。NG的课程更加的大众，很多东西都不敢讲深一点。或许对于现阶段的我来说，高经大学的课程更加适合。课程中，有很多启发，比如，在intro-to-deep-learning第二周中提出：deep learning is a language。然后举了两个例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bottleneck layer](../../image/dl-is-a-language0.png)\n",
    "#### Bottle neck layer  \n",
    "这是一个预测汽车价格的网络。有两类数据，第一类是Raw features，是汽车图片，第二类是汽车的high level属性，比如：品牌，配置，型号，年限等等。一般我们认为第二类数据更加代表了汽车的价格，第一类数据由于涉及到拍照的条件影响，可能误判的可能性比较大，这种情况下，我们要加大对第二类数据的权重。通过引入bottleneck layer能够简明实现这一逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bottleneck layer](../../image/dl-is-a-language1.png)\n",
    "\n",
    "利用Age gender等数据量巨大的数据集和训练神经网络，然后用这个网络再来训练小的数据集，这样可以得到更好的结果。其实这也是迁移学习，不是第一次看到，但看了这个图之后，感觉更加的有触动，首先，age， gender是一些高级特性，很容易得大量数据，而从道理上说，年纪，性别等对衣服的选择有很多的影响。采用这个迁移学习，实现了高级特性和低层特性的融合。真的非常巧妙。联想到之前绘画风格的转换融合，感觉深度学习网络是一种连接器，用它来连接相关的一些属性，建立这些属性深层的联系。真的要开阔思路了。\n",
    "\n",
    "通过两个例子可以感到，深度神经网络是一种语言，用它来连接我们的各种数据，用它来表达我们对数据关系的理解。这不就是一种语言吗？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
